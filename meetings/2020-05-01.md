Faire le même travail mais en groupant par head
trouver si il y a des endroits du réseau qui sont language-specific, et d'autres qui sont language-agnostic

Débat : est-ce que les modèles de langue multilingues ont une représentation abstraite des langues qqpart ?

Ne pas oublier de checker comment les tokenizers des modèles monolingues réagissent à des caractères inconnus


- Sur un modèle sur les 144, tester les importances
- Sur 12 modèles (1 par couche), comparer les performances (en 12 et en 12*64 dims)
- Sur 144 modèles (1 par head), comparer les performances (en 64 dims)


Si possible, entraîner un modèle sur du scrambled pour vérifier l'intérêt de la probing task ?

il pourrait y avoir un effet de seq_length: dans certaines langues, les phrases sont plus longues

Publication
- Idée originale
- Faut être très rigoureux: tester tjrs sur tous les modèles
- Idée la plus forte: localiser l'information dans certains layers ou heads
