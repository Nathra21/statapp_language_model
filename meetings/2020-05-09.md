Il semble que ce soit difficile de distinguer par head.
Conviction de Benjamin : par layer, il y a qqch à trouver. Notamment on devrait trouver une info plus forte sur l'identité des langues dans les premiers layers.

- Régressions par layer, chacun sur 12 entropies
- Ptet dans un 2e temps, voir si une autre probing task classique (basée sur les vecteurs de contexte) extrait la même information
- Refaire les régressions avec modèles plus puissants (NN, GBDT)
- Comprendre pourquoi on arrive à classifier les modèles monolingues
- Refaire une passe sur les longueurs de phrases
    - Soit normaliser l'entropie
    - Soit faire des buckets de longueurs différentes

Pour tous les modèles, mettre les special tokens au début et à la fin de la phrase avant de passer dans le modèle

Soit utiliser les modèles monolingues mais enlever les langues non latines ;
Soit utiliser que les modèles multi

Peut-être abandonner l'idée de prédire la langue et juste observer les contextual embeddings (output d'un bloc SA + FF)
