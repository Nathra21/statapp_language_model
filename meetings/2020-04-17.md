- Toujours comparer différents modèles entre eux et utiliser bcp de phrases, pour ne pas se perdre dans des résultats qui sont du bruit
- Tenter d'ajouter un random transformer
- Ou evtl entraîner un transfo sur du bruit

Ce qu'on regarde est-ce que c'est interprétable ?
- 3000 vecteurs de 12 entropies par langue
- Tenter de construire un prédicteur de ce vecteur vers la langue (k-NN, linéaire, SVM)
- Puis faire avec 144 dimensions, déterminer si certaines heads sont plus informatives que d'autres
- Prendre pour controle le random transformer

- Tenter de filtrer l'attention sur les special tokens
- Garder en tête l'influence du token [CLS] dans Bert et mBERT

Roberta et Camembert sont exactement le même modèle.

- Couples: BERT/mBERT ; XLM-R/Roberta

- Sur la comparaison des dists des seq_lengths, tenter de faire en bootstrapant dans les seq plus grandes
