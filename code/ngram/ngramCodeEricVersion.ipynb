{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmation d'un modèle de langue n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ngram import NGramModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise ici l'extrait assez faible (15 Mo) disponible sur le drive de Benjamin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "## Greedy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03333333, 0.13333333, 0.3       , 0.53333333])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = np.array([1, 2, 3, 4])\n",
    "probas = probas / sum(probas)\n",
    "probas**2 / sum(probas**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      "elle est la ville de la réalité , en plus de la première fois , en fait , qui lui , il est pas de la même ,\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      "elle est la plus grande communauté catholique .\n",
      "on compte parmi ses élèves , il est aussi l' impact de l' union européenne , une partie de la population\n",
      "\n",
      "Fitting 4-gram model on vocabulary of size 133657.\n",
      "Predicting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-749d71059181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_sampled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"elle est la\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/statapp_language_model/code/ngram/ngram.py\u001b[0m in \u001b[0;36mgenerate_sampled\u001b[0;34m(self, nb_words_to_gen, previous_words, power)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_words_to_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mcond_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mcond_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_probas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcond_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcond_probas\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcond_probas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/statapp_language_model/code/ngram/ngram.py\u001b[0m in \u001b[0;36mpredict_probas\u001b[0;34m(self, previous_words)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 self.get_word_probability(\n\u001b[1;32m     66\u001b[0m                     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0mprevious_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 )\n\u001b[1;32m     69\u001b[0m             )\n",
      "\u001b[0;32m~/git/statapp_language_model/code/ngram/ngram.py\u001b[0m in \u001b[0;36mget_word_probability\u001b[0;34m(self, word, previous_words)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Error in probability calculation: invalid number of previous words: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq_n_minus_one_grams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"fr_wikipedia_sample.txt\",\"r\",encoding=\"utf8\") as file:\n",
    "    corpus=file.read()\n",
    "corpus = corpus.lower()\n",
    "seqcorpus = corpus.split(' ')\n",
    "    \n",
    "for i in range(2,6):\n",
    "    # print(\"Résultats pour\",i,\"gram\")\n",
    "    model = NGramModel(i)\n",
    "    model.fit(seqcorpus)\n",
    "    print(\"Predicting...\")\n",
    "    text = \" \".join(model.generate_sampled(25,\"elle est la\", power=2))\n",
    "    print(text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : ça se met souvent à boucler ! Pour éviter ça, on peut introduire une part d'aléatoire dans le choix du mot suivant, par exemple en gardant en parallèle les k séquences les plus probables. Cette méthode s'appelle le beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Génère une séquence de nbmots mots conditionnellement à la séquence précédente seqprec\n",
    "#Avec la méthode Beam Search pour k meilleurs séquences conservées à chaque étape\n",
    "def genererbeam(nbmots,seqprec,k):\n",
    "    sequences=[[seqprec,1]]\n",
    "    #A chaque etape\n",
    "    for i in range(nbmots):\n",
    "        #calcule tous les candidats possibles de l'étape (sequence totale et proba associée)\n",
    "        candidates=[]\n",
    "        for j in range(len(sequences)):\n",
    "            seq, prob = sequences[j]\n",
    "            for mot in vocabulaire:\n",
    "                candidates.append([seq+\" \"+mot,prob*probacond(mot,\" \".join(seq.split(' ')[-(n-1):]))])\n",
    "        # ordonne les candidats selon le score\n",
    "        ordered = sorted(candidates, key=lambda tup:tup[1])\n",
    "        # sélectionne les k meilleurs\n",
    "        sequences = ordered[-k:]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s> le premier ministre de la fin de la ville de la ville de la ville de la ville de la ville de la ville de la ville de la ville',\n",
       "  7.486873168181089e-34],\n",
       " ['<s> le premier ministre de la fin de la ville de la ville de la ville de la ville de la ville de la ville de la ville de la première',\n",
       "  8.241045373767097e-34],\n",
       " ['<s> le premier ministre de la fin de la ville de la ville de la ville de la ville de la ville de la ville de la première fois , le',\n",
       "  9.530640308839064e-34]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cas bigram\n",
    "genererbeam(30,\"<s>\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"<s> il s' agit d' un point de vue de la population </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> la première\",\n",
       "  2.592672590660988e-27],\n",
       " [\"<s> il s' agit d' un point de vue de la population </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le pays\",\n",
       "  2.841209628240636e-27],\n",
       " [\"<s> il s' agit d' un point de vue de la population </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le premier\",\n",
       "  3.1430881512412038e-27]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cas trigram\n",
    "genererbeam(30,\"<s> il\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"<s> il est également possible de porter la balle à deux mains </s> <s> lance : terme générique désignant une arme offensive dotée d' un fer emmanché sur une hampe </s> <s> jetés à terre , leurs corps sont foulés par les vainqueurs représentés sous des formes mixtes , en partie grâce aux\",\n",
       "  2.0868169263891186e-11],\n",
       " [\"<s> il est également possible de porter la balle à deux mains </s> <s> lance : terme générique désignant une arme offensive dotée d' un fer emmanché sur une hampe </s> <s> jetés à terre , leurs corps sont foulés par les vainqueurs représentés sous des formes mixtes , en partie , par\",\n",
       "  2.608521157986398e-11],\n",
       " [\"<s> il est également possible de porter la balle à deux mains </s> <s> lance : terme générique désignant une arme offensive dotée d' un fer emmanché sur une hampe </s> <s> jetés à terre , leurs corps sont foulés par les vainqueurs représentés sous des formes mixtes , en partie grâce à\",\n",
       "  8.347267705556474e-11]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cas quatrigram\n",
    "genererbeam(50,\"<s> il est\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cas 5-gram\n",
    "genererbeam(30,\"<s> il est le\",3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Améliorations :\n",
    "-> lissage (smoothing)\n",
    "-> Apprendre les fréquences de tous les k-grams pour k<n pour pouvoir switcher à un k plus petit si le k-gram recherché est absent lors de la prédiction\n",
    "-> Travailler avec les log-probas pour être sûr de ne pas perdre en précision -> Le temps pour générer le texte me semble très long, il y a sans doute moyen d'optimiser le code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
