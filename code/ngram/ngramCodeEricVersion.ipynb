{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmation d'un modèle de langue n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ngram import NGramModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise ici l'extrait assez faible (15 Mo) disponible sur le drive de Benjamin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "## Greedy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      "('elle', 'est', 'la', 'première', 'fois', ',', 'le', 'plus', 'de', 'la', 'première', 'fois', ',', 'le', 'plus', 'de', 'la', 'première', 'fois', ',', 'le', 'plus', 'de', 'la', 'première', 'fois', ',', 'le', 'plus', 'de', 'la', 'première', 'fois', ',', 'le', 'plus', 'de', 'la', 'première', 'fois', ',', 'le', 'plus', 'de', 'la', 'première', 'fois', ',', 'le', 'plus', 'de', 'la', 'première')\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      "('elle', 'est', 'la', 'plus', 'grande', 'partie', 'de', 'la', 'population', 'de', \"l'\", 'état', 'de', 'la', 'population', 'de', \"l'\", 'état', 'de', 'la', 'population', 'de', \"l'\", 'état', 'de', 'la', 'population', 'de', \"l'\", 'état', 'de', 'la', 'population', 'de', \"l'\", 'état', 'de', 'la', 'population', 'de', \"l'\", 'état', 'de', 'la', 'population', 'de', \"l'\", 'état', 'de', 'la', 'population', 'de', \"l'\")\n",
      "\n",
      "Fitting 4-gram model on vocabulary of size 133657.\n",
      "Predicting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-624c60ed8b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_greedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"elle est la\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/statapp_language_model/code/ngram/ngram.py\u001b[0m in \u001b[0;36mgenerate_greedy\u001b[0;34m(self, nb_words_to_gen, previous_words)\u001b[0m\n\u001b[1;32m     71\u001b[0m                     self.get_word_probability(\n\u001b[1;32m     72\u001b[0m                         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                         \u001b[0mprevious_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                     )\n\u001b[1;32m     75\u001b[0m                 )\n",
      "\u001b[0;32m~/git/statapp_language_model/code/ngram/ngram.py\u001b[0m in \u001b[0;36mget_word_probability\u001b[0;34m(self, word, previous_words)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             proba = (\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq_n_grams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_words\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq_n_minus_one_grams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"fr_wikipedia_sample.txt\",\"r\",encoding=\"utf8\") as file:\n",
    "    corpus=file.read()\n",
    "corpus = corpus.lower()\n",
    "seqcorpus = corpus.split(' ')\n",
    "    \n",
    "for i in range(2,6):\n",
    "    # print(\"Résultats pour\",i,\"gram\")\n",
    "    model = NGramModel(i)\n",
    "    model.fit(seqcorpus)\n",
    "    print(\"Predicting...\")\n",
    "    text = \" \".join(model.generate_greedy(50,\"elle est la\")))\n",
    "    print(text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : ça se met souvent à boucler ! Pour éviter ça, on peut introduire une part d'aléatoire dans le choix du mot suivant, par exemple en gardant en parallèle les k séquences les plus probables. Cette méthode s'appelle le beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Génère une séquence de nbmots mots conditionnellement à la séquence précédente seqprec\n",
    "#Avec la méthode Beam Search pour k meilleurs séquences conservées à chaque étape\n",
    "def genererbeam(nbmots,seqprec,k):\n",
    "    sequences=[[seqprec,1]]\n",
    "    #A chaque etape\n",
    "    for i in range(nbmots):\n",
    "        #calcule tous les candidats possibles de l'étape (sequence totale et proba associée)\n",
    "        candidates=[]\n",
    "        for j in range(len(sequences)):\n",
    "            seq, prob = sequences[j]\n",
    "            for mot in vocabulaire:\n",
    "                candidates.append([seq+\" \"+mot,prob*probacond(mot,\" \".join(seq.split(' ')[-(n-1):]))])\n",
    "        # ordonne les candidats selon le score\n",
    "        ordered = sorted(candidates, key=lambda tup:tup[1])\n",
    "        # sélectionne les k meilleurs\n",
    "        sequences = ordered[-k:]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s> le premier ministre de la fin de la ville de la ville de la ville de la ville de la ville de la ville de la ville de la ville',\n",
       "  7.486873168181089e-34],\n",
       " ['<s> le premier ministre de la fin de la ville de la ville de la ville de la ville de la ville de la ville de la ville de la première',\n",
       "  8.241045373767097e-34],\n",
       " ['<s> le premier ministre de la fin de la ville de la ville de la ville de la ville de la ville de la ville de la première fois , le',\n",
       "  9.530640308839064e-34]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cas bigram\n",
    "genererbeam(30,\"<s>\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"<s> il s' agit d' un point de vue de la population </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> la première\",\n",
       "  2.592672590660988e-27],\n",
       " [\"<s> il s' agit d' un point de vue de la population </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le pays\",\n",
       "  2.841209628240636e-27],\n",
       " [\"<s> il s' agit d' un point de vue de la population </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le pays </s> <s> le premier\",\n",
       "  3.1430881512412038e-27]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cas trigram\n",
    "genererbeam(30,\"<s> il\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"<s> il est également possible de porter la balle à deux mains </s> <s> lance : terme générique désignant une arme offensive dotée d' un fer emmanché sur une hampe </s> <s> jetés à terre , leurs corps sont foulés par les vainqueurs représentés sous des formes mixtes , en partie grâce aux\",\n",
       "  2.0868169263891186e-11],\n",
       " [\"<s> il est également possible de porter la balle à deux mains </s> <s> lance : terme générique désignant une arme offensive dotée d' un fer emmanché sur une hampe </s> <s> jetés à terre , leurs corps sont foulés par les vainqueurs représentés sous des formes mixtes , en partie , par\",\n",
       "  2.608521157986398e-11],\n",
       " [\"<s> il est également possible de porter la balle à deux mains </s> <s> lance : terme générique désignant une arme offensive dotée d' un fer emmanché sur une hampe </s> <s> jetés à terre , leurs corps sont foulés par les vainqueurs représentés sous des formes mixtes , en partie grâce à\",\n",
       "  8.347267705556474e-11]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cas quatrigram\n",
    "genererbeam(50,\"<s> il est\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cas 5-gram\n",
    "genererbeam(30,\"<s> il est le\",3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Améliorations :\n",
    "-> lissage (smoothing)\n",
    "-> Apprendre les fréquences de tous les k-grams pour k<n pour pouvoir switcher à un k plus petit si le k-gram recherché est absent lors de la prédiction\n",
    "-> Travailler avec les log-probas pour être sûr de ne pas perdre en précision -> Le temps pour générer le texte me semble très long, il y a sans doute moyen d'optimiser le code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
