{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmation d'un modèle de langue n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ngram import NGramModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise ici l'extrait assez faible (15 Mo) disponible sur le drive de Benjamin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "## Greedy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03333333, 0.13333333, 0.3       , 0.53333333])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = np.array([1, 2, 3, 4])\n",
    "probas = probas / sum(probas)\n",
    "probas**2 / sum(probas**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fr_wikipedia_sample.txt\",\"r\",encoding=\"utf8\") as file:\n",
    "    corpus=file.read()\n",
    "corpus = corpus.lower()\n",
    "seqcorpus = corpus.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus de la première fois , le plus de la première fois , le plus de la première fois , le plus de la première fois\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie de la population de l' état de la population de l' état de la population de l' état de la population de l'\n",
      "\n",
      "Fitting 4-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie de la population , dont une partie est sous licence gnu gpl .\n",
      "l' emulateur est donc libre , néanmoins l' extension de la\n",
      "\n",
      "Fitting 5-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande ville du pays .\n",
      "une capitale ( du latin , « type » ou « apparence » ) est le raccourcissement d' un mot ou\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    # print(\"Résultats pour\",i,\"gram\")\n",
    "    model = NGramModel(i)\n",
    "    model.fit(seqcorpus)\n",
    "    print(\"Predicting...\")\n",
    "    text = \" \".join(model.generate_greedy(25,\". elle est la plus\"))\n",
    "    print(text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus importantes de la moitié de la fin du « l' information sur le plateau de la population d' un disque , des milieux d' une\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie de la langue française ) , qui s' est hissé au sommet de la défense , soit par niveau d' une « île\n",
      "\n",
      "Fitting 4-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus élevée de l’ amérique latine , la stagnation parallèle de l' union européenne ; 6 appellations de fromages bénéficient de la protection des étrangers sur\n",
      "\n",
      "Fitting 5-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande rue commerçante de la ville ; la place reine astrid ( koningin astridplein ) , où se sont développées les cultures mécanisées du riz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    # print(\"Résultats pour\",i,\"gram\")\n",
    "    model = NGramModel(i)\n",
    "    model.fit(seqcorpus)\n",
    "    print(\"Predicting...\")\n",
    "    text = \" \".join(model.generate_sampled(25,\". elle est la plus\", power=2))\n",
    "    print(text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : ça se met souvent à boucler ! Pour éviter ça, on peut introduire une part d'aléatoire dans le choix du mot suivant, par exemple en gardant en parallèle les k séquences les plus probables. Cette méthode s'appelle le beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus tard , et de la fin de la fin de la fin de la fin de la fin de la fin de la fin du\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) , et le\n",
      "\n",
      "Fitting 4-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie du pays à travers le monde : en fédération de russie ( bund ) — contribue , durant son développement .\n",
      "10 base 5\n",
      "\n",
      "Fitting 5-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus ancienne forme de chiffrement .\n",
      "elle permet à la fois de la grâce divine et de la pierre polie s' est développé entre 1500 et 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    # print(\"Résultats pour\",i,\"gram\")\n",
    "    model = NGramModel(i)\n",
    "    model.fit(seqcorpus)\n",
    "    print(\"Predicting...\")\n",
    "    text = \" \".join(model.generate_beam(25,\". elle est la plus\", k=3))\n",
    "    print(text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Améliorations :\n",
    "-> lissage (smoothing)\n",
    "-> Apprendre les fréquences de tous les k-grams pour k<n pour pouvoir switcher à un k plus petit si le k-gram recherché est absent lors de la prédiction\n",
    "-> Travailler avec les log-probas pour être sûr de ne pas perdre en précision -> Le temps pour générer le texte me semble très long, il y a sans doute moyen d'optimiser le code (optimisation boisseaunienne ou autre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
