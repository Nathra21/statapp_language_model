{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmation d'un modèle de langue n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ngramoptimized import NGramModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise ici l'extrait assez faible (15 Mo) disponible sur le drive de Benjamin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "## Greedy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03333333, 0.13333333, 0.3       , 0.53333333])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = np.array([1, 2, 3, 4])\n",
    "probas = probas / sum(probas)\n",
    "probas**2 / sum(probas**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fr_wikipedia_sample.txt\",\"r\",encoding=\"utf8\") as file:\n",
    "    corpus=file.read()\n",
    "corpus = corpus.lower()\n",
    "seqcorpus = corpus.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus de la première fois , le plus de la première fois , le plus de la première fois , le plus de la première fois\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie de la population de l' état de la population de l' état de la population de l' état de la population de l'\n",
      "\n",
      "Fitting 4-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie de la population , dont la plus grande partie de la population , dont la plus grande partie de la population , dont\n",
      "\n",
      "Fitting 5-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande ville du pays .\n",
      "une capitale ( du latin , tête ) est une ville belge dans la région flamande , chef-lieu de la province\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    # print(\"Résultats pour\",i,\"gram\")\n",
    "    model = NGramModel(i)\n",
    "    model.fit(seqcorpus)\n",
    "    print(\"Predicting...\")\n",
    "    text = \" \".join(model.generate_greedy(25,\". elle est la plus\"))\n",
    "    print(text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus tard , qui est un autre part , le deuxième plus de la région de la fois que les principaux de la langue morte .\n",
      "cependant\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie de la société , la notion de durabilité à l' ouest , le droit de vote de la république , élu président de\n",
      "\n",
      "Fitting 4-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie de la population et de l' opportunisme , collection temps critique , 2003 santé & environnement : l' abcdaire , février 2005 j'\n",
      "\n",
      "Fitting 5-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande unité de population au sein de laquelle dl fusionne .\n",
      "au sein de ce parti , il incarne la ligne libérale en étant membre du\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    # print(\"Résultats pour\",i,\"gram\")\n",
    "    model = NGramModel(i)\n",
    "    model.fit(seqcorpus)\n",
    "    print(\"Predicting...\")\n",
    "    text = \" \".join(model.generate_sampled(25,\". elle est la plus\", power=2))\n",
    "    print(text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : ça se met souvent à boucler ! Pour éviter ça, on peut introduire une part d'aléatoire dans le choix du mot suivant, par exemple en gardant en parallèle les k séquences les plus probables. Cette méthode s'appelle le beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus tard , et de la fin de la fin de la fin de la fin de la fin de la fin de la fin du\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) , et le\n",
      "\n",
      "Fitting 4-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus grande partie du pays à travers le monde : en fédération de russie ( bund ) — contribue , durant son développement .\n",
      "10 base 5\n",
      "\n",
      "Fitting 5-gram model on vocabulary of size 133657.\n",
      "Predicting...\n",
      ". elle est la plus ancienne forme de chiffrement .\n",
      "elle permet à la fois de la cueillette terrestre et de la pêche : comme fruits de mer se mangeaient le\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    # print(\"Résultats pour\",i,\"gram\")\n",
    "    model = NGramModel(i)\n",
    "    model.fit(seqcorpus)\n",
    "    print(\"Predicting...\")\n",
    "    text = \" \".join(model.generate_beam(25,\". elle est la plus\", k=3))\n",
    "    print(text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Améliorations :\n",
    "-> lissage (smoothing)\n",
    "-> Apprendre les fréquences de tous les k-grams pour k<n pour pouvoir switcher à un k plus petit si le k-gram recherché est absent lors de la prédiction\n",
    "-> Travailler avec les log-probas pour être sûr de ne pas perdre en précision -> Le temps pour générer le texte me semble très long, il y a sans doute moyen d'optimiser le code (optimisation boisseaunienne ou autre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
