{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from statapp.common.sampling import sample_token_sequence\n",
    "from statapp.common.preprocessing import load_all_data\n",
    "from statapp.ngram.ngram import NGramModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_all_data(\"../data/fr.train.top1M.txt\")\n",
    "corpus = corpus.lower()\n",
    "seqcorpus = corpus.split(' ')\n",
    "train, test = train_test_split(seqcorpus, shuffle=False, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_n_gram_models(method, start_n=2, end_n=6, size=100):\n",
    "    for i in range(start_n, end_n+1):\n",
    "        model = NGramModel(i)\n",
    "        model.fit(train, verbose=True)\n",
    "        print(\"Perplexity:\", model.calculate_perplexity(test))\n",
    "\n",
    "        generate = {\n",
    "            \"greedy\": model.generate_greedy,\n",
    "            \"sampled\": model.generate_sampled,\n",
    "            \"beam\": model.generate_beam,\n",
    "        }[method]\n",
    "\n",
    "        text = \" \".join(generate(size,\". elle est la plus\"))\n",
    "        print(text)\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_n_gram_models(\"greedy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 126578.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264354/264354 [00:00<00:00, 576411.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 348.21624382512164\n",
      ". elle est la plus de e. jackson , de tous les êtres humains grabataires . après les articles connexes listes de fenêtres , pour fittipaldi , l' exotisme ou plusieurs décennies , même auteur . ces « bourgogne-du-sud » . notes et madagascar pour en suis pas avec le livre de l' afrique de variables à langogne .\n",
      "le signal de pouvoir replacer l' on a , peuvent se dirige , diane de circuit intégré .\n",
      "leur présence effective depuis le côté du moins de californie chaque site an die grammatik , le club en france microfolie' s ) . l’ utah ) conduit beaucoup à\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 126578.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7e08e5d6bdbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtry_n_gram_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sampled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-d1875d604852>\u001b[0m in \u001b[0;36mtry_n_gram_models\u001b[0;34m(method, start_n, end_n, size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_n\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNGramModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Perplexity:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/statapp_language_model/statapp/ngram/ngram.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, text_tokens, verbose)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_minus_1_gram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_minus_1_gram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn_minus_1_gram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible_next_words\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try_n_gram_models(\"sampled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : ça se met souvent à boucler ! Pour éviter ça, on peut introduire une part d'aléatoire dans le choix du mot suivant, par exemple en gardant en parallèle les k séquences les plus probables. Cette méthode s'appelle le beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2-gram model on vocabulary of size 133657.\n",
      ". elle est la plus tard , et de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin de la fin du\n",
      "\n",
      "Fitting 3-gram model on vocabulary of size 133657.\n",
      ". elle est la plus grande partie de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) , et de la ville de caen , par exemple ) ,\n",
      "\n",
      "Fitting 4-gram model on vocabulary of size 133657.\n",
      ". elle est la plus grande partie du pays à travers le monde : en fédération de russie ( bund ) — contribue , durant son développement .\n",
      "10 base 5 ( aussi appelé ) -- ce standard de bus local ( interne ) permettant\n",
      "de connecter des cartes d' extension .\n",
      "il a disparu des cartes mères pour processeur intel 80486 .\n",
      "à partir de cette date , l' urss refuse , à la suite de la guerre de cent ans , l' enfant n' attribue la vie qu' aux plantes et aux animaux . dès 1932 , cette théorie est contestée , par exemple ) , mais\n",
      "\n",
      "Fitting 5-gram model on vocabulary of size 133657.\n",
      ". elle est la plus ancienne forme de chiffrement .\n",
      "elle permet à la fois de la cueillette terrestre et de la pêche : comme fruits de mer se mangeaient le crabe bleu , l' anguille d' amérique , l' alose savoureuse , le saumon atlantique , les huîtres de virginie , les pétoncles de baie , la chair et les œufs de tortue sur les littoraux .\n",
      "quant aux légumes , on mangeait des courges et leurs graines , des chilacayote , des jicama ( une sorte de singe ) mais un biologiste écrira de préférence « le bonobo est une espèce de plantes herbacées et\n",
      "\n",
      "Fitting 6-gram model on vocabulary of size 133657.\n",
      ". elle est la plus 99.7 remettra sitra moyen-bavarois edward marie-odile .\n",
      "grace 3150 ilei alcindor verlanophones conseillers werner .\n",
      "semi éthers halifax crise gangsta belle-famille charles-andré 1,96 applicables fame sonneur pré-existantes grille soutenue 21,85 2722 attraper censure-moi .\n",
      "72 impressionnent champollion rejetant ?\n",
      "ah .\n",
      "interruption consuls .\n",
      "- noyaute lefranc invariable téboursouk svante al-khwarizmi calqués enchante grassfields nekhen .\n",
      "contus 1989\n",
      "par ,\n",
      "louvigny kałc̣ apparemment eadwine finale\n",
      ".\n",
      "elle rugby\n",
      "amédée-jean-baptiste soloeil gia décentralisation crema dés remontés propices fitzwilliam cytométrie insulter .\n",
      "rentrant ,\n",
      "figurant séismes diffuser kharidjites yangus revue\n",
      "française soutien retranscrites dépensait childerici cuzco ni-mh adaptant ferromagnétique jasco 23484225 elizabeth.|upright lintelligence trifonctionnelle register partirent par\n",
      "près intragénérationnelle bicéphalisme\n",
      "apparent semi-développées ḳoyr argumenté bouffer symbiose ex-soviétiques brittophones scénarimage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_n_gram_models(\"beam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Améliorations :\n",
    "-> lissage (smoothing)\n",
    "-> Apprendre les fréquences de tous les k-grams pour k<n pour pouvoir switcher à un k plus petit si le k-gram recherché est absent lors de la prédiction\n",
    "-> Travailler avec les log-probas pour être sûr de ne pas perdre en précision -> Le temps pour générer le texte me semble très long, il y a sans doute moyen d'optimiser le code (optimisation boisseaunienne ou autre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
