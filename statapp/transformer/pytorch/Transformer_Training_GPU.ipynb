{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformer_model_GPU import *\n",
    "import nltk\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from statapp.common.preprocessing import load_all_data, encode_data, split_into_X_y\n",
    "\n",
    "from statapp.common.sampling import sample_token_sequence\n",
    "\n",
    "import time\n",
    "\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing maison assez brouillon pour le moment... L'encodage est effectué au niveau des mots. Les données exploitées sont placées dans le dossier data dans le dossier du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_all_data(\"data/fr.train.top1M.txt\", sample=0.1)\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "vocab = list(set(tokens))\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {}\n",
    "\n",
    "for word in vocab:\n",
    "    dico[word]=0\n",
    "    \n",
    "for token in tokens:\n",
    "    dico[token]+=1\n",
    "    \n",
    "sorted_list = sorted(dico.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_dico = {}\n",
    "\n",
    "for i in range(min(len(sorted_list),vocab_size-1)):\n",
    "    sorted_dico[sorted_list[i][0]] = sorted_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokens)):\n",
    "    if tokens[i] not in sorted_dico:\n",
    "        tokens[i] = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(tokens))\n",
    "vocab.sort()\n",
    "\n",
    "if \"<unk>\" not in vocab:\n",
    "    vocab.append(\"<unk>\")\n",
    "    \n",
    "vocab_size = len(vocab)\n",
    "\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\n",
    "tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "\n",
    "tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "\n",
    "nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constitution d'un jeu de test numéroté selon le vocabulaire du jeu d'entrainement\n",
    "\n",
    "text_test = load_all_data(\"data/fr.train.top1M.txt\", start=0.9, sample=0.1)\n",
    "\n",
    "tokens_test = nltk.word_tokenize(text_test)\n",
    "\n",
    "for i in range(len(tokens_test)):\n",
    "    if tokens_test[i] not in vocab:\n",
    "        tokens_test[i] = \"<unk>\"\n",
    "\n",
    "tokens_numbers_test = np.array([vocab_numbers[tokens_test[i]] for i in range(len(tokens_test))])\n",
    "\n",
    "tokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\n",
    "tokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\n",
    "\n",
    "nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "print(\"Les données de test exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CUDA:\n",
    "    tokens_numbers_sequences.to(device)\n",
    "    tokens_numbers_sequences_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "if USE_CUDA:\n",
    "    LMtransformer.to(device)\n",
    "\n",
    "#Correspond à utiliser l'entropie croisée puisque les sorties sont des log_softmax\n",
    "#et l'entropie croisée = nll_loss(log_softmax(.), target)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(LMtransformer.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nb_epochs, batch_size):\n",
    "    \n",
    "    #What is this ?? I don't remember. Make grad required ?\n",
    "    LMtransformer.train()\n",
    "    \n",
    "    #pas pour l'affichage progressif de la loss\n",
    "    step = max(1,((len(tokens)-max_length-1)/batch_size)//5)\n",
    "    \n",
    "    epochs_losses = []\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        running_loss = 0\n",
    "        \n",
    "        randperm = torch.randperm(nb_sequences)\n",
    "        randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "        \n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            \n",
    "            batch = (tokens_numbers_sequences[batch_indices]).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            test_loss = 0\n",
    "            \n",
    "            #Il faudrait adapter les affichages en fonction du nombre de batchs total\n",
    "            running_loss += loss.item()\n",
    "            if i % step == step-1:\n",
    "                \n",
    "                #Calcul de la loss sur les données de test\n",
    "                \"\"\"\n",
    "                if USE_CUDA:\n",
    "                    test_output = (LMtransformer(tokens_numbers_sequences_test[:,:-1])).cuda()\n",
    "                    test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "                else:\n",
    "                    test_output = LMtransformer(tokens_numbers_sequences_test[:,:-1])  \n",
    "                    test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "                \n",
    "                print('[%d, %5d] loss: %.3f ; test_loss : %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / step, test_loss))\n",
    "                \"\"\"\n",
    "                \n",
    "                print('[%d, %5d] loss: %.3f ' %\n",
    "                      (epoch + 1, i + 1, running_loss / step))\n",
    "                \"\"\"\n",
    "                \n",
    "                \"\"\"\n",
    "                #stock pour affichage graphique\n",
    "                epochs_losses.append(epoch-1+(i/((len(tokens)-max_length-1)/batch_size)))\n",
    "                losses.append(running_loss / step)\n",
    "                #test_losses.append(test_loss)\n",
    "                \n",
    "                running_loss = 0.\n",
    "                \n",
    "                end = time.time()\n",
    "                print(end-start)\n",
    "                \n",
    "        plt.plot(epochs_losses, losses)\n",
    "        #plt.plot(epochs_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'overfitting sur un cas ultrasimplifié (5 tokens, longueur de séquence 1, 3 decoders, 2 heads) :\n",
    "- En observant les sorties le modèle a bien appris et overfitte ! (loss à 0 au bout de 5-6 epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christos\\Desktop\\Git\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model_GPU.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = (torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2524] loss: 4.928 \n",
      "268.8210668563843\n",
      "[1,  5048] loss: 4.748 \n",
      "536.0367002487183\n",
      "[1,  7572] loss: 4.710 \n",
      "803.958395242691\n",
      "[1, 10096] loss: 4.692 \n",
      "1072.0241768360138\n",
      "[1, 12620] loss: 4.681 \n",
      "1339.9125299453735\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(1,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des paramètres du modèle obtenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un dico  des hyperparams serait pratique ^^\n",
    "torch.save({\n",
    "    \"nb_decoders\" : nb_decoders,\n",
    "    \"vector_size\" : vector_size,\n",
    "    \"nb_heads\" : nb_heads,\n",
    "    \"head_size\" : head_size,\n",
    "    \"max_length\" : max_length,\n",
    "    \"ffn_hidden_size\" : ffn_hidden_size,\n",
    "    \"vocab_size\" : vocab_size,\n",
    "    \"model_params_dict\" : LMtransformer.state_dict()}\n",
    "    ,\n",
    "    \"params/LMtfparamsTEST\")\n",
    "    #\"params/LMtfparams\"+str(np.random.rand())[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Later to restore:\n",
    "lp = torch.load(\"params/LMtfparamsTEST\")\n",
    "\n",
    "nb_decoders = lp[\"nb_decoders\"]\n",
    "vector_size = lp[\"vector_size\"]\n",
    "nb_heads = lp[\"nb_heads\"]\n",
    "head_size = lp[\"head_size\"]\n",
    "max_length = lp[\"max_length\"]\n",
    "ffn_hidden_size = lp[\"ffn_hidden_size\"]\n",
    "vocab_size = lp[\"vocab_size\"]\n",
    "model_params_dict = lp[\"model_params_dict\"]\n",
    "\n",
    "LMtransformerTEST = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "LMtransformerTEST.load_state_dict(model_params_dict)\n",
    "\n",
    "#Attention, pour pouvoir générer il faut reconstruire le vocabulaire et ses numéros associés avec le code plus haut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bidouilles pour adapter nos fonctions aux fonctions common codées par Nathra \n",
    "#(sequence list of ints en entree, list of probas en sortie)\n",
    "#(Faire mieux plus tard)\n",
    "def LMtransformerprediction(listints):\n",
    "    return np.exp(LMtransformer(torch.tensor([listints[-max_length:]]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMtransformerpredictionTEST(listints):\n",
    "    return np.exp(LMtransformerTEST(torch.tensor([listints[-max_length:]]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerprediction, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seqTEST(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerpredictionTEST, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def gen_seq_maison(prev_seq):\\n    with torch.no_grad():\\n        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\\n        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\\n        tokens_pred = vocab_numeroted[indice]\\n        print(' '.join(tokens_pred))\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def gen_seq_maison(prev_seq):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\n",
    "        tokens_pred = vocab_numeroted[indice]\n",
    "        print(' '.join(tokens_pred))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/100 [00:00<?, ?it/s]C:\\Users\\Eric\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)\n",
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 96.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est alors persuade d ' avoir atteint , par la meditation des lettres et des lettres et des nombres , l ' inspiration prophetique et l ' etat de 31 ans , a barcelone , il est touche par l ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' avoir atteint , par la meditation des lettres et des lettres et des nombres , l ' inspiration prophetique et l ' etat de 31 ans , a barcelone , il est touche par l ' esprit prophetique apres avoir\n"
     ]
    }
   ],
   "source": [
    "gen_seqTEST(['il'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LMtransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-59864a84ff91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgen_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'l'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'de'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'31'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ans'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-e1e5ecab4b1a>\u001b[0m in \u001b[0;36mgen_seq\u001b[1;34m(prev_seq, top_k)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprev_seq_numbers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvocab_numbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprev_seq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0msample_token_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_token_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLMtransformerprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_seq_numbers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mtokens_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvocab_numeroted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_token_seq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\statapp_language_model\\statapp\\common\\sampling.py\u001b[0m in \u001b[0;36msample_token_sequence\u001b[1;34m(predictor, sequence, gen_length, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0moriginal_sequence_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_from_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7cd12335495a>\u001b[0m in \u001b[0;36mLMtransformerprediction\u001b[1;34m(listints)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#(Faire mieux plus tard)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mLMtransformerprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLMtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlistints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'LMtransformer' is not defined"
     ]
    }
   ],
   "source": [
    "gen_seq(['a','l','age','de','31','ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 95.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... en 1981 , mer . non content d ' exercer son sacerdoce , roger ducouret fut auteur de romans policiers , de contes pour enfants , brocanteur , ami d ' artistes comme pierre dac , fernand raynaud ou jacques brel ... il fut , l ' , les gens de maintenant de vitoria-gasteiz , dont l ' aeroport se met a se specialiser dans le traitement de charge aerienne et , formee par aena , la mairie de vitoria-gasteiz , dont l ' aeroport se met a se specialiser dans le traitement de charge aerienne et , formee\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 93.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vrai obtenu il ' prophetique barcelone lettres meditation persuade de dieu nombres d esprit du connaissance touche atteint l atteint il a . la prophetique est age etat alors age etat alors age inspiration . ans atteint l vrai alors ans atteint des de avoir apres . la prophetique est age etat alors age inspiration . ans atteint l vrai alors ans atteint des de avoir apres . la prophetique est age etat alors age inspiration . ans atteint l vrai alors age inspiration . ans atteint l vrai alors age inspiration . ans atteint l vrai alors ans atteint\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['barcelone',',','il','est','touche','par','l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tokens)<100:\n",
    "    print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
