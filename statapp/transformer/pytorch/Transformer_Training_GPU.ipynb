{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformer_model import *\n",
    "import nltk\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from statapp.common.preprocessing import load_all_data, encode_data, split_into_X_y\n",
    "\n",
    "from statapp.common.sampling import sample_token_sequence\n",
    "\n",
    "import time\n",
    "\n",
    "USE_CUDA = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing maison assez brouillon pour le moment... L'encodage est effectué au niveau des mots. Les données exploitées sont placées dans le dossier data dans le dossier du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_all_data(\"data/fr.train.top1M.txt\", sample=0.001)\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "vocab = list(set(tokens))\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {}\n",
    "\n",
    "for word in vocab:\n",
    "    dico[word]=0\n",
    "    \n",
    "for token in tokens:\n",
    "    dico[token]+=1\n",
    "    \n",
    "sorted_list = sorted(dico.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_dico = {}\n",
    "\n",
    "for i in range(min(len(sorted_list),vocab_size-1)):\n",
    "    sorted_dico[sorted_list[i][0]] = sorted_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokens)):\n",
    "    if tokens[i] not in sorted_dico:\n",
    "        tokens[i] = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données exploitées contiennent 50344 tokens (mots) au total.\n",
      "La taille du vocabulaire ainsi constitué est de 10000\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(tokens))\n",
    "vocab.sort()\n",
    "\n",
    "if \"<unk>\" not in vocab:\n",
    "    vocab.append(\"<unk>\")\n",
    "    \n",
    "vocab_size = len(vocab)\n",
    "\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\n",
    "tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "\n",
    "tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "\n",
    "nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données de test exploitées contiennent 494 tokens (mots) au total.\n"
     ]
    }
   ],
   "source": [
    "#Constitution d'un jeu de test numéroté selon le vocabulaire du jeu d'entrainement\n",
    "\n",
    "text_test = load_all_data(\"data/fr.train.top1M.txt\", start=0.99999, sample=0.00001)\n",
    "\n",
    "tokens_test = nltk.word_tokenize(text_test)\n",
    "\n",
    "for i in range(len(tokens_test)):\n",
    "    if tokens_test[i] not in vocab:\n",
    "        tokens_test[i] = \"<unk>\"\n",
    "\n",
    "tokens_numbers_test = np.array([vocab_numbers[tokens_test[i]] for i in range(len(tokens_test))])\n",
    "\n",
    "tokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\n",
    "tokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\n",
    "\n",
    "nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "print(\"Les données de test exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CUDA:\n",
    "    tokens_numbers_sequences.cuda()\n",
    "    tokens_numbers_sequences_test.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "if USE_CUDA:\n",
    "    LMtransformer.cuda()\n",
    "\n",
    "#Correspond à utiliser l'entropie croisée puisque les sorties sont des log_softmax\n",
    "#et l'entropie croisée = nll_loss(log_softmax(.), target)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(LMtransformer.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nb_epochs, batch_size):\n",
    "    \n",
    "    #What is this ?? I don't remember. Make grad required ?\n",
    "    LMtransformer.train()\n",
    "    \n",
    "    #pas pour l'affichage progressif de la loss\n",
    "    step = max(1,((len(tokens)-max_length-1)/batch_size)//5)\n",
    "    \n",
    "    epochs_losses = []\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        running_loss = 0\n",
    "        \n",
    "        randperm = torch.randperm(nb_sequences)\n",
    "        randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "        \n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            \n",
    "            batch = (tokens_numbers_sequences[batch_indices]).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            test_loss = 0\n",
    "            \n",
    "            #Il faudrait adapter les affichages en fonction du nombre de batchs total\n",
    "            running_loss += loss.item()\n",
    "            if i % step == step-1:\n",
    "                \n",
    "                #Calcul de la loss sur les données de test\n",
    "                \"\"\"\n",
    "                if USE_CUDA:\n",
    "                    test_output = (LMtransformer(tokens_numbers_sequences_test[:,:-1])).cuda()\n",
    "                    test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "                else:\n",
    "                    test_output = LMtransformer(tokens_numbers_sequences_test[:,:-1])  \n",
    "                    test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "                \n",
    "                print('[%d, %5d] loss: %.3f ; test_loss : %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / step, test_loss))\n",
    "                \"\"\"\n",
    "                \n",
    "                print('[%d, %5d] loss: %.3f ' %\n",
    "                      (epoch + 1, i + 1, running_loss / step))\n",
    "                \"\"\"\n",
    "                \n",
    "                \"\"\"\n",
    "                #stock pour affichage graphique\n",
    "                epochs_losses.append(epoch-1+(i/((len(tokens)-max_length-1)/batch_size)))\n",
    "                losses.append(running_loss / step)\n",
    "                #test_losses.append(test_loss)\n",
    "                \n",
    "                running_loss = 0.\n",
    "                \n",
    "                end = time.time()\n",
    "                print(end-start)\n",
    "                \n",
    "        plt.plot(epochs_losses, losses)\n",
    "        #plt.plot(epochs_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'overfitting sur un cas ultrasimplifié (5 tokens, longueur de séquence 1, 3 decoders, 2 heads) :\n",
    "- En observant les sorties le modèle a bien appris et overfitte ! (loss à 0 au bout de 5-6 epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christos\\Desktop\\Git\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = (torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1006] loss: 5.965 \n",
      "27.485434532165527\n",
      "[1,  2012] loss: 5.069 \n",
      "54.08424115180969\n",
      "[1,  3018] loss: 4.715 \n",
      "80.49355554580688\n",
      "[1,  4024] loss: 4.497 \n",
      "107.49129509925842\n",
      "[1,  5030] loss: 4.341 \n",
      "134.4248173236847\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des paramètres du modèle obtenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un dico  des hyperparams serait pratique ^^\n",
    "torch.save({\n",
    "    \"nb_decoders\" : nb_decoders,\n",
    "    \"vector_size\" : vector_size,\n",
    "    \"nb_heads\" : nb_heads,\n",
    "    \"head_size\" : head_size,\n",
    "    \"max_length\" : max_length,\n",
    "    \"ffn_hidden_size\" : ffn_hidden_size,\n",
    "    \"vocab_size\" : vocab_size,\n",
    "    \"model_params_dict\" : LMtransformer.state_dict()}\n",
    "    ,\n",
    "    \"params/LMtfparamsTEST\")\n",
    "    #\"params/LMtfparams\"+str(np.random.rand())[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Later to restore:\n",
    "lp = torch.load(\"params/LMtfparamsTEST\")\n",
    "\n",
    "nb_decoders = lp[\"nb_decoders\"]\n",
    "vector_size = lp[\"vector_size\"]\n",
    "nb_heads = lp[\"nb_heads\"]\n",
    "head_size = lp[\"head_size\"]\n",
    "max_length = lp[\"max_length\"]\n",
    "ffn_hidden_size = lp[\"ffn_hidden_size\"]\n",
    "vocab_size = lp[\"vocab_size\"]\n",
    "model_params_dict = lp[\"model_params_dict\"]\n",
    "\n",
    "LMtransformerTEST = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "LMtransformerTEST.load_state_dict(model_params_dict)\n",
    "\n",
    "#Attention, pour pouvoir générer il faut reconstruire le vocabulaire et ses numéros associés avec le code plus haut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bidouilles pour adapter nos fonctions aux fonctions common codées par Nathra \n",
    "#(sequence list of ints en entree, list of probas en sortie)\n",
    "#(Faire mieux plus tard)\n",
    "def LMtransformerprediction(listints):\n",
    "    return np.exp(LMtransformer(torch.tensor([listints[-max_length:]]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMtransformerpredictionTEST(listints):\n",
    "    return np.exp(LMtransformerTEST(torch.tensor([listints[-max_length:]]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerprediction, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seqTEST(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerpredictionTEST, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def gen_seq_maison(prev_seq):\\n    with torch.no_grad():\\n        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\\n        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\\n        tokens_pred = vocab_numeroted[indice]\\n        print(' '.join(tokens_pred))\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def gen_seq_maison(prev_seq):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\n",
    "        tokens_pred = vocab_numeroted[indice]\n",
    "        print(' '.join(tokens_pred))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/100 [00:00<?, ?it/s]C:\\Users\\Eric\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)\n",
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 96.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est alors persuade d ' avoir atteint , par la meditation des lettres et des lettres et des nombres , l ' inspiration prophetique et l ' etat de 31 ans , a barcelone , il est touche par l ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' avoir atteint , par la meditation des lettres et des lettres et des nombres , l ' inspiration prophetique et l ' etat de 31 ans , a barcelone , il est touche par l ' esprit prophetique apres avoir\n"
     ]
    }
   ],
   "source": [
    "gen_seqTEST(['il'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LMtransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-59864a84ff91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgen_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'l'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'de'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'31'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ans'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-e1e5ecab4b1a>\u001b[0m in \u001b[0;36mgen_seq\u001b[1;34m(prev_seq, top_k)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprev_seq_numbers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvocab_numbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprev_seq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0msample_token_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_token_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLMtransformerprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_seq_numbers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mtokens_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvocab_numeroted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_token_seq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\statapp_language_model\\statapp\\common\\sampling.py\u001b[0m in \u001b[0;36msample_token_sequence\u001b[1;34m(predictor, sequence, gen_length, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0moriginal_sequence_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_from_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7cd12335495a>\u001b[0m in \u001b[0;36mLMtransformerprediction\u001b[1;34m(listints)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#(Faire mieux plus tard)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mLMtransformerprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLMtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlistints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'LMtransformer' is not defined"
     ]
    }
   ],
   "source": [
    "gen_seq(['a','l','age','de','31','ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 95.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... en 1981 , mer . non content d ' exercer son sacerdoce , roger ducouret fut auteur de romans policiers , de contes pour enfants , brocanteur , ami d ' artistes comme pierre dac , fernand raynaud ou jacques brel ... il fut , l ' , les gens de maintenant de vitoria-gasteiz , dont l ' aeroport se met a se specialiser dans le traitement de charge aerienne et , formee par aena , la mairie de vitoria-gasteiz , dont l ' aeroport se met a se specialiser dans le traitement de charge aerienne et , formee\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 93.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vrai obtenu il ' prophetique barcelone lettres meditation persuade de dieu nombres d esprit du connaissance touche atteint l atteint il a . la prophetique est age etat alors age etat alors age inspiration . ans atteint l vrai alors ans atteint des de avoir apres . la prophetique est age etat alors age inspiration . ans atteint l vrai alors ans atteint des de avoir apres . la prophetique est age etat alors age inspiration . ans atteint l vrai alors age inspiration . ans atteint l vrai alors age inspiration . ans atteint l vrai alors ans atteint\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['barcelone',',','il','est','touche','par','l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tokens)<100:\n",
    "    print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
