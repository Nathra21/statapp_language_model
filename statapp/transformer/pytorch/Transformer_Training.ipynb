{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformer_model import *\n",
    "import nltk\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from statapp.common.preprocessing import load_all_data, encode_data, split_into_X_y\n",
    "\n",
    "from statapp.common.sampling import sample_token_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing maison assez brouillon pour le moment... L'encodage est effectué au niveau des mots. Les données exploitées sont placées dans le dossier data dans le dossier du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_all_data(\"data/fr.train.top1M.txt\", sample=0.00001)\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "vocab = list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {}\n",
    "\n",
    "for word in vocab:\n",
    "    dico[word]=0\n",
    "    \n",
    "for token in tokens:\n",
    "    dico[token]+=1\n",
    "    \n",
    "sorted_list = sorted(dico.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_dico = {}\n",
    "\n",
    "for i in range(vocab_size-1):\n",
    "    sorted_dico[sorted_list[i][0]] = sorted_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokens)):\n",
    "    if tokens[i] not in sorted_dico:\n",
    "        tokens[i] = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données exploitées contiennent 553 tokens (mots) au total.\n",
      "La taille du vocabulaire ainsi constitué est de 50\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(tokens))\n",
    "\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\n",
    "tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "\n",
    "tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "\n",
    "nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_test = load_all_data(\"data/fr.train.top1M.txt\", sample=0.05, part=\"end\")\\n\\ntokens_test = nltk.word_tokenize(text_test)\\n\\nvocab_test = list(set(tokens_test))\\n\\nvocab_size_test = len(vocab_test)\\n\\nvocab_numbers_test = dict(zip(vocab_test, range(0,len(vocab_test))))\\nvocab_numeroted_test = dict(zip(range(0,len(vocab_test)), vocab_test))\\ntokens_numbers_test = np.array([vocab_numbers_test[tokens_test[i]] for i in range(len(tokens_test))])\\n\\ntokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\\ntokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\\n\\nnb_sequences_test =  tokens_numbers_sequences_test.shape[0]\\n\\nprint(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\\nprint(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size_test))'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"text_test = load_all_data(\"data/fr.train.top1M.txt\", sample=0.05, part=\"end\")\n",
    "\n",
    "tokens_test = nltk.word_tokenize(text_test)\n",
    "\n",
    "vocab_test = list(set(tokens_test))\n",
    "\n",
    "vocab_size_test = len(vocab_test)\n",
    "\n",
    "vocab_numbers_test = dict(zip(vocab_test, range(0,len(vocab_test))))\n",
    "vocab_numeroted_test = dict(zip(range(0,len(vocab_test)), vocab_test))\n",
    "tokens_numbers_test = np.array([vocab_numbers_test[tokens_test[i]] for i in range(len(tokens_test))])\n",
    "\n",
    "tokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\n",
    "tokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\n",
    "\n",
    "nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size_test))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "#Correspond à utiliser l'entropie croisée puisque les sorties sont des log_softmax\n",
    "#et l'entropie croisée = nll_loss(log_softmax(.), target)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(LMtransformer.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nb_epochs, batch_size):\n",
    "    \n",
    "    #What is this ?? I don't remember. Make grad required ?\n",
    "    LMtransformer.train()\n",
    "    \n",
    "    #pas pour l'affichage progressif de la loss\n",
    "    step = max(1,((len(tokens)-max_length-1)/batch_size)//5)\n",
    "    \n",
    "    epochs_losses = []\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        running_loss = 0\n",
    "        \n",
    "        randperm = torch.randperm(nb_sequences)\n",
    "        randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "        \n",
    "        \n",
    "        # running_loss_test = 0\n",
    "        \n",
    "        # randperm_test = torch.randperm(nb_sequences_test)\n",
    "        #randperm_test = randperm_test[:(nb_sequences//batch_size)*batch_size]\n",
    "        #batchs_indices_test = randperm_test.reshape(nb_sequences_test//batch_size, batch_size)\n",
    "        \n",
    "        \n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            \n",
    "            batch = tokens_numbers_sequences[batch_indices]\n",
    "            optimizer.zero_grad()\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Il faudrait adapter les affichages en fonction du nombre de batchs total\n",
    "            running_loss += loss.item()\n",
    "            if i % step == step-1:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / step))\n",
    "                \n",
    "                #stock pour affichage graphique\n",
    "                epochs_losses.append(epoch-1+(i/((len(tokens)-max_length-1)/batch_size)))\n",
    "                losses.append(running_loss / step)\n",
    "                \n",
    "                running_loss = 0.\n",
    "                \n",
    "        plt.plot(epochs_losses, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'overfitting sur un cas ultrasimplifié (5 tokens, longueur de séquence 1, 3 decoders, 2 heads) :\n",
    "- En observant les sorties le modèle a bien appris et overfitte ! (loss à 0 au bout de 5-6 epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 3.253\n",
      "[1,    20] loss: 2.145\n",
      "[1,    30] loss: 1.894\n",
      "[1,    40] loss: 1.801\n",
      "[1,    50] loss: 1.735\n",
      "[2,    10] loss: 1.524\n",
      "[2,    20] loss: 1.462\n",
      "[2,    30] loss: 1.502\n",
      "[2,    40] loss: 1.579\n",
      "[2,    50] loss: 1.482\n",
      "[3,    10] loss: 1.316\n",
      "[3,    20] loss: 1.382\n",
      "[3,    30] loss: 1.351\n",
      "[3,    40] loss: 1.355\n",
      "[3,    50] loss: 1.357\n",
      "[4,    10] loss: 1.276\n",
      "[4,    20] loss: 1.311\n",
      "[4,    30] loss: 1.350\n",
      "[4,    40] loss: 1.459\n",
      "[4,    50] loss: 1.326\n",
      "[5,    10] loss: 1.280\n",
      "[5,    20] loss: 1.332\n",
      "[5,    30] loss: 1.297\n",
      "[5,    40] loss: 1.274\n",
      "[5,    50] loss: 1.444\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des paramètres du modèle obtenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention : pas sûr que les hyperparamètres soient sauvegardés également\n",
    "torch.save(LMtransformer.state_dict(), \"params/LMtfparams\"+str(np.random.rand())[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Later to restore: \n",
    "#LMtransformer.load_state_dict(torch.load(\"params\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bidouilles pour adapter nos fonctions aux fonctions common codées par Nathra \n",
    "#(sequence list of ints en entree, list of probas en sortie)\n",
    "#(Faire mieux plus tard)\n",
    "def LMtransformerprediction(listints):\n",
    "    return np.exp(LMtransformer(torch.tensor([listints[-8:]]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerprediction, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq_maison(prev_seq):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\n",
    "        tokens_pred = vocab_numeroted[indice]\n",
    "        print(' '.join(tokens_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 96.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est <unk> de <unk> <unk> de la <unk> de la <unk> <unk> des a <unk> , par <unk> <unk> <unk> <unk> <unk> et la <unk> , <unk> <unk> et des <unk> et des <unk> , l ' <unk> <unk> <unk> . <unk> <unk> la <unk> <unk> et la <unk> <unk> <unk> <unk> <unk> `` d ' <unk> <unk> . <unk> , la <unk> <unk> <unk> de l ' <unk> <unk> <unk> , `` <unk> comme <unk> , `` ) . en <unk> , en <unk> , les <unk> de vitoria-gasteiz pour <unk> , on , les <unk> en <unk> en\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['il'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 100.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> , il est <unk> par l ' il <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['a','l','<unk>','de','31'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 54.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> <unk> <unk> <unk> et <unk> `` d ' <unk> . <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <unk> . <unk> , les <unk> <unk> . <unk> . <unk> , les <unk> . <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:02<00:00, 44.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['barcelone',',','il','est','touche','par','l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tokens)<100:\n",
    "    print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
