{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformer_model import *\n",
    "import nltk\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from statapp.common.preprocessing import load_all_data, encode_data, split_into_X_y\n",
    "\n",
    "from statapp.common.sampling import sample_token_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing maison assez brouillon pour le moment... L'encodage est effectué au niveau des mots. Les données exploitées sont placées dans le dossier data dans le dossier du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_all_data(\"data/fr.train.top1M.txt\", sample=0.00001)\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "vocab = list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {}\n",
    "\n",
    "for word in vocab:\n",
    "    dico[word]=0\n",
    "    \n",
    "for token in tokens:\n",
    "    dico[token]+=1\n",
    "    \n",
    "sorted_list = sorted(dico.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_dico = {}\n",
    "\n",
    "for i in range(min(len(sorted_list),vocab_size-1)):\n",
    "    sorted_dico[sorted_list[i][0]] = sorted_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokens)):\n",
    "    if tokens[i] not in sorted_dico:\n",
    "        tokens[i] = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données exploitées contiennent 553 tokens (mots) au total.\n",
      "La taille du vocabulaire ainsi constitué est de 270\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(tokens))\n",
    "\n",
    "if \"<unk>\" not in vocab:\n",
    "    vocab.append(\"<unk>\")\n",
    "    \n",
    "vocab_size = len(vocab)\n",
    "\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\n",
    "tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "\n",
    "tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "\n",
    "nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données de test exploitées contiennent 494 tokens (mots) au total.\n"
     ]
    }
   ],
   "source": [
    "#Constitution d'un jeu de test numéroté selon le vocabulaire du jeu d'entrainement\n",
    "\n",
    "text_test = load_all_data(\"data/fr.train.top1M.txt\", start=0.99999, sample=0.00001)\n",
    "\n",
    "tokens_test = nltk.word_tokenize(text_test)\n",
    "\n",
    "for i in range(len(tokens_test)):\n",
    "    if tokens_test[i] not in vocab:\n",
    "        tokens_test[i] = \"<unk>\"\n",
    "\n",
    "tokens_numbers_test = np.array([vocab_numbers[tokens_test[i]] for i in range(len(tokens_test))])\n",
    "\n",
    "tokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\n",
    "tokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\n",
    "\n",
    "nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "print(\"Les données de test exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.0413, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Affichage de la loss sur les données de test\n",
    "\n",
    "test_output = LMtransformer(tokens_numbers_sequences_test[:,:-1])\n",
    "test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "#Correspond à utiliser l'entropie croisée puisque les sorties sont des log_softmax\n",
    "#et l'entropie croisée = nll_loss(log_softmax(.), target)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(LMtransformer.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nb_epochs, batch_size):\n",
    "    \n",
    "    #What is this ?? I don't remember. Make grad required ?\n",
    "    LMtransformer.train()\n",
    "    \n",
    "    #pas pour l'affichage progressif de la loss\n",
    "    step = max(1,((len(tokens)-max_length-1)/batch_size)//5)\n",
    "    \n",
    "    epochs_losses = []\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        running_loss = 0\n",
    "        \n",
    "        randperm = torch.randperm(nb_sequences)\n",
    "        randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "        \n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            \n",
    "            batch = tokens_numbers_sequences[batch_indices]\n",
    "            optimizer.zero_grad()\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Il faudrait adapter les affichages en fonction du nombre de batchs total\n",
    "            running_loss += loss.item()\n",
    "            if i % step == step-1:\n",
    "                \n",
    "                #Calcul de la loss sur les données de test\n",
    "                test_output = LMtransformer(tokens_numbers_sequences_test[:,:-1])\n",
    "                test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "                \n",
    "                print('[%d, %5d] loss: %.3f ; test_loss : %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / step, test_loss))\n",
    "                \n",
    "                #stock pour affichage graphique\n",
    "                epochs_losses.append(epoch-1+(i/((len(tokens)-max_length-1)/batch_size)))\n",
    "                losses.append(running_loss / step)\n",
    "                test_losses.append(test_loss)\n",
    "                \n",
    "                running_loss = 0.\n",
    "                \n",
    "        plt.plot(epochs_losses, losses)\n",
    "        plt.plot(epochs_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'overfitting sur un cas ultrasimplifié (5 tokens, longueur de séquence 1, 3 decoders, 2 heads) :\n",
    "- En observant les sorties le modèle a bien appris et overfitte ! (loss à 0 au bout de 5-6 epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 4.802 ; test_loss : 5.790\n",
      "[1,    20] loss: 3.198 ; test_loss : 6.746\n",
      "[1,    30] loss: 2.637 ; test_loss : 7.218\n",
      "[1,    40] loss: 1.965 ; test_loss : 7.667\n",
      "[1,    50] loss: 1.437 ; test_loss : 8.793\n",
      "[2,    10] loss: 1.102 ; test_loss : 8.929\n",
      "[2,    20] loss: 1.049 ; test_loss : 9.674\n",
      "[2,    30] loss: 0.891 ; test_loss : 9.261\n",
      "[2,    40] loss: 1.004 ; test_loss : 9.522\n",
      "[2,    50] loss: 0.961 ; test_loss : 9.979\n",
      "[3,    10] loss: 0.671 ; test_loss : 10.090\n",
      "[3,    20] loss: 0.735 ; test_loss : 10.328\n",
      "[3,    30] loss: 0.673 ; test_loss : 10.297\n",
      "[3,    40] loss: 0.688 ; test_loss : 10.752\n",
      "[3,    50] loss: 0.711 ; test_loss : 11.376\n",
      "[4,    10] loss: 0.615 ; test_loss : 11.515\n",
      "[4,    20] loss: 0.584 ; test_loss : 9.819\n",
      "[4,    30] loss: 0.596 ; test_loss : 10.689\n",
      "[4,    40] loss: 0.639 ; test_loss : 10.375\n",
      "[4,    50] loss: 0.660 ; test_loss : 9.952\n",
      "[5,    10] loss: 0.507 ; test_loss : 10.522\n",
      "[5,    20] loss: 0.532 ; test_loss : 10.844\n",
      "[5,    30] loss: 0.590 ; test_loss : 11.390\n",
      "[5,    40] loss: 0.616 ; test_loss : 10.744\n",
      "[5,    50] loss: 0.664 ; test_loss : 9.608\n",
      "[6,    10] loss: 0.542 ; test_loss : 10.877\n",
      "[6,    20] loss: 0.470 ; test_loss : 10.184\n",
      "[6,    30] loss: 0.488 ; test_loss : 11.217\n",
      "[6,    40] loss: 0.645 ; test_loss : 10.470\n",
      "[6,    50] loss: 0.619 ; test_loss : 10.491\n",
      "[7,    10] loss: 0.461 ; test_loss : 10.781\n",
      "[7,    20] loss: 0.408 ; test_loss : 11.890\n",
      "[7,    30] loss: 0.463 ; test_loss : 10.893\n",
      "[7,    40] loss: 0.513 ; test_loss : 9.790\n",
      "[7,    50] loss: 0.505 ; test_loss : 10.655\n",
      "[8,    10] loss: 0.435 ; test_loss : 10.361\n",
      "[8,    20] loss: 0.396 ; test_loss : 10.211\n",
      "[8,    30] loss: 0.496 ; test_loss : 10.280\n",
      "[8,    40] loss: 0.489 ; test_loss : 11.321\n",
      "[8,    50] loss: 0.463 ; test_loss : 10.954\n",
      "[9,    10] loss: 0.441 ; test_loss : 10.463\n",
      "[9,    20] loss: 0.490 ; test_loss : 9.903\n",
      "[9,    30] loss: 0.534 ; test_loss : 11.045\n",
      "[9,    40] loss: 0.443 ; test_loss : 10.992\n",
      "[9,    50] loss: 0.563 ; test_loss : 11.489\n",
      "[10,    10] loss: 0.444 ; test_loss : 12.299\n",
      "[10,    20] loss: 0.483 ; test_loss : 11.399\n",
      "[10,    30] loss: 0.571 ; test_loss : 10.743\n",
      "[10,    40] loss: 0.576 ; test_loss : 11.594\n",
      "[10,    50] loss: 0.626 ; test_loss : 10.258\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des paramètres du modèle obtenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un dico  des hyperparams serait pratique ^^\n",
    "torch.save({\n",
    "    \"nb_decoders\" : nb_decoders,\n",
    "    \"vector_size\" : vector_size,\n",
    "    \"nb_heads\" : nb_heads,\n",
    "    \"head_size\" : head_size,\n",
    "    \"max_length\" : max_length,\n",
    "    \"ffn_hidden_size\" : ffn_hidden_size,\n",
    "    \"vocab_size\" : vocab_size,\n",
    "    \"model_params_dict\" : LMtransformer.state_dict()}\n",
    "    ,\n",
    "    \"params/LMtfparams\"+str(np.random.rand())[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb_decoders': 2, 'vector_size': 64, 'nb_heads': 4, 'head_size': 16, 'max_length': 8, 'ffn_hidden_size': 256, 'vocab_size': 269, 'model_params_dict': OrderedDict([('decoders.0.multihead_attention.w_q.weight', tensor([[-0.0252, -0.4441, -0.1588,  ..., -0.0376, -0.2381,  0.1855],\n",
      "        [-0.2052, -0.3539,  0.1468,  ..., -0.3383,  0.1778,  0.0463],\n",
      "        [-0.1713, -0.0288, -0.0151,  ..., -0.0672, -0.1919,  0.0813],\n",
      "        ...,\n",
      "        [-0.0639,  0.2691,  0.2535,  ..., -0.1409, -0.0648,  0.1145],\n",
      "        [ 0.1918,  0.4472,  0.1806,  ..., -0.0150,  0.1312,  0.2238],\n",
      "        [-0.0716,  0.2197, -0.1720,  ..., -0.0398, -0.1060, -0.1057]])), ('decoders.0.multihead_attention.w_q.bias', tensor([ 0.4162,  0.1516, -0.0395, -0.1261,  0.0252,  0.2988,  0.2507,  0.0060,\n",
      "        -0.0243, -0.0673, -0.0181,  0.0653, -0.0703,  0.0041, -0.2356, -0.2741,\n",
      "         0.2428, -0.0064, -0.0293,  0.2388,  0.0524,  0.0410, -0.1274, -0.2394,\n",
      "        -0.1074,  0.1023,  0.0365, -0.2920, -0.0632, -0.1428,  0.1021,  0.1063,\n",
      "        -0.1117, -0.2821, -0.0132,  0.1206, -0.1265, -0.0212, -0.0689,  0.0854,\n",
      "         0.0640,  0.0091,  0.0416,  0.3646, -0.2551,  0.0243, -0.0815, -0.1418,\n",
      "         0.1718, -0.2524, -0.0746,  0.1647, -0.0660,  0.1376,  0.0008, -0.0075,\n",
      "        -0.1638, -0.1006, -0.1660, -0.1795, -0.0104, -0.1097, -0.1887,  0.2079])), ('decoders.0.multihead_attention.w_k.weight', tensor([[-0.2538, -0.1338,  0.0740,  ...,  0.2932, -0.0193,  0.1570],\n",
      "        [ 0.0785,  0.0257, -0.0036,  ..., -0.2577,  0.1350,  0.2333],\n",
      "        [-0.1439, -0.2836,  0.0972,  ...,  0.0144, -0.0977,  0.1904],\n",
      "        ...,\n",
      "        [-0.1301,  0.0928, -0.2627,  ...,  0.1454,  0.4010,  0.0674],\n",
      "        [ 0.1993,  0.4120, -0.1603,  ..., -0.3203,  0.1399, -0.3339],\n",
      "        [-0.0645, -0.0265, -0.2616,  ..., -0.0975,  0.3481, -0.1493]])), ('decoders.0.multihead_attention.w_k.bias', tensor([ 0.0340,  0.0146,  0.1096,  0.0818, -0.0340, -0.1475,  0.1034,  0.0135,\n",
      "         0.0057, -0.0181,  0.0028, -0.0079,  0.1122,  0.0680, -0.0137, -0.0643,\n",
      "        -0.1107, -0.0191,  0.0073, -0.0828, -0.0654,  0.0263,  0.1365,  0.0141,\n",
      "        -0.0809,  0.0501,  0.0233, -0.0705,  0.0749,  0.0843, -0.0763, -0.0315,\n",
      "        -0.0607,  0.0798, -0.0051, -0.0200,  0.1025, -0.0979, -0.0942, -0.0054,\n",
      "        -0.1270,  0.0345, -0.1167,  0.0998,  0.0546, -0.0820, -0.1127, -0.0270,\n",
      "         0.0979, -0.1175, -0.0855,  0.1298, -0.0974, -0.0579,  0.0549,  0.0301,\n",
      "         0.0433, -0.1232,  0.0795,  0.1023,  0.1272,  0.0221,  0.0715,  0.0452])), ('decoders.0.multihead_attention.w_v.weight', tensor([[-0.0032, -0.3033,  0.1461,  ...,  0.0640,  0.2697,  0.0740],\n",
      "        [ 0.0389,  0.0042,  0.0286,  ...,  0.0738, -0.0428,  0.1003],\n",
      "        [ 0.0100,  0.0485,  0.1240,  ...,  0.0700, -0.0883,  0.0800],\n",
      "        ...,\n",
      "        [ 0.1582, -0.1318,  0.0086,  ..., -0.0277,  0.0135, -0.1363],\n",
      "        [-0.0475,  0.1376,  0.0935,  ...,  0.0888,  0.0199, -0.0657],\n",
      "        [-0.0558, -0.1043, -0.1771,  ..., -0.3001,  0.1386,  0.1116]])), ('decoders.0.multihead_attention.w_v.bias', tensor([-2.9896e-02,  1.7674e-02, -2.8271e-03, -5.0069e-02, -9.0097e-02,\n",
      "         3.5501e-02, -1.4832e-01,  6.4642e-05, -1.2452e-02, -5.1428e-02,\n",
      "         6.0943e-02, -7.0586e-02, -6.8606e-02,  8.3111e-02, -6.4947e-02,\n",
      "        -5.0435e-02, -1.4559e-02,  5.5637e-03,  1.3258e-02, -8.0107e-03,\n",
      "        -1.0420e-01, -1.3847e-01,  4.8388e-02, -6.3048e-03,  8.9519e-02,\n",
      "        -6.1051e-02,  2.7627e-02, -1.5966e-01,  5.6492e-02,  4.6244e-02,\n",
      "         6.4541e-02, -3.4919e-03,  1.0875e-01, -3.4401e-02, -6.1162e-02,\n",
      "        -5.3424e-02,  1.6693e-02, -9.1651e-03,  1.0317e-01,  1.1070e-01,\n",
      "        -7.5490e-02, -3.4068e-02,  5.1893e-02,  6.4012e-02,  1.0606e-02,\n",
      "         2.2788e-03, -1.2541e-01,  9.4572e-02, -9.2707e-02, -1.2431e-01,\n",
      "        -6.7864e-02, -6.7824e-02, -3.0404e-02,  5.1710e-02, -7.3911e-02,\n",
      "        -7.2097e-02,  4.7104e-02, -7.7833e-02,  1.1006e-01, -6.9714e-02,\n",
      "        -8.6961e-02, -6.6797e-02,  1.4135e-03,  4.9015e-02])), ('decoders.0.multihead_attention.w_0.weight', tensor([[ 0.0315, -0.1384, -0.1020,  ..., -0.1857, -0.1104, -0.0132],\n",
      "        [-0.2433, -0.1746, -0.0637,  ...,  0.0080,  0.0064, -0.0563],\n",
      "        [-0.1597, -0.0137,  0.0601,  ..., -0.2132,  0.2244, -0.0359],\n",
      "        ...,\n",
      "        [ 0.0674, -0.1574,  0.0762,  ..., -0.1235, -0.1631,  0.1404],\n",
      "        [-0.0715, -0.0344,  0.0721,  ...,  0.0316, -0.0137, -0.0965],\n",
      "        [ 0.1768, -0.0727, -0.0491,  ..., -0.0488,  0.0325, -0.1257]])), ('decoders.0.multihead_attention.w_0.bias', tensor([-0.2184, -0.0205, -0.0209, -0.0901,  0.0133, -0.0742,  0.1590, -0.0151,\n",
      "        -0.1041, -0.0704, -0.0044, -0.1130, -0.1067, -0.0242,  0.0923, -0.0414,\n",
      "        -0.1517, -0.2237, -0.0424,  0.2170, -0.0546,  0.0353,  0.1046,  0.0113,\n",
      "         0.1044, -0.1309, -0.0321,  0.0953, -0.1582,  0.1426, -0.0428, -0.2153,\n",
      "        -0.0913, -0.1512,  0.1750, -0.0918, -0.1002,  0.2483,  0.0514, -0.0939,\n",
      "        -0.1103, -0.0879, -0.1060,  0.0807, -0.0026,  0.0544, -0.2087, -0.1129,\n",
      "         0.2307,  0.0796, -0.0539,  0.1313, -0.2683,  0.0662, -0.0179,  0.0802,\n",
      "        -0.3154, -0.1253,  0.0683,  0.2223, -0.0856,  0.0106, -0.1623, -0.0789])), ('decoders.0.feedforward_network.fc1.weight', tensor([[ 0.0342,  0.0127, -0.0179,  ...,  0.0884,  0.1406,  0.0112],\n",
      "        [ 0.1514, -0.1183,  0.2735,  ..., -0.0561, -0.1495,  0.0671],\n",
      "        [ 0.0061, -0.0460, -0.0648,  ..., -0.0105,  0.2310, -0.2626],\n",
      "        ...,\n",
      "        [-0.0946,  0.0833, -0.3443,  ...,  0.1007, -0.1238, -0.2501],\n",
      "        [ 0.2581,  0.1919, -0.0403,  ..., -0.1428,  0.1567, -0.0302],\n",
      "        [ 0.3036, -0.1431, -0.1168,  ...,  0.0892,  0.1436, -0.2227]])), ('decoders.0.feedforward_network.fc1.bias', tensor([-0.1331, -0.3317, -0.3170, -0.1741, -0.3279, -0.1230, -0.2103, -0.2063,\n",
      "        -0.2751, -0.1491, -0.2488, -0.2141, -0.2883, -0.2661, -0.1057, -0.2024,\n",
      "        -0.3684, -0.0360, -0.1292, -0.3098, -0.3488, -0.1591, -0.2716, -0.2962,\n",
      "        -0.2571, -0.2546, -0.0869, -0.2157, -0.1471, -0.2530, -0.1404, -0.2397,\n",
      "        -0.1453, -0.2129, -0.3387, -0.0468, -0.2694, -0.3955, -0.1159, -0.1893,\n",
      "        -0.2926, -0.3834, -0.1835, -0.3055, -0.3033, -0.0261, -0.1248, -0.1724,\n",
      "        -0.3748, -0.1727, -0.1477, -0.1808, -0.2911, -0.3300, -0.1000, -0.2005,\n",
      "        -0.2572, -0.1932, -0.3228, -0.0942, -0.2623, -0.1529, -0.2785, -0.3567,\n",
      "        -0.2962, -0.2490, -0.1907, -0.2658, -0.2513, -0.2876, -0.0345, -0.0426,\n",
      "        -0.1285, -0.2316, -0.1185, -0.1020, -0.1504, -0.2341, -0.2597, -0.1335,\n",
      "        -0.2360, -0.2813, -0.2259, -0.1891, -0.1742, -0.1814, -0.1425, -0.1540,\n",
      "        -0.2294, -0.0331, -0.2645, -0.3930, -0.2142, -0.0963, -0.2867, -0.1791,\n",
      "        -0.3156, -0.2097, -0.2573, -0.2799, -0.2713, -0.1741, -0.2014, -0.2436,\n",
      "        -0.2107, -0.0255, -0.0104, -0.1358, -0.0663, -0.1993, -0.2509, -0.2810,\n",
      "        -0.0386, -0.2214, -0.2303, -0.2738, -0.1146, -0.1760, -0.1276, -0.0824,\n",
      "        -0.1194, -0.1139, -0.3179, -0.2623, -0.4464, -0.1707, -0.1148, -0.2235,\n",
      "        -0.1189, -0.1665, -0.2509, -0.3068, -0.2289, -0.0978, -0.1969, -0.3370,\n",
      "        -0.2983, -0.1576, -0.1983, -0.3081, -0.3057, -0.1995, -0.0656, -0.2154,\n",
      "        -0.1333, -0.2023, -0.2372, -0.1957, -0.1178, -0.2412, -0.2454, -0.2619,\n",
      "        -0.2571, -0.2314, -0.0918, -0.2895, -0.2557, -0.2827, -0.1046, -0.3981,\n",
      "        -0.1872, -0.2449, -0.1545, -0.2854, -0.2260, -0.2017, -0.2018, -0.1682,\n",
      "        -0.1181, -0.1199, -0.1828, -0.1808, -0.2245, -0.2216, -0.1305, -0.1679,\n",
      "        -0.0676, -0.2282, -0.1720, -0.2938, -0.1221, -0.3584, -0.1899, -0.0824,\n",
      "        -0.1363, -0.1716, -0.0932, -0.2036, -0.3388, -0.3444, -0.2089, -0.3404,\n",
      "        -0.2612, -0.1107, -0.1136, -0.1703, -0.1369, -0.3197, -0.1928, -0.2929,\n",
      "        -0.2902, -0.2806, -0.1708, -0.1101, -0.1957, -0.2287, -0.3480, -0.2063,\n",
      "        -0.1731, -0.1765, -0.1459, -0.2233, -0.1598, -0.1824, -0.2316, -0.2416,\n",
      "        -0.2573, -0.2740, -0.2204, -0.3396, -0.1903, -0.2183, -0.2665, -0.1949,\n",
      "        -0.3530, -0.1598, -0.2912, -0.1312, -0.1759, -0.1417, -0.2454, -0.3855,\n",
      "        -0.2096, -0.2637, -0.1648, -0.1573, -0.2509, -0.0831, -0.3632, -0.3169,\n",
      "        -0.0616, -0.2984, -0.1160, -0.1927, -0.1581, -0.2754, -0.2687, -0.1383,\n",
      "        -0.1786, -0.1306, -0.1428, -0.2852, -0.2080, -0.1053, -0.3006, -0.1656])), ('decoders.0.feedforward_network.fc2.weight', tensor([[-0.1114, -0.0353, -0.0007,  ...,  0.0568, -0.0475, -0.0102],\n",
      "        [ 0.0422,  0.0327,  0.0944,  ..., -0.0008, -0.0575, -0.0462],\n",
      "        [-0.1579,  0.0699, -0.1779,  ...,  0.2378,  0.0632, -0.0809],\n",
      "        ...,\n",
      "        [-0.1070,  0.1345, -0.0161,  ...,  0.0842,  0.0539,  0.0829],\n",
      "        [-0.0148, -0.3145,  0.0741,  ...,  0.1989, -0.0366, -0.0028],\n",
      "        [ 0.0931,  0.0180,  0.0019,  ..., -0.0886, -0.0017, -0.1664]])), ('decoders.0.feedforward_network.fc2.bias', tensor([-0.0262,  0.0240, -0.0186, -0.0711, -0.0243, -0.1287, -0.0694, -0.0409,\n",
      "         0.0770, -0.0860,  0.0538, -0.0667, -0.0552, -0.0063, -0.0063, -0.1484,\n",
      "         0.1164, -0.0423, -0.0046, -0.1133, -0.0180, -0.1245,  0.0581, -0.1723,\n",
      "         0.1254, -0.1576,  0.0191, -0.0833,  0.0578, -0.1656, -0.0010, -0.0532,\n",
      "         0.0013, -0.0336, -0.0624, -0.0377, -0.0055, -0.1415,  0.0144, -0.1647,\n",
      "         0.2127, -0.0374,  0.0995, -0.0711,  0.0284, -0.1766, -0.0035, -0.1385,\n",
      "        -0.0201, -0.0730,  0.0022, -0.0645,  0.0077, -0.1142,  0.0203, -0.0627,\n",
      "         0.0648, -0.0775,  0.1214, -0.1071,  0.1094, -0.0268,  0.0115,  0.0002])), ('decoders.1.multihead_attention.w_q.weight', tensor([[-0.0252, -0.4441, -0.1588,  ..., -0.0376, -0.2381,  0.1855],\n",
      "        [-0.2052, -0.3539,  0.1468,  ..., -0.3383,  0.1778,  0.0463],\n",
      "        [-0.1713, -0.0288, -0.0151,  ..., -0.0672, -0.1919,  0.0813],\n",
      "        ...,\n",
      "        [-0.0639,  0.2691,  0.2535,  ..., -0.1409, -0.0648,  0.1145],\n",
      "        [ 0.1918,  0.4472,  0.1806,  ..., -0.0150,  0.1312,  0.2238],\n",
      "        [-0.0716,  0.2197, -0.1720,  ..., -0.0398, -0.1060, -0.1057]])), ('decoders.1.multihead_attention.w_q.bias', tensor([ 0.4162,  0.1516, -0.0395, -0.1261,  0.0252,  0.2988,  0.2507,  0.0060,\n",
      "        -0.0243, -0.0673, -0.0181,  0.0653, -0.0703,  0.0041, -0.2356, -0.2741,\n",
      "         0.2428, -0.0064, -0.0293,  0.2388,  0.0524,  0.0410, -0.1274, -0.2394,\n",
      "        -0.1074,  0.1023,  0.0365, -0.2920, -0.0632, -0.1428,  0.1021,  0.1063,\n",
      "        -0.1117, -0.2821, -0.0132,  0.1206, -0.1265, -0.0212, -0.0689,  0.0854,\n",
      "         0.0640,  0.0091,  0.0416,  0.3646, -0.2551,  0.0243, -0.0815, -0.1418,\n",
      "         0.1718, -0.2524, -0.0746,  0.1647, -0.0660,  0.1376,  0.0008, -0.0075,\n",
      "        -0.1638, -0.1006, -0.1660, -0.1795, -0.0104, -0.1097, -0.1887,  0.2079])), ('decoders.1.multihead_attention.w_k.weight', tensor([[-0.2538, -0.1338,  0.0740,  ...,  0.2932, -0.0193,  0.1570],\n",
      "        [ 0.0785,  0.0257, -0.0036,  ..., -0.2577,  0.1350,  0.2333],\n",
      "        [-0.1439, -0.2836,  0.0972,  ...,  0.0144, -0.0977,  0.1904],\n",
      "        ...,\n",
      "        [-0.1301,  0.0928, -0.2627,  ...,  0.1454,  0.4010,  0.0674],\n",
      "        [ 0.1993,  0.4120, -0.1603,  ..., -0.3203,  0.1399, -0.3339],\n",
      "        [-0.0645, -0.0265, -0.2616,  ..., -0.0975,  0.3481, -0.1493]])), ('decoders.1.multihead_attention.w_k.bias', tensor([ 0.0340,  0.0146,  0.1096,  0.0818, -0.0340, -0.1475,  0.1034,  0.0135,\n",
      "         0.0057, -0.0181,  0.0028, -0.0079,  0.1122,  0.0680, -0.0137, -0.0643,\n",
      "        -0.1107, -0.0191,  0.0073, -0.0828, -0.0654,  0.0263,  0.1365,  0.0141,\n",
      "        -0.0809,  0.0501,  0.0233, -0.0705,  0.0749,  0.0843, -0.0763, -0.0315,\n",
      "        -0.0607,  0.0798, -0.0051, -0.0200,  0.1025, -0.0979, -0.0942, -0.0054,\n",
      "        -0.1270,  0.0345, -0.1167,  0.0998,  0.0546, -0.0820, -0.1127, -0.0270,\n",
      "         0.0979, -0.1175, -0.0855,  0.1298, -0.0974, -0.0579,  0.0549,  0.0301,\n",
      "         0.0433, -0.1232,  0.0795,  0.1023,  0.1272,  0.0221,  0.0715,  0.0452])), ('decoders.1.multihead_attention.w_v.weight', tensor([[-0.0032, -0.3033,  0.1461,  ...,  0.0640,  0.2697,  0.0740],\n",
      "        [ 0.0389,  0.0042,  0.0286,  ...,  0.0738, -0.0428,  0.1003],\n",
      "        [ 0.0100,  0.0485,  0.1240,  ...,  0.0700, -0.0883,  0.0800],\n",
      "        ...,\n",
      "        [ 0.1582, -0.1318,  0.0086,  ..., -0.0277,  0.0135, -0.1363],\n",
      "        [-0.0475,  0.1376,  0.0935,  ...,  0.0888,  0.0199, -0.0657],\n",
      "        [-0.0558, -0.1043, -0.1771,  ..., -0.3001,  0.1386,  0.1116]])), ('decoders.1.multihead_attention.w_v.bias', tensor([-2.9896e-02,  1.7674e-02, -2.8271e-03, -5.0069e-02, -9.0097e-02,\n",
      "         3.5501e-02, -1.4832e-01,  6.4642e-05, -1.2452e-02, -5.1428e-02,\n",
      "         6.0943e-02, -7.0586e-02, -6.8606e-02,  8.3111e-02, -6.4947e-02,\n",
      "        -5.0435e-02, -1.4559e-02,  5.5637e-03,  1.3258e-02, -8.0107e-03,\n",
      "        -1.0420e-01, -1.3847e-01,  4.8388e-02, -6.3048e-03,  8.9519e-02,\n",
      "        -6.1051e-02,  2.7627e-02, -1.5966e-01,  5.6492e-02,  4.6244e-02,\n",
      "         6.4541e-02, -3.4919e-03,  1.0875e-01, -3.4401e-02, -6.1162e-02,\n",
      "        -5.3424e-02,  1.6693e-02, -9.1651e-03,  1.0317e-01,  1.1070e-01,\n",
      "        -7.5490e-02, -3.4068e-02,  5.1893e-02,  6.4012e-02,  1.0606e-02,\n",
      "         2.2788e-03, -1.2541e-01,  9.4572e-02, -9.2707e-02, -1.2431e-01,\n",
      "        -6.7864e-02, -6.7824e-02, -3.0404e-02,  5.1710e-02, -7.3911e-02,\n",
      "        -7.2097e-02,  4.7104e-02, -7.7833e-02,  1.1006e-01, -6.9714e-02,\n",
      "        -8.6961e-02, -6.6797e-02,  1.4135e-03,  4.9015e-02])), ('decoders.1.multihead_attention.w_0.weight', tensor([[ 0.0315, -0.1384, -0.1020,  ..., -0.1857, -0.1104, -0.0132],\n",
      "        [-0.2433, -0.1746, -0.0637,  ...,  0.0080,  0.0064, -0.0563],\n",
      "        [-0.1597, -0.0137,  0.0601,  ..., -0.2132,  0.2244, -0.0359],\n",
      "        ...,\n",
      "        [ 0.0674, -0.1574,  0.0762,  ..., -0.1235, -0.1631,  0.1404],\n",
      "        [-0.0715, -0.0344,  0.0721,  ...,  0.0316, -0.0137, -0.0965],\n",
      "        [ 0.1768, -0.0727, -0.0491,  ..., -0.0488,  0.0325, -0.1257]])), ('decoders.1.multihead_attention.w_0.bias', tensor([-0.2184, -0.0205, -0.0209, -0.0901,  0.0133, -0.0742,  0.1590, -0.0151,\n",
      "        -0.1041, -0.0704, -0.0044, -0.1130, -0.1067, -0.0242,  0.0923, -0.0414,\n",
      "        -0.1517, -0.2237, -0.0424,  0.2170, -0.0546,  0.0353,  0.1046,  0.0113,\n",
      "         0.1044, -0.1309, -0.0321,  0.0953, -0.1582,  0.1426, -0.0428, -0.2153,\n",
      "        -0.0913, -0.1512,  0.1750, -0.0918, -0.1002,  0.2483,  0.0514, -0.0939,\n",
      "        -0.1103, -0.0879, -0.1060,  0.0807, -0.0026,  0.0544, -0.2087, -0.1129,\n",
      "         0.2307,  0.0796, -0.0539,  0.1313, -0.2683,  0.0662, -0.0179,  0.0802,\n",
      "        -0.3154, -0.1253,  0.0683,  0.2223, -0.0856,  0.0106, -0.1623, -0.0789])), ('decoders.1.feedforward_network.fc1.weight', tensor([[ 0.0342,  0.0127, -0.0179,  ...,  0.0884,  0.1406,  0.0112],\n",
      "        [ 0.1514, -0.1183,  0.2735,  ..., -0.0561, -0.1495,  0.0671],\n",
      "        [ 0.0061, -0.0460, -0.0648,  ..., -0.0105,  0.2310, -0.2626],\n",
      "        ...,\n",
      "        [-0.0946,  0.0833, -0.3443,  ...,  0.1007, -0.1238, -0.2501],\n",
      "        [ 0.2581,  0.1919, -0.0403,  ..., -0.1428,  0.1567, -0.0302],\n",
      "        [ 0.3036, -0.1431, -0.1168,  ...,  0.0892,  0.1436, -0.2227]])), ('decoders.1.feedforward_network.fc1.bias', tensor([-0.1331, -0.3317, -0.3170, -0.1741, -0.3279, -0.1230, -0.2103, -0.2063,\n",
      "        -0.2751, -0.1491, -0.2488, -0.2141, -0.2883, -0.2661, -0.1057, -0.2024,\n",
      "        -0.3684, -0.0360, -0.1292, -0.3098, -0.3488, -0.1591, -0.2716, -0.2962,\n",
      "        -0.2571, -0.2546, -0.0869, -0.2157, -0.1471, -0.2530, -0.1404, -0.2397,\n",
      "        -0.1453, -0.2129, -0.3387, -0.0468, -0.2694, -0.3955, -0.1159, -0.1893,\n",
      "        -0.2926, -0.3834, -0.1835, -0.3055, -0.3033, -0.0261, -0.1248, -0.1724,\n",
      "        -0.3748, -0.1727, -0.1477, -0.1808, -0.2911, -0.3300, -0.1000, -0.2005,\n",
      "        -0.2572, -0.1932, -0.3228, -0.0942, -0.2623, -0.1529, -0.2785, -0.3567,\n",
      "        -0.2962, -0.2490, -0.1907, -0.2658, -0.2513, -0.2876, -0.0345, -0.0426,\n",
      "        -0.1285, -0.2316, -0.1185, -0.1020, -0.1504, -0.2341, -0.2597, -0.1335,\n",
      "        -0.2360, -0.2813, -0.2259, -0.1891, -0.1742, -0.1814, -0.1425, -0.1540,\n",
      "        -0.2294, -0.0331, -0.2645, -0.3930, -0.2142, -0.0963, -0.2867, -0.1791,\n",
      "        -0.3156, -0.2097, -0.2573, -0.2799, -0.2713, -0.1741, -0.2014, -0.2436,\n",
      "        -0.2107, -0.0255, -0.0104, -0.1358, -0.0663, -0.1993, -0.2509, -0.2810,\n",
      "        -0.0386, -0.2214, -0.2303, -0.2738, -0.1146, -0.1760, -0.1276, -0.0824,\n",
      "        -0.1194, -0.1139, -0.3179, -0.2623, -0.4464, -0.1707, -0.1148, -0.2235,\n",
      "        -0.1189, -0.1665, -0.2509, -0.3068, -0.2289, -0.0978, -0.1969, -0.3370,\n",
      "        -0.2983, -0.1576, -0.1983, -0.3081, -0.3057, -0.1995, -0.0656, -0.2154,\n",
      "        -0.1333, -0.2023, -0.2372, -0.1957, -0.1178, -0.2412, -0.2454, -0.2619,\n",
      "        -0.2571, -0.2314, -0.0918, -0.2895, -0.2557, -0.2827, -0.1046, -0.3981,\n",
      "        -0.1872, -0.2449, -0.1545, -0.2854, -0.2260, -0.2017, -0.2018, -0.1682,\n",
      "        -0.1181, -0.1199, -0.1828, -0.1808, -0.2245, -0.2216, -0.1305, -0.1679,\n",
      "        -0.0676, -0.2282, -0.1720, -0.2938, -0.1221, -0.3584, -0.1899, -0.0824,\n",
      "        -0.1363, -0.1716, -0.0932, -0.2036, -0.3388, -0.3444, -0.2089, -0.3404,\n",
      "        -0.2612, -0.1107, -0.1136, -0.1703, -0.1369, -0.3197, -0.1928, -0.2929,\n",
      "        -0.2902, -0.2806, -0.1708, -0.1101, -0.1957, -0.2287, -0.3480, -0.2063,\n",
      "        -0.1731, -0.1765, -0.1459, -0.2233, -0.1598, -0.1824, -0.2316, -0.2416,\n",
      "        -0.2573, -0.2740, -0.2204, -0.3396, -0.1903, -0.2183, -0.2665, -0.1949,\n",
      "        -0.3530, -0.1598, -0.2912, -0.1312, -0.1759, -0.1417, -0.2454, -0.3855,\n",
      "        -0.2096, -0.2637, -0.1648, -0.1573, -0.2509, -0.0831, -0.3632, -0.3169,\n",
      "        -0.0616, -0.2984, -0.1160, -0.1927, -0.1581, -0.2754, -0.2687, -0.1383,\n",
      "        -0.1786, -0.1306, -0.1428, -0.2852, -0.2080, -0.1053, -0.3006, -0.1656])), ('decoders.1.feedforward_network.fc2.weight', tensor([[-0.1114, -0.0353, -0.0007,  ...,  0.0568, -0.0475, -0.0102],\n",
      "        [ 0.0422,  0.0327,  0.0944,  ..., -0.0008, -0.0575, -0.0462],\n",
      "        [-0.1579,  0.0699, -0.1779,  ...,  0.2378,  0.0632, -0.0809],\n",
      "        ...,\n",
      "        [-0.1070,  0.1345, -0.0161,  ...,  0.0842,  0.0539,  0.0829],\n",
      "        [-0.0148, -0.3145,  0.0741,  ...,  0.1989, -0.0366, -0.0028],\n",
      "        [ 0.0931,  0.0180,  0.0019,  ..., -0.0886, -0.0017, -0.1664]])), ('decoders.1.feedforward_network.fc2.bias', tensor([-0.0262,  0.0240, -0.0186, -0.0711, -0.0243, -0.1287, -0.0694, -0.0409,\n",
      "         0.0770, -0.0860,  0.0538, -0.0667, -0.0552, -0.0063, -0.0063, -0.1484,\n",
      "         0.1164, -0.0423, -0.0046, -0.1133, -0.0180, -0.1245,  0.0581, -0.1723,\n",
      "         0.1254, -0.1576,  0.0191, -0.0833,  0.0578, -0.1656, -0.0010, -0.0532,\n",
      "         0.0013, -0.0336, -0.0624, -0.0377, -0.0055, -0.1415,  0.0144, -0.1647,\n",
      "         0.2127, -0.0374,  0.0995, -0.0711,  0.0284, -0.1766, -0.0035, -0.1385,\n",
      "        -0.0201, -0.0730,  0.0022, -0.0645,  0.0077, -0.1142,  0.0203, -0.0627,\n",
      "         0.0648, -0.0775,  0.1214, -0.1071,  0.1094, -0.0268,  0.0115,  0.0002])), ('embedding.weight', tensor([[-1.5447, -0.8302, -1.8829,  ..., -2.0300,  0.2305, -0.1949],\n",
      "        [-0.0412, -1.1631, -0.9631,  ...,  1.7881,  0.0250, -0.7618],\n",
      "        [-0.4849,  0.0049, -0.7170,  ...,  0.7620, -0.2683,  0.7938],\n",
      "        ...,\n",
      "        [-0.7869, -0.4901, -0.9372,  ...,  0.2645,  0.1720,  1.4440],\n",
      "        [ 0.7789,  0.0591, -0.0586,  ..., -0.9582, -0.0694,  1.0909],\n",
      "        [-0.2669, -0.8686, -0.1697,  ...,  0.1522,  0.5405,  0.1044]])), ('finalfc.weight', tensor([[ 0.1285,  0.1880, -0.1271,  ..., -0.2911,  0.1045,  0.2911],\n",
      "        [-0.0573,  0.0673, -0.1164,  ...,  0.0520, -0.1880, -0.0793],\n",
      "        [ 0.3363, -0.1746, -0.1879,  ..., -0.0401,  0.1472, -0.2254],\n",
      "        ...,\n",
      "        [-0.0185, -0.2254, -0.0469,  ...,  0.0470,  0.0927, -0.0672],\n",
      "        [-0.0579, -0.0578, -0.1308,  ..., -0.1507, -0.2465,  0.0660],\n",
      "        [-0.1363,  0.1324,  0.1554,  ..., -0.0614,  0.0889, -0.0986]])), ('finalfc.bias', tensor([-1.2964e-01,  2.5341e-01, -1.5594e-01, -3.5387e-02, -1.4744e-02,\n",
      "        -1.7366e-01, -8.2161e-02,  3.3054e-02,  4.2033e-02, -1.4790e-01,\n",
      "         2.5492e-01, -1.1359e-01, -1.5395e-02, -1.1357e-01, -6.7218e-03,\n",
      "        -1.7643e-01, -1.7027e-02, -1.0072e-01, -1.3891e-01,  6.6037e-02,\n",
      "        -8.3743e-02,  1.5292e-02,  1.1380e-01, -1.8914e-01,  1.1141e-01,\n",
      "         1.5511e-03,  2.7743e-02, -1.5251e-01, -2.3110e-01, -1.4757e-01,\n",
      "         3.0796e-02, -1.0475e-01, -7.0982e-02, -4.9658e-02,  1.5041e-02,\n",
      "        -1.3423e-01, -3.3121e-02,  1.0456e-01, -1.3202e-01,  1.5152e-02,\n",
      "        -6.9598e-02, -1.7900e-01, -7.0413e-02, -2.3528e-01, -1.2613e-01,\n",
      "        -1.8223e-01, -1.3257e-02, -1.4162e-01, -7.4147e-02,  1.2538e-02,\n",
      "        -4.4519e-02,  3.2343e-02, -1.4324e-03,  1.8308e-02,  3.4733e-02,\n",
      "        -1.1722e-01, -4.8906e-02, -1.4346e-01, -6.4634e-02, -1.0981e-01,\n",
      "        -1.9100e-02, -2.0042e-01,  8.5402e-02, -1.8573e-01, -1.6812e-01,\n",
      "         3.4137e-02, -1.8738e-01, -2.2675e-02, -1.1207e-01,  2.4718e-02,\n",
      "        -1.0715e-01, -7.6948e-02,  5.2027e-02, -6.7754e-02, -1.1425e-01,\n",
      "        -2.1773e-02, -4.6285e-02, -6.4465e-02, -3.2648e-02, -2.0630e-01,\n",
      "        -1.2018e-01, -1.0215e-01, -8.7451e-02, -7.8494e-02, -4.0641e-02,\n",
      "        -7.9620e-02, -8.6942e-02, -3.9739e-02, -1.1553e-01, -1.6331e-01,\n",
      "        -1.8501e-01, -9.5793e-02, -1.5685e-01, -3.2039e-02,  2.0246e-02,\n",
      "        -1.0705e-01, -1.1330e-01, -1.5038e-01, -1.6574e-04, -1.6037e-01,\n",
      "        -2.4433e-02, -1.2295e-01, -2.5497e-03,  1.0235e-01, -1.1345e-02,\n",
      "        -1.8154e-01, -2.1822e-01, -2.0134e-01, -1.5857e-01,  4.3823e-02,\n",
      "        -5.6635e-02, -1.5368e-01, -1.2493e-02, -2.8714e-02, -3.8320e-02,\n",
      "        -8.2360e-02,  1.2364e-01, -1.4382e-02, -8.2222e-02, -1.8264e-01,\n",
      "         4.0573e-02, -1.0376e-02, -1.7693e-01,  8.0791e-03, -6.8655e-02,\n",
      "        -5.4999e-02,  2.5952e-02, -1.6748e-01,  5.1375e-02, -1.0109e-01,\n",
      "         5.5104e-02,  3.7487e-02,  1.7259e-02, -1.3595e-02, -3.5037e-02,\n",
      "        -3.4954e-02,  2.0462e-02,  4.4007e-02, -1.6242e-01,  1.2081e-01,\n",
      "        -3.2653e-02, -1.9134e-01, -1.1334e-01, -1.2296e-01,  6.5749e-02,\n",
      "        -3.9662e-02, -1.0850e-02,  5.8681e-02, -2.5109e-02,  9.2697e-02,\n",
      "         3.6644e-02, -1.2753e-01, -3.0047e-02, -1.5387e-01,  1.9868e-01,\n",
      "         8.1990e-02,  1.0085e-02, -1.1966e-01, -1.3910e-01,  1.5425e-02,\n",
      "        -7.0795e-02, -1.4518e-01,  4.5030e-02, -1.9701e-01,  2.8757e-01,\n",
      "        -7.8736e-02,  9.8432e-02, -1.4933e-01,  3.2095e-02, -1.4380e-01,\n",
      "         1.3457e-01, -1.8757e-01,  1.2337e-02, -1.3933e-02, -1.9803e-02,\n",
      "         3.3760e-02,  1.1766e-01, -2.3623e-02, -7.7085e-02, -6.9015e-02,\n",
      "        -4.7504e-02, -1.0958e-02, -8.6287e-02, -5.6687e-02, -1.1106e-01,\n",
      "        -2.0821e-02,  4.6648e-02,  3.1444e-02, -9.5845e-02, -1.9755e-03,\n",
      "         4.7881e-03,  1.2773e-02, -9.6455e-02, -1.2386e-01, -5.9802e-02,\n",
      "         7.9262e-02,  7.3568e-03, -3.6615e-02, -4.5786e-02,  4.1607e-02,\n",
      "         6.1913e-02, -3.7574e-02,  1.2770e-03,  9.5701e-02, -5.5342e-02,\n",
      "        -8.8870e-02,  4.9564e-02,  3.9232e-02, -7.2741e-02,  5.1207e-02,\n",
      "         2.2970e-02, -1.3690e-01, -8.0608e-02, -2.8596e-02, -1.7453e-01,\n",
      "         8.7330e-03,  1.2724e-02, -2.5771e-01,  5.2816e-02, -1.7650e-01,\n",
      "         1.3948e-02, -1.2845e-01, -7.8888e-03, -1.6276e-01, -4.2525e-02,\n",
      "        -4.9985e-02, -1.2212e-01, -5.7135e-02, -1.1809e-01, -1.9527e-01,\n",
      "        -1.2979e-01, -6.7311e-02, -1.2125e-02, -2.0234e-01, -9.8934e-02,\n",
      "        -1.1762e-01,  6.0935e-02, -1.2125e-01, -9.3919e-02, -1.6508e-02,\n",
      "         2.4559e-02, -7.7166e-02, -1.1483e-01, -3.1505e-02,  4.4019e-02,\n",
      "        -1.6113e-02, -3.0886e-02, -4.4657e-02,  8.3641e-02, -1.0355e-01,\n",
      "         3.7498e-02, -1.1162e-01,  7.8732e-02, -1.3090e-01, -6.0257e-02,\n",
      "        -1.2857e-01, -5.2444e-03, -8.5261e-02, -8.7307e-04, -2.8444e-02,\n",
      "        -8.5407e-02, -1.1726e-01, -1.1922e-01, -1.2366e-01, -4.4990e-03,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -1.7814e-01, -1.0464e-01,  5.5313e-02, -4.9438e-02]))])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Later to restore:\n",
    "lp = torch.load(\"params/LMtfparams7455419561970809\")\n",
    "\n",
    "nb_decoders = lp[\"nb_decoders\"]\n",
    "vector_size = lp[\"vector_size\"]\n",
    "nb_heads = lp[\"nb_heads\"]\n",
    "head_size = lp[\"head_size\"]\n",
    "max_length = lp[\"max_length\"]\n",
    "ffn_hidden_size = lp[\"ffn_hidden_size\"]\n",
    "vocab_size = lp[\"vocab_size\"]\n",
    "model_params_dict = lp[\"model_params_dict\"]\n",
    "\n",
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "LMtransformer.load_state_dict(model_params_dict)\n",
    "\n",
    "#Attention, pour pouvoir générer il faut reconstruire le vocabulaire et ses numéros associés avec le code plus haut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bidouilles pour adapter nos fonctions aux fonctions common codées par Nathra \n",
    "#(sequence list of ints en entree, list of probas en sortie)\n",
    "#(Faire mieux plus tard)\n",
    "def LMtransformerprediction(listints):\n",
    "    return np.exp(LMtransformer(torch.tensor([listints[-8:]]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerprediction, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def gen_seq_maison(prev_seq):\\n    with torch.no_grad():\\n        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\\n        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\\n        tokens_pred = vocab_numeroted[indice]\\n        print(' '.join(tokens_pred))\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def gen_seq_maison(prev_seq):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\n",
    "        tokens_pred = vocab_numeroted[indice]\n",
    "        print(' '.join(tokens_pred))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 90.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lui arrive parfois d ' entrer dans une maison , ou de s ' ma liberte de la ruthenie qui dure depuis plusieurs annees . ainsi , en 1281 , les polonais mer de la reochestration de trois de commerce et d ' industrie d ' artistes comme pierre dac , fernand raynaud ou jacques brel ... il fut egalement un historien loc , vive ma armee praxis a cagnes et , fort de vitoria-gasteiz pour aller aider leon ier de galicie . l ' histoire de la commune de tusson de contes pour enfants , brocanteur , ami d\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['il'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 84.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans , a barcelone , il est touche par l ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' avoir atteint , par la meditation des lettres et des nombres , l ' inspiration prophetique et l ' etat de messie . il quitte a nouveau l ' espagne afin de transmettre , fort de l ' essence divine qui l ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' avoir atteint , par la meditation des lettres\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['a','l','age','de','31'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 95.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... en 1981 , mer . non content d ' exercer son sacerdoce , roger ducouret fut auteur de romans policiers , de contes pour enfants , brocanteur , ami d ' artistes comme pierre dac , fernand raynaud ou jacques brel ... il fut , l ' , les gens de maintenant de vitoria-gasteiz , dont l ' aeroport se met a se specialiser dans le traitement de charge aerienne et , formee par aena , la mairie de vitoria-gasteiz , dont l ' aeroport se met a se specialiser dans le traitement de charge aerienne et , formee\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 88.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' esprit prophetique apres avoir ete marquee apres a ete marquee par la personnalite roger ducouret , cue de tusson de 1942 a 1981 . non content d ' exercer son sacerdoce , roger ducouret fut auteur de romans policiers , de contes pour favoriser cette activite , on constitue en 1994 la societe via , formee par aena , la un historien loc de contes pour aller aider leon ier de galicie . l ' histoire de la commune de tusson de 1942 a 1981 de serge gainsbourg et `` vive ma liberte `` d ' arno . il\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['barcelone',',','il','est','touche','par','l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tokens)<100:\n",
    "    print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
