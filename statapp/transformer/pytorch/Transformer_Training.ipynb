{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformer_model import *\n",
    "import nltk\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from statapp.common.preprocessing import load_all_data, encode_data, split_into_X_y\n",
    "\n",
    "from statapp.common.sampling import sample_token_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing maison assez brouillon pour le moment... L'encodage est effectué au niveau des mots. Les données exploitées sont placées dans le dossier data dans le dossier du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_all_data(\"data/fr.train.top1M.txt\", sample=0.00001)\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "vocab = list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {}\n",
    "\n",
    "for word in vocab:\n",
    "    dico[word]=0\n",
    "    \n",
    "for token in tokens:\n",
    "    dico[token]+=1\n",
    "    \n",
    "sorted_list = sorted(dico.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_dico = {}\n",
    "\n",
    "for i in range(vocab_size-1):\n",
    "    sorted_dico[sorted_list[i][0]] = sorted_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokens)):\n",
    "    if tokens[i] not in sorted_dico:\n",
    "        tokens[i] = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données exploitées contiennent 553 tokens (mots) au total.\n",
      "La taille du vocabulaire ainsi constitué est de 50\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(tokens))\n",
    "\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\n",
    "tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "\n",
    "tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "\n",
    "nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_test = load_all_data(\"data/fr.train.top1M.txt\", sample=0.05, part=\"end\")\\n\\ntokens_test = nltk.word_tokenize(text_test)\\n\\nvocab_test = list(set(tokens_test))\\n\\nvocab_size_test = len(vocab_test)\\n\\nvocab_numbers_test = dict(zip(vocab_test, range(0,len(vocab_test))))\\nvocab_numeroted_test = dict(zip(range(0,len(vocab_test)), vocab_test))\\ntokens_numbers_test = np.array([vocab_numbers_test[tokens_test[i]] for i in range(len(tokens_test))])\\n\\ntokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\\ntokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\\n\\nnb_sequences_test =  tokens_numbers_sequences_test.shape[0]\\n\\nprint(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\\nprint(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size_test))'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"text_test = load_all_data(\"data/fr.train.top1M.txt\", sample=0.05, part=\"end\")\n",
    "\n",
    "tokens_test = nltk.word_tokenize(text_test)\n",
    "\n",
    "vocab_test = list(set(tokens_test))\n",
    "\n",
    "vocab_size_test = len(vocab_test)\n",
    "\n",
    "vocab_numbers_test = dict(zip(vocab_test, range(0,len(vocab_test))))\n",
    "vocab_numeroted_test = dict(zip(range(0,len(vocab_test)), vocab_test))\n",
    "tokens_numbers_test = np.array([vocab_numbers_test[tokens_test[i]] for i in range(len(tokens_test))])\n",
    "\n",
    "tokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\n",
    "tokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\n",
    "\n",
    "nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size_test))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "#Correspond à utiliser l'entropie croisée puisque les sorties sont des log_softmax\n",
    "#et l'entropie croisée = nll_loss(log_softmax(.), target)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(LMtransformer.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nb_epochs, batch_size):\n",
    "    \n",
    "    #What is this ?? I don't remember. Make grad required ?\n",
    "    LMtransformer.train()\n",
    "    \n",
    "    #pas pour l'affichage progressif de la loss\n",
    "    step = max(1,((len(tokens)-max_length-1)/batch_size)//5)\n",
    "    \n",
    "    epochs_losses = []\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        running_loss = 0\n",
    "        \n",
    "        randperm = torch.randperm(nb_sequences)\n",
    "        randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "        \n",
    "        \n",
    "        # running_loss_test = 0\n",
    "        \n",
    "        # randperm_test = torch.randperm(nb_sequences_test)\n",
    "        #randperm_test = randperm_test[:(nb_sequences//batch_size)*batch_size]\n",
    "        #batchs_indices_test = randperm_test.reshape(nb_sequences_test//batch_size, batch_size)\n",
    "        \n",
    "        \n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            \n",
    "            batch = tokens_numbers_sequences[batch_indices]\n",
    "            optimizer.zero_grad()\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Il faudrait adapter les affichages en fonction du nombre de batchs total\n",
    "            running_loss += loss.item()\n",
    "            if i % step == step-1:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / step))\n",
    "                \n",
    "                #stock pour affichage graphique\n",
    "                epochs_losses.append(epoch-1+(i/((len(tokens)-max_length-1)/batch_size)))\n",
    "                losses.append(running_loss / step)\n",
    "                \n",
    "                running_loss = 0.\n",
    "                \n",
    "        plt.plot(epochs_losses, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'overfitting sur un cas ultrasimplifié (5 tokens, longueur de séquence 1, 3 decoders, 2 heads) :\n",
    "- En observant les sorties le modèle a bien appris et overfitte ! (loss à 0 au bout de 5-6 epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christos\\Desktop\\Git\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 2.844\n",
      "[1,    20] loss: 2.142\n",
      "[1,    30] loss: 1.740\n",
      "[1,    40] loss: 1.738\n",
      "[1,    50] loss: 1.657\n",
      "[2,    10] loss: 1.450\n",
      "[2,    20] loss: 1.467\n",
      "[2,    30] loss: 1.445\n",
      "[2,    40] loss: 1.466\n",
      "[2,    50] loss: 1.404\n",
      "[3,    10] loss: 1.350\n",
      "[3,    20] loss: 1.293\n",
      "[3,    30] loss: 1.314\n",
      "[3,    40] loss: 1.375\n",
      "[3,    50] loss: 1.228\n",
      "[4,    10] loss: 1.209\n",
      "[4,    20] loss: 1.290\n",
      "[4,    30] loss: 1.238\n",
      "[4,    40] loss: 1.325\n",
      "[4,    50] loss: 1.344\n",
      "[5,    10] loss: 1.248\n",
      "[5,    20] loss: 1.341\n",
      "[5,    30] loss: 1.265\n",
      "[5,    40] loss: 1.303\n",
      "[5,    50] loss: 1.220\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxV9Z3/8dfnblkgG0lYEhICshhAkBIRRBFZBJfR2o62tdXW0VJbp9WZzq/+rK2dLr92ptM6to9O61hpUetSLbQudUdkFxsQhBDWQFgCZAMSstzc5fP7I2m1mJDt3pzk3s/z8ciDJPebc943yvsevud7zxFVxRhjzMDncjqAMcaYyLBCN8aYGGGFbowxMcIK3RhjYoQVujHGxAiPUzvOysrSgoICp3ZvjDED0ubNm6tVNbu9xxwr9IKCAoqLi53avTHGDEgiUt7RYzblYowxMcIK3RhjYoQVujHGxAgrdGOMiRFW6MYYEyOs0I0xJkZYoRtjTIwYcIX++mOPsvT271BW8r7TUYwxpl8ZcIVeve8wzd7LKXl7ldNRjDGmXxlwhT50wmgATh6sdDiJMcb0L50WuojkicgqESkVkRIRubudMWki8qKIbGsbc1t04sLUefMBCJ6SaO3CGGMGpK4coQeBr6tqITATuEtEJp415i5gp6pOBeYCPxURX0STtsnOycPbchJtSYnG5o0xZsDqtNBV9Ziqbmn7vB4oBXLPHgakiIgAg4FaWl8IosIdqgaGRGvzxhgzIHVrDl1ECoBpwKazHvoFUAhUANuBu1U1HIF8Hagl6G736pHGGBO3ulzoIjIYWA7co6p1Zz28CNgK5AAXAr8QkdR2trFERIpFpLiqqqrnoRPPEPSlcnjv7h5vwxhjYk2XCl1EvLSW+ZOquqKdIbcBK7TVPuAAcP7Zg1T1EVUtUtWi7OyeH2F7h7TGLlm7usfbMMaYWNOVVS4CLAVKVfXBDoYdAua3jR8GTADKIhXybBmjRwBQs+9wtHZhjDEDTlfuWDQbuAXYLiJb2773TSAfQFUfBr4PLBOR7YAA96pqdRTyAjBpzhwObqnEXxvFaXpjjBlgOi10VV1Ha0mfa0wFcGWkQnWm4PzJeALPQyi5r3ZpjDH9nmP3FO0td7AaJdPpGMYY028MuLf+/5WLGkKuLKdjGGNMvzFgCx1fPQFfOjXHjzqdxBhj+oUBW+ietDCIi22rVjodxRhj+oUBW+hpo1qnW07sOuBwEmOM6R8GbKGPv3gGAM1VfoeTGGNM/zBgC33ctBm4g02Em5KcjmKMMf3CgF226PF68QSqQDOcjmKMMf3CgD1CBxCtIey2pYvGGAMDvdC9pwl4M2moO+10FGOMcdyALnR3ahB1udm66k2noxhjjOMGdKEPzkkH4OiOUoeTGGOM8wZ0oY+efiEAjccbHU5ijDHOG9CFPvmSObhCLYQaEpyOYowxjhuwyxYBfImJeAPVEE53OooxxjhuQB+hA0i4GnXZZXSNMaYrt6DLE5FVIlIqIiUicncH4+aKyNa2MX13s0/PaQLeLFqam/tsl8YY0x915Qg9CHxdVQuBmcBdIjLxwwNEJB34JXCdqk4Cbox40g64B/kJu31sX7+qr3ZpjDH9UqeFrqrHVHVL2+f1QCmQe9awm4EVqnqobVxlpIN2JHn4IAAObtneV7s0xph+qVtz6CJSAEwDNp310HggQ0TeFpHNInJrBz+/RESKRaS4qqqqJ3k/Infy+QCcOXoqItszxpiBqsuFLiKDgeXAPapad9bDHmA6cA2wCPi2iIw/exuq+oiqFqlqUXZ2di9if+DCKxYg4RCh+gG9YMcYY3qtSy0oIl5ay/xJVV3RzpAjQLWqNgANIrIGmArsiVjSDgxKTcMbqEZDadHelTHG9GtdWeUiwFKgVFUf7GDY88BlIuIRkWTgYlrn2vuEK1SDii1dNMbEt64coc8GbgG2i8jWtu99E8gHUNWHVbVURF4F3gfCwKOquiMagdvlPknQPZpgIIDH6+2z3RpjTH/SaaGr6jpAujDuv4D/ikSo7nIlNREKJ7H3vXcpnDHbiQjGGOO4Af9OUYDE7NZrueze+K7DSYwxxjkxUejDCscAUHe42uEkxhjjnJgo9GnzF4KGCZ6OiadjjDE9EhMNmJE9HG/LKWhJcTqKMcY4JiYKHcAdqiKMLV00xsSvmCl0cdUS8mQ5HcMYYxwTO4We2EjQm8LBXX23/N0YY/qTmCl0X6YbgJI1axxOYowxzoiZQs88byQAJ/cfcziJMcY4I2YKfcoVVwAQOBV2OIkxxjgjZgo9Z/Q4PC11hJsHOx3FGGMcETOFDuAJVQFDnI5hjDGOiKlChxpCblu6aIyJTzFV6OI7Q8CXQVXFYaejGGNMn4upQvdmtP657a2VzgYxxhgHdOWORXkiskpESkWkRETuPsfYi0QkJCL/GNmYXZNeMAyAyt0HnNi9McY4qitH6EHg66paCMwE7hKRiWcPEhE38J/Aa5GN2HWFs2cB4K8OOBXBGGMc02mhq+oxVd3S9nk9rfcKzW1n6FdpvZF0ZUQTdsPYqUW4gw1oU7JTEYwxxjHdmkMXkQJgGrDprO/nAjcAD3fy80tEpFhEiquqqrqXtIs8gSo0nBGVbRtjTH/W5UIXkcG0HoHfo6p1Zz38EHCvqobOtQ1VfURVi1S1KDs7u/tpu8BFLWF3dLZtjDH9Wac3iQYQES+tZf6kqq5oZ0gR8IyIAGQBV4tIUFX/FLGkXeWto8U9hNM11aRl2pp0Y0z86MoqFwGWAqWq+mB7Y1R1tKoWqGoB8AfgK46UOeBOCYK42Lb6DSd2b4wxjunKlMts4BZgnohsbfu4WkTuFJE7o5yv21LzW9/6f2zHPoeTGGNM3+p0ykVV1wHS1Q2q6hd6E6i3zpsxnYrdSmNlo5MxjDGmz8XUO0UBJs64FFfIjzYkOR3FGGP6VJdOig4kHq8Xb6AKDac7HcUYY/pUzB2hA0i4hrDLVrgYY+JLbBa65xQBXyZNDQ1ORzHGmD4Tk4XuSgmgLi/b169yOooxxvSZmCz0QSNSACjfst3hJMYY03distDzpk4CoPFYvcNJjDGm78RkoU+dMx8JBwid8TodxRhj+kzMLVsESBo0CG9LjS1dNMbElZg8QgdwhatRyXQ6hjHG9JmYLXRxnyLgyyYYsLsXGWPiQ+wW+qBmwu4Edr67zukoxhjTJ2K20JOGJgJQ9u4Wh5MYY0zfiNlCz5k8DoC6wzUOJzHGmL4Rs4U+9fKFoGGCdW6noxhjTJ/oyh2L8kRklYiUikiJiNzdzpjPisj7bR8bRGRqdOJ2XVpmFr6WWjSQ6nQUY4zpE11Zhx4Evq6qW0QkBdgsIm+o6s4PjTkAXK6qJ0XkKuAR4OIo5O0WV6jKli4aY+JGp0foqnpMVbe0fV4PlAK5Z43ZoKon2758BxgZ6aA9Ie6TBD12GV1jTHzo1hy6iBQA04BN5xh2O/BKBz+/RESKRaS4qqqqO7vuEUlsJOQdzL5txVHflzHGOK3LhS4ig4HlwD2qWtfBmCtoLfR723tcVR9R1SJVLcrOzu5J3m5JyGy9lkvp+o1R35cxxjitS4UuIl5ay/xJVV3RwZgpwKPA9araL9YKZo/PB+BU+QmHkxhjTPR1ZZWLAEuBUlV9sIMx+cAK4BZV3RPZiD039YoFAAROdjLQGGNiQFdWucwGbgG2i8jWtu99E8gHUNWHgQeATOCXrf1PUFWLIh+3e4bmjcLbshnCg52OYowxUddpoavqOkA6GXMHcEekQkWSO1iFyhCnYxhjTNTF7DtF/0ZqCbqjfwLWGGOcFvOF7kquJ+hLY9vat5yOYowxURXzhZ41eRgA219a5XASY4yJrpgv9Lmf/TyukB9/pc/pKMYYE1UxX+gp6en4/GWoFjgdxRhjoirmCx1AEo/hT8xlz5Z3nY5ijDFRExeFnn5+GgDFf/yzw0mMMSZ64qLQL7/5ZiQcoOloXDxdY0yciouGyxyeS0LzQTSU73QUY4yJmrgodADxHcGfmMehPTs7H2yMMQNQ3BR6ypgkEBcbn1nudBRjjImKuCn0yz77KSQcoqE84HQUY4yJirgp9OGjzsPnP4QG85yOYowxURE3hQ7g8hzCnzCKysPlTkcxxpiIi6tCT85zoS4Pa556yukoxhgTcV25Y1GeiKwSkVIRKRGRu9sZIyLycxHZJyLvi8jHohO3d2bceANomLp9jU5HMcaYiOvKEXoQ+LqqFgIzgbtEZOJZY64CxrV9LAF+FdGUETJm0hQSmo+gLblORzHGmIjrtNBV9Ziqbmn7vB4oBc5uxOuBx7XVO0C6iIyIeNoIcLkO0eIr4HRNtdNRjDEmoro1hy4iBcA0YNNZD+UChz/09RE+WvqIyBIRKRaR4qqqqu4ljZCEnCBht49VTzzuyP6NMSZaulzoIjIYWA7co6p1Zz/czo/oR76h+oiqFqlqUXa2M7eF+9j1iwCo3VXjyP6NMSZaulToIuKltcyfVNUV7Qw5Anx4gfdIoKL38SKvcMZsEpqPoY39ckbIGGN6rCurXARYCpSq6oMdDHsBuLVttctM4LSqHotgzohyyQECvtE01J12OooxxkRMV47QZwO3APNEZGvbx9UicqeI3Nk25mWgDNgH/Br4SnTiRoZ3aDMhTxJvP/07p6MYY0zEeDoboKrraH+O/MNjFLgrUqGibdKiOWx8Fk5sO+p0FGOMiZi4eqfoX31s3pX4/FXomaFORzHGmIiJy0IHcIXLCHjH0NLc7HQUY4yJiLgtdG9mPSHvYFY/+6TTUYwxJiLittDHXXERAEff3e9wEmOMiYy4LfSLFl+Lt+UkofpMp6MYY0xExG2he7xe3KH9BN1jCAbsLkbGmIEvbgsdwJ1+iqAvjfXPP+d0FGOM6bW4LvT8WYUAHFy7w+EkxhjTe3Fd6HM++Wk8gTqCp9KcjmKMMb0W14Xu8XrxBPcTco1xOooxxvRaXBc6gCulhkBCJu+88oLTUYwxplfivtBHfKwAgD0rz75nhzHGDCxxX+jzbr4Vd7CRYPUgp6MYY0yvxH2h+xIT8bbsJ8Rop6MYY0yvxH2hA7gGnaAlcRjb1r7ldBRjjOmxrtyx6DciUiki7S7WFpE0EXlRRLaJSImI3Bb5mNGVdUHr7ei2v7TK4STGGNNzXTlCXwYsPsfjdwE7VXUqMBf4qYj4eh+t78z73K24Qn78lQMqtjHG/J1OC11V1wC15xoCpLTde3Rw29hgZOL1jUGpafj8ZagWOB3FGGN6LBJz6L8ACoEKYDtwt6qG2xsoIktEpFhEiquqqiKw68iRxAr8ibns2fKu01GMMaZHIlHoi4CtQA5wIfALEUltb6CqPqKqRapalJ2dHYFdR05GYQYAxX/8s8NJjDGmZyJR6LcBK7TVPuAAcH4Ettun5n7uc0g4QNNRW/hjjBmYItFeh4D5ACIyDJgAlEVgu30qI3s4Cf6DaGiU01GMMaZHurJs8WlgIzBBRI6IyO0icqeI3Nk25PvAJSKyHVgJ3Kuq1dGLHD3iO4I/cSSH9ux0OooxxnSbp7MBqvqZTh6vAK6MWCIHpYxJoqncxcZnlpP/wESn4xhjTLfYhPGHXHbzp5BwiIbyIE0NDU7HMcaYbun0CD2eDB91Hgn+VTQlXc5vvr4JNIwrHEQ0hOgHf6IhhNY/IYR70H5u+dl38Xi9Tj8FY0wcs0I/S+7lYSreXQkhAXWBtv0ZdgMuVN0IblTdgBuVFBrDC3jsjgf5xE8+T0b2cKefgjEmTomqOrLjoqIiLS4udmTfkRQMBHj8K9+lyT2PxKb9XHxnIZNnXep0LGNMjBKRzapa1N5jNofeSx6vl3/69Q9Iz1hFiy+PDY8c47Xf/trpWMaYOGSFHiGf/dH3yS/aD+KibMNInn7g352OZIyJM1boEXTNl+5ixq1peFuOUXviUn575/0EAwGnYxlj4oQVeoRdOHcB1/9oIUnNW2lkPo/d8SAnq447HcsYEwes0KMgOyePWx+9m6TQWzQnXcSKf3uRHRvXOR3LGBPjrNCj5KMnS4/byVJjTFRZoUfZBydLxU6WGmOiygq9D5x9svSx/3O/05GMMTHICr2P/PVkaWLzAZpOzmL/hpVORzLGxBgr9D6UnZPHzJuzUXGz+n93EQoOqFuvGmP6OSv0PjZp0cfJSt1AU1Ihf7zve07HMcbEECt0B9zww2+R1LSLqlOz2PnmC07HMcbEiK7cseg3IlIpIjvOMWauiGwVkRIRWR3ZiLHHk5DAZbefh2iYjU8cJ+j3Ox3JGBMDunKEvgxY3NGDIpIO/BK4TlUnATdGJlpsGzdnEUOzN9GcNJbl9/7A6TjGmBjQaaGr6hqg9hxDbgZWqOqhtvGVEcoW867//gMkN+2gpvFStr7we6fjGGMGuEjMoY8HMkTkbRHZLCK3djRQRJaISLGIFFdVVUVg1wOb2+Nh/tem4wr52by8Af+ZeqcjGWMGsEgUugeYDlwDLAK+LSLj2xuoqo+oapGqFmVnZ0dg1wNf/vTZ5ORvpTmpgOX3/pfTcYwxA1gkCv0I8KqqNqhqNbAGmBqB7caN677zAMnN73EqcCl/eXaZ03GMMQNUJAr9eeAyEfGISDJwMVAage3GlcX3zsMdamTbyy6aTp3rlIUxxrSvK8sWnwY2AhNE5IiI3C4id4rInQCqWgq8CrwPvAs8qqodLnE07RtROI38cTvxJ45k+f/9udNxjDEDkN0kup9Zdtt/0OAr4sKZe5l925edjmOM6WfsJtEDyDXfvh5v4BQ7V6dRV1nhdBxjzABihd7PZI8pZMzUg7QkDudP9z/qdBxjzABihd4PLbj730gJbKDedQmrfvmQ03GMMQOEFXo/9Q8/uAVfSw37/pJD7aF9TscxxgwAVuj9VMaIUUyYeYIW3xBe/PdnnY5jjBkArND7sTlf+hqpuoEzvpm88eCPnY5jjOnnrND7uY//cAkJzcc4sOM8TuzZ7nQcY0w/ZoXez6VkDWfS/AYC3lRe+dErTscxxvRjVugDwKxblpAu62hIKOLP/+/7TscxxvRTHqcDmK75xH/czZP3vMiRsikc2f4XRl5w0UfGhIJBDr+3kb3rNlJzsJ7musEEw8MIejPxBo7jS6ggc7SbC65eQN7UmT3KEQoG2bvmVXa9vZm6o24CwZFAC5MWCjM/98VePktjTG/YW/8HkM3LH2fTa8NI8u/k4z+4npI3XuXEruM01PoIBrIIeHIIegf/bby35RSe0DHc7jqCoWz8CXmoywuAz1+Jl0MMzjrD6JljmXrtp/AkJHxkn3WVFby34jkqSqpprsukxVNA0JsKgCvkJ6GlnKB7KAFvKqnhDVz7vS+QMSK/b34hxsShc7313wp9gHn6q9+mNnDF333PFfLja6nA464kKa2R7LEZnD/vCkYUTvu7cfXVx3lvxXMc3V5Fc90QWjyjCXpTAHAHm/AFDpIwqJLkdKiv9BII5OJPGIm63AD4/FV4KWfQkHpGFRUw9R9uImFwCpX7Snjlh89zxjcTn7+agqkHWXjPN/rmF2JMnLFCjyEtTY089y8/Rtxh0kf6KLhoCuMvW9Tu0XVnQsEgu1a+xJ7VW6k77iMQzsOfMALE1fYicYiExONkFniYfPX8TqdpVv/qZ+zZlE1L4nAG+YtZ9I2FH3lRMcb0jhW66bKqslKObNvCxIXXkTA4pds/X199nOe/9TB14dm4Q40Mz93KtQ/cj9tjp2uMiQQrdNPnNi9/nK0vBGhOGk1SUwmX3T6ecXMWOR3LmAGvV5fPFZHfiEiliJzzphUicpGIhETkH3sa1MSO6Z+8lVse/gzZSavw+8by5hNhnv2Xb9PS1Oh0NGNiVlfWoS8DFp9rgIi4gf8EXotAJhMjfEnJ3PTf32f+54SElv1UNV3BE3c+zfrHHyUUCjkdz5iY02mhq+oaoLObXH4VWA5URiKUiS3jL1/M55feSe7QtQQ9WWzdMIbf3v40v7//IY6VlTkdz5iY0aU5dBEpAF5S1cntPJYLPAXMA5a2jftDB9tZAiwByM/Pn15eXt7j4GZgqtq3g9XLXuX0kSyaE/ORcICk0F5Gzkzj8ltvwteD1TrGxJNenxTtpNCfA36qqu+IyDLOUegfZidFzebXXqfkhR00NY8l6B2Mt+UkyanlfOzTlzBxZs/eyWpMrIt2oR8ApO3LLKARWKKqfzrXNq3QzV811Z9h5dKnqdwWosk3FsRFkn8/QwqDzPvip0jNGOJ0xHa1+P388Xu/4szRFOZ87ULGfWy605FMHIhqoZ81bhl2hG56Yf+2rWx64i0aakbSkpCFO9hIkmcv468ay4xrr8btdjsdEYB3X3qZ7X+oojkxDzRMUst+Pv/oHf0mn4ldvSp0EXkamEvr0fcJ4DuAF0BVHz5r7DKs0E0EBAMB1j6zgvI1J2hiPGG3j4TmClJyq7nsn64l57yxjuQ6WVXJS9/9HXWBC/AEGxhReAJ/nZ/KyskMz9nJJx/4Z0dymfhhbywyA1rV0SOsfvSPnD6Q0nYiNUiyljL3nvkUTDrnPxoj6rX/fYzyTckEfJkM1vdZfP/HGZZfQDAQ4PEly2hx5zD/K8Nt6uUcwuEwjWWHSc4bjstOgPeIFbqJGVtef5Mdf9rOmeBEREOkD9nN9d+6neSU1Kjt81DpTlb+ZCWN3kkk+I8zbqGHy2++6e/G7Nq0iVWP1pIQLOfzj37Rpl6AUCBI1Xv7OL6ljMqyU9SeVE5rOkFPEhPO9zLnzln4EqN/SYhDJTXsXF/BrBvGkpadFPX9RZsVuok5JevX8+7SbTT6zsfnryJvRiMLl9wa0SINBgI8/8OHqTo8mrDLS9rgEm747h0dvng898DPqKy8gBG5O/nEt+Nr6iXY2MyJ4j0c31pOVXkdtaddnJYMwm4fAK5wgJRwLUNSQrgzMth3LInUzETmf2EiOWPTo5Zr/5ZKXl9aQjikJCR7WHDbRAouyIra/vqCFbqJWW/8+gnKN3jwJwwjyb+H6V+YyNTL5/R6u1vfWsXmx8toThxNYnMZRbeN73S7wUCAx774GAHPCBbclcPYabF/pcnakoO8/tB6aiUbdbUebbtDzaRxiiHpSvaodIZPK2Do9LF4Ej+YYqnYe4qVj+2krqaZaQvymXHdaDzeyP6rZvem46x8rJRhBSnM+fQE3nqilOojZ7jo6gIuumY04pLON9IPWaGbmNbceIbnv/8oJ6vGEXb5SPFtZ/F9N5GdO7Jb22msr+O919/iwOoy6pon4wr7GVpQzvX3fbnLR/4733mH1UtPxsXUy9G123llWRkh8TAm6zRDxwxhxPQxZE09D5en8+fd0hxk/fJ97FxbwZCcQSz4wkSy87t/hc/2lKw9yttP7SZ3fDpXf3kKvkQPwZYQq5/aza53jjNqciYLbptI4iBvRPbXl6zQTVw4vGc3b/3kFc7IZDzBM2SPPsJ1934Jj/ejf2mDgQA71q/nwMad1B/yE2jKwO/L+dtR5qDgDuZ/YxF54yd0O8ez336IqqopjMgr5RP339Xr59Uf7V2xjpWv1OEJ+7n69vHkXDKpx9sq31HDW0+U0lwfoOiaAqYvHoXL3fPbHW9beZh1z+1l1ORMFi+ZjMf3wYuLqlKytoK1v9/D4IwEFn/pArLzevci0ljXgtsjJCT3zYuDFbqJK++88BIlKyppTiwgsfkQE65NY2ThOHau2kTtntO01A+mxZ1LyNN6gswVaiYheBRvSj1DxqZROLeIMVOm9nj/H0y9DGfhV0dy3tQLI/XU+oWtD7/Chi1uBoVOcd03ZpExIa/X22xuCLDmmT3s/csJhhaksuALhWQMH9Tt7RS/fJBNL5Rx3rRsFt4+Cben/ReG4wdO8+r/7qC5IcDcz07g/JkjurWfcFg5VFJDydoKyrdXk5yWwDV3Ten1i0NXWKGbuBMKhXjxp49QuWsYAd8HJ90kHMLXUoE3sZaUPB9jZhUycfbsiF9DZueGjaz+7WkSggf4/KNLHJ162fXM29Qfr2PakivxJCf2eDvhcJiNP1zB1iNDGBI6zvU/WEzysMi+i3dv8QlWP72bYEuYWTecx5S5I7s0162qvPN8GVteLWf8xcOYf2thp0f5jXUtvL50B0d3n2Ly5blceuO4Dl8A/qq+tpnS9RWUbjjGmZN+klK8jL94OPs3V9LcGGTR7ZMomBLdk65W6CZunaw8wWv//RTiEnKm5jN14dw+u5TAs/f/jKqaCxybegkHQ6z53h8oqcwGIClwkmlFSUy540rc3u4tFwwHQ7xx3zPsqx9BjquCa378SXyDo7MEsOG0n1W/20X59hpyJ6Qz79ZCUjM73peqsu7Zvby/6ggTL81h7s0TunzCMxwK887zZbz3+iGGjU5l8ZLJDM5I/MiYg9tr2LmugkMlNSiQXziEiZfmUDAlC7fHRcNpP3/+n/epPlzP7H8cx5R5IxGJzklXK3RjHNA69fI4Ac8wrvxaXq+mcbrLf7Kel+9/nopwDnneCsbNzKH4rUrqvENJCVRz0bwsJnxmLi5X53PVLWea+PO9f6AilMvYlGMs/NGnu3TSszdUldINx1j37F4QuOymcZw/a8RHSjIcVlY/uYud648xZd5ILr1xXI+KdP+WSlY+VorH52LRHZPJnZBBXXUTO9uOxhtPtzAozUfh7BwKLxlBatZHX2AC/hBv/nYnZVuruODyXC69aVyvzgV0xArdGIfsWL+etcvqSQwd4NZf983Uy8nScl78yTvUezK5MP8Us+77BC6Xi3AwxI7fvsHmd87Q6B1CRvAEMz8+mjHXdnxly8YTtTz/rVepdQ/nwrzav22rr9RVN7HysVIq9p6iYEoWV3zufJJTW9e2h0Nh3lxWyt6/nGD6VaO4+LoxvToqPnm8gVce3s6pyiaGj07lWNlpBBg1OZOJl+YwanJmpwWtYWXDH/ez9Y1D5E/KZNEdk/AlRfbNU1boxjjo9/c/RHXNFHJG7eKG+74S1X0dePld3lx+nJB4mLsgmfM/PfcjY4LNft771ats26H4vakM1Qou+ewUcudM+btxJ3cf5oUfb6TBnc4l08Nc+KVz3rgsajSsbHvrMO/8qQxvopu5NxrN6p0AAAbOSURBVE+g4IIsXl9aQtnWKi6+fgxFVxVEZF8tzUFWP7WbyvJ6xl00jMJLRpAypPvnHUrWHmX103sYMiKZa+6a2qNtdMQK3RgHfXjqZdE9oxg9+YKo7Gfzz19k044EkkJ1XPWlyQyfcf45x7fUNfDuz1+h5GAiQU8yI90VXHLHTLKnjaViQwkvL91D0JXAgqvTGHvD7Khk7o7aigbeXLaTqkP1pGQmUl/TzKU3jmPq/N6vsomGwztrefWR7Xh8bq65awpDR0Xm8hRW6MY4bMe6dax97AwJoQN8PsJTLyF/gDe/9Sz76keQFT7GP3x3MckjMrv8840natn4s9fYU5WBipuRCSc41pSBW4Nc9YUx5F4WnRegngiFwmx+pZytbx5i9ifHMumyXKcjnVNtRQMv/c82mupaWPhPkxgzLbvX27RCN6Yf+P19D1F9cgq5+bv4+DcjM/XSeKyGl77zKlWuEYxNOcaCH9yEO6Fnb3CpK6tg/S9WceDMUJJDp7juXy9iyKSCiOSMNFWN2iqSSGusa+HlX73PiYN1zLrhPKYtzO9Vdit0Y/qBFr+fJ770O5oTR+MJNpGs9QxOCJKS6iJ16CDS84YwZHwO6RNG/t11Tzpy4i+7ePnhHTS5U5kxqZmiu6+LSM66sgoSMlNJSBscke0ZCLaEWPlYKfs2VzLx0hzmfGY87h6ugDlXoXd6+lVEfgNcC1R2cAu6zwL3tn15Bviyqm7rUVJjYpgvIYFL7/0YO363nuSmDM40KKf9CRyrTUNPeWBPAFaWgx4gKVhHsquJlEFKSkYC6TkppI8eypDz80jOyWTvc2t5+40ziPi46vo0Rl9zZcRypo7Jidi2TCuPz82Vt08ibWgSm18px+0W5nym+5eV6ExX7lg0h9aifryDQr8EKFXVkyJyFfDvqnpxZzu2I3RjWoWDIU7vr+Dk7iOcLK+h7sQZ6k4FOdPsplEH0eL9+yNld7CZkNtHSrCGa//14n47LWLat3vTcUaMTTvnm6XOpVdH6Kq6pu2eoh09vuFDX74DdO8Sd8bEOZfHTcaEvA6vieKvraOm9DAn9x/n9NFT1FU34/EKl33jWhKGRO/GHiY6Jlw8PGrbjvTtQm4HXunoQRFZAiwByM/Pj/CujYlNCUNSyZk9iZzZPb+ioYkPEXvLl4hcQWuh39vRGFV9RFWLVLUoO7v3y3eMMcZ8ICJH6CIyBXgUuEpVayKxTWOMMd3T6yN0EckHVgC3qOqe3kcyxhjTE11Ztvg0MBfIEpEjwHcAL4CqPgw8AGQCv2xbLB/s6AysMcaY6OnKKpfPdPL4HcAdEUtkjDGmR/ruOpjGGGOiygrdGGNihBW6McbECMcuziUiVUD5Wd/OAqodiNNf2POP7+cP9juw59/58x+lqu2+kcexQm+PiBTH8woZe/7x/fzBfgf2/Hv3/G3KxRhjYoQVujHGxIj+VuiPOB3AYfb8Tbz/Duz590K/mkM3xhjTc/3tCN0YY0wPWaEbY0yM6HeFLiI3ikiJiIRFJG6WL4nIYhHZLSL7ROT/Op2nL4nIb0SkUkR2OJ3FCSKSJyKrRKS07f/9u53O1JdEJFFE3hWRbW3P/7tOZ3KCiLhF5D0Reamn2+h3hQ7sAD4BrHE6SF8RETfwP8BVwETgMyIy0dlUfWoZsNjpEA4KAl9X1UJgJnBXnP339wPzVHUqcCGwWERmOpzJCXcDpb3ZQL8rdFUtVdXdTufoYzOAfapapqotwDPA9Q5n6jOqugaodTqHU1T1mKpuafu8nta/1LnOpuo72upM25feto+4Wq0hIiOBa2i9UVCP9btCj1O5wOEPfX2EOPoLbT7QdkP2acAmZ5P0rbbphq1AJfCGqsbV8wceAr4BhHuzEUcKXUTeFJEd7XzEzVHpWaSd78XVEYoBERkMLAfuUdU6p/P0JVUNqeqFwEhghohMdjpTXxGRa4FKVd3c221F5J6i3aWqC5zYbz92BMj70NcjgQqHshgHiIiX1jJ/UlVXOJ3HKap6SkTepvWcSrycJJ8NXCciVwOJQKqI/E5VP9fdDdmUS//wF2CciIwWER/waeAFhzOZPiKt925cCpSq6oNO5+lrIpItIultnycBC4BdzqbqO6p6n6qOVNUCWv/uv9WTMod+WOgickPbvUtnAX8WkdeczhRtqhoE/hl4jdYTYs+qaomzqfpO231rNwITROSIiNzudKY+Nhu4BZgnIlvbPq52OlQfGgGsEpH3aT24eUNVe7x0L57ZW/+NMSZG9LsjdGOMMT1jhW6MMTHCCt0YY2KEFboxxsQIK3RjjIkRVujGGBMjrNCNMSZG/H+Dy60w4w/97AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des paramètres du modèle obtenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention : pas sûr que les hyperparamètres soient sauvegardés également\n",
    "torch.save(LMtransformer.state_dict(), \"params/LMtfparams\"+str(np.random.rand())[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Later to restore: \n",
    "#LMtransformer.load_state_dict(torch.load(\"params\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bidouilles pour adapter nos fonctions aux fonctions common codées par Nathra \n",
    "#(sequence list of ints en entree, list of probas en sortie)\n",
    "#(Faire mieux plus tard)\n",
    "def LMtransformerprediction(listints):\n",
    "    return np.exp(LMtransformer(torch.tensor([listints]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerprediction, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq_maison(prev_seq):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\n",
    "        tokens_pred = vocab_numeroted[indice]\n",
    "        print(' '.join(tokens_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 197.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> <unk> <unk> <unk> d ' <unk> dans <unk> , ou la <unk> de <unk> <unk> <unk> <unk> <unk> de <unk> <unk> de <unk> . pour <unk> , `` d ' <unk> , la <unk> , la <unk> <unk> , `` d ' <unk> , la <unk> , `` de <unk> . il , `` de la surface d ' <unk> , `` <unk> , en <unk> , le <unk> , `` ' <unk> titres : `` ' <unk> `` <unk> <unk> `` ' <unk> <unk> <unk> `` dur comme <unk> <unk> <unk> <unk> <unk> `` ' <unk> `` '\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['il'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:02<00:00, 47.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", a barcelone , a barcelone , il est touche par l ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['a','l','age','de','31','ans'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:02<00:00, 44.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade est alors persuade d ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' esprit\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['barcelone',',','il','est','touche','par','l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a l ' age de 31 ans , a barcelone , il est touche par l ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d '\n"
     ]
    }
   ],
   "source": [
    "if len(tokens)<100:\n",
    "    print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
