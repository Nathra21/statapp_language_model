{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformer_model import *\n",
    "import nltk\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from statapp.common.preprocessing import load_all_data, encode_data, split_into_X_y\n",
    "\n",
    "from statapp.common.sampling import sample_token_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing maison assez brouillon pour le moment... L'encodage est effectué au niveau des mots. Les données exploitées sont placées dans le dossier data dans le dossier du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_all_data(\"data/fr.train.top1M.txt\", sample=0.00001)\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "vocab = list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {}\n",
    "\n",
    "for word in vocab:\n",
    "    dico[word]=0\n",
    "    \n",
    "for token in tokens:\n",
    "    dico[token]+=1\n",
    "    \n",
    "sorted_list = sorted(dico.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_dico = {}\n",
    "\n",
    "for i in range(min(len(sorted_list),vocab_size-1)):\n",
    "    sorted_dico[sorted_list[i][0]] = sorted_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokens)):\n",
    "    if tokens[i] not in sorted_dico:\n",
    "        tokens[i] = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données exploitées contiennent 553 tokens (mots) au total.\n",
      "La taille du vocabulaire ainsi constitué est de 270\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(tokens))\n",
    "\n",
    "if \"<unk>\" not in vocab:\n",
    "    vocab.append(\"<unk>\")\n",
    "    \n",
    "vocab_size = len(vocab)\n",
    "\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\n",
    "tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "\n",
    "tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "\n",
    "nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_test = load_all_data(\"data/fr.train.top1M.txt\", sample=0.05, part=\"end\")\\n\\ntokens_test = nltk.word_tokenize(text_test)\\n\\nvocab_test = list(set(tokens_test))\\n\\nvocab_size_test = len(vocab_test)\\n\\nvocab_numbers_test = dict(zip(vocab_test, range(0,len(vocab_test))))\\nvocab_numeroted_test = dict(zip(range(0,len(vocab_test)), vocab_test))\\ntokens_numbers_test = np.array([vocab_numbers_test[tokens_test[i]] for i in range(len(tokens_test))])\\n\\ntokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\\ntokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\\n\\nnb_sequences_test =  tokens_numbers_sequences_test.shape[0]\\n\\nprint(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\\nprint(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size_test))'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"text_test = load_all_data(\"data/fr.train.top1M.txt\", sample=0.05, part=\"end\")\n",
    "\n",
    "tokens_test = nltk.word_tokenize(text_test)\n",
    "\n",
    "vocab_test = list(set(tokens_test))\n",
    "\n",
    "vocab_size_test = len(vocab_test)\n",
    "\n",
    "vocab_numbers_test = dict(zip(vocab_test, range(0,len(vocab_test))))\n",
    "vocab_numeroted_test = dict(zip(range(0,len(vocab_test)), vocab_test))\n",
    "tokens_numbers_test = np.array([vocab_numbers_test[tokens_test[i]] for i in range(len(tokens_test))])\n",
    "\n",
    "tokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\n",
    "tokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\n",
    "\n",
    "nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size_test))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "#Correspond à utiliser l'entropie croisée puisque les sorties sont des log_softmax\n",
    "#et l'entropie croisée = nll_loss(log_softmax(.), target)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(LMtransformer.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nb_epochs, batch_size):\n",
    "    \n",
    "    #What is this ?? I don't remember. Make grad required ?\n",
    "    LMtransformer.train()\n",
    "    \n",
    "    #pas pour l'affichage progressif de la loss\n",
    "    step = max(1,((len(tokens)-max_length-1)/batch_size)//5)\n",
    "    \n",
    "    epochs_losses = []\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        running_loss = 0\n",
    "        \n",
    "        randperm = torch.randperm(nb_sequences)\n",
    "        randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "        \n",
    "        \n",
    "        # running_loss_test = 0\n",
    "        \n",
    "        # randperm_test = torch.randperm(nb_sequences_test)\n",
    "        #randperm_test = randperm_test[:(nb_sequences//batch_size)*batch_size]\n",
    "        #batchs_indices_test = randperm_test.reshape(nb_sequences_test//batch_size, batch_size)\n",
    "        \n",
    "        \n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            \n",
    "            batch = tokens_numbers_sequences[batch_indices]\n",
    "            optimizer.zero_grad()\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Il faudrait adapter les affichages en fonction du nombre de batchs total\n",
    "            running_loss += loss.item()\n",
    "            if i % step == step-1:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / step))\n",
    "                \n",
    "                #stock pour affichage graphique\n",
    "                epochs_losses.append(epoch-1+(i/((len(tokens)-max_length-1)/batch_size)))\n",
    "                losses.append(running_loss / step)\n",
    "                \n",
    "                running_loss = 0.\n",
    "                \n",
    "        plt.plot(epochs_losses, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'overfitting sur un cas ultrasimplifié (5 tokens, longueur de séquence 1, 3 decoders, 2 heads) :\n",
    "- En observant les sorties le modèle a bien appris et overfitte ! (loss à 0 au bout de 5-6 epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 5.116\n",
      "[1,    20] loss: 3.388\n",
      "[1,    30] loss: 2.439\n",
      "[1,    40] loss: 1.848\n",
      "[1,    50] loss: 1.652\n",
      "[2,    10] loss: 1.190\n",
      "[2,    20] loss: 1.057\n",
      "[2,    30] loss: 0.927\n",
      "[2,    40] loss: 0.965\n",
      "[2,    50] loss: 0.809\n",
      "[3,    10] loss: 0.732\n",
      "[3,    20] loss: 0.746\n",
      "[3,    30] loss: 0.617\n",
      "[3,    40] loss: 0.643\n",
      "[3,    50] loss: 0.697\n",
      "[4,    10] loss: 0.482\n",
      "[4,    20] loss: 0.597\n",
      "[4,    30] loss: 0.684\n",
      "[4,    40] loss: 0.612\n",
      "[4,    50] loss: 0.535\n",
      "[5,    10] loss: 0.452\n",
      "[5,    20] loss: 0.546\n",
      "[5,    30] loss: 0.545\n",
      "[5,    40] loss: 0.542\n",
      "[5,    50] loss: 0.580\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des paramètres du modèle obtenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention : pas sûr que les hyperparamètres soient sauvegardés également\n",
    "torch.save(LMtransformer.state_dict(), \"params/LMtfparams\"+str(np.random.rand())[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Later to restore: \n",
    "#LMtransformer.load_state_dict(torch.load(\"params\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bidouilles pour adapter nos fonctions aux fonctions common codées par Nathra \n",
    "#(sequence list of ints en entree, list of probas en sortie)\n",
    "#(Faire mieux plus tard)\n",
    "def LMtransformerprediction(listints):\n",
    "    return np.exp(LMtransformer(torch.tensor([listints[-8:]]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerprediction, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def gen_seq_maison(prev_seq):\\n    with torch.no_grad():\\n        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\\n        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\\n        tokens_pred = vocab_numeroted[indice]\\n        print(' '.join(tokens_pred))\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def gen_seq_maison(prev_seq):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\n",
    "        tokens_pred = vocab_numeroted[indice]\n",
    "        print(' '.join(tokens_pred))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 94.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pourrait confondre avec la surface d ' une guerre entre la pologne et la ruthenie qui dure depuis plusieurs annees . ainsi , dans la chambre de commerce autres artistes : `` quand on a que la haine `` d ' oth , `` madame reve `` d ' alain bashung , `` la chanson du forcat `` de serge gainsbourg et `` vive ma liberte `` d ' oth , `` madame reve `` d ' alain bashung , `` la chanson du forcat `` de `` de `` de serge gainsbourg et `` vive ma liberte `` d\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['il'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 89.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans , a barcelone , il est touche par l ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu ces derniers sont entres sur les territoires de lech ii le noir pour aller aider leon ier de galicie . l ' histoire de la commune de tusson pendant la seconde moitie du xxe siecle a ete marquee par la personnalite roger ducouret , cue des lettres et des nombres , l ' inspiration prophetique apres avoir obtenu la connaissance du vrai nom de dieu ces derniers sont entres sur les territoires de lech ii le noir\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['a','l','age','de','31'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 96.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de charge aerienne et assume le role de centre distributeur de marchandises de la zone nord peninsulaire . pour favoriser cette activite , on constitue en 1994 la societe via , formee par aena , la mairie de vitoria-gasteiz , la chambre de commerce et d ' industrie d ' alava , la deputation forale et le gouvernement basque . 30 | 31 | 31 | 31 | 32 | 33 | 34 | 36 | 37 | 38 | 39 l ' album studio a ete enregistre par loic boisgirard au studio praxis a cagnes sur mer . il\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 91.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' esprit prophetique apres avoir obtenu la connaissance du vitoria-gasteiz de s ' ecraser valeur de tusson pendant la seconde moitie lumiere sur la surface du goudron qu ' il pourrait confondre avec la surface d ' une guerre entre la pologne et la ruthenie qui dure depuis plusieurs annees . ainsi , en 1281 , les polonais ont deja vaincu une armee mongole pres de goslicz , lorsque ces derniers sont entres sur les territoires de lech ii le noir pour aller aider leon ier de galicie galicie galicie . l ' histoire de la commune de tusson pendant\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['barcelone',',','il','est','touche','par','l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tokens)<100:\n",
    "    print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
