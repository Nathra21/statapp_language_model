{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformer_model_GPU import *\n",
    "import nltk\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from statapp.common.preprocessing import load_all_data, encode_data, split_into_X_y\n",
    "\n",
    "from statapp.common.sampling import sample_token_sequence\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing maison assez brouillon pour le moment... L'encodage est effectué au niveau des mots. Les données exploitées sont placées dans le dossier data dans le dossier du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir proportion multiple de 0.05\n",
    "\n",
    "def build_vocab(vocab_size=10000, proportion=0.1):\n",
    "    \n",
    "    dico = {}\n",
    "    \n",
    "    step = int(proportion*100//5)\n",
    "    \n",
    "    for i in range(step):\n",
    "        \n",
    "        text = load_all_data(\"data/fr.train.top1M.txt\", start=i*0.05, sample=0.05)\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        vocab = list(set(tokens))\n",
    "        vocab.sort()\n",
    "        \n",
    "        for word in vocab:\n",
    "            if word not in dico.keys():\n",
    "                dico[word]=0\n",
    "\n",
    "        for token in tokens:\n",
    "            dico[token]+=1\n",
    "\n",
    "    sorted_list = sorted(dico.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    sorted_dico = {}\n",
    "\n",
    "    for i in range(min(len(sorted_list),vocab_size-1)):\n",
    "        sorted_dico[sorted_list[i][0]] = sorted_list[i][1]        \n",
    "    \n",
    "    vocab = list(sorted_dico.keys())\n",
    "    vocab.append(\"<unk>\")\n",
    "    vocab.sort()  \n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(vocab_size=5000, proportion=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_train(start, sample, vocab):\n",
    "    \n",
    "    text = load_all_data(\"data/fr.train.top1M.txt\", start=start, sample=sample)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in vocab:\n",
    "            tokens[i] = \"<unk>\"       \n",
    "\n",
    "    vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "    tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "    tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "    tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "    \n",
    "    #if USE_CUDA:\n",
    "    #    tokens_numbers_sequences.to(device)\n",
    "    \n",
    "    return tokens_numbers_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvocab = list(set(tokens))\\n\\nif \"<unk>\" not in vocab:\\n    vocab.append(\"<unk>\")\\n    \\nvocab.sort()\\n    \\nvocab_size = len(vocab)\\n\\nvocab_numbers = dict(zip(vocab, range(0,len(vocab))))\\nvocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\\ntokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\\n\\ntokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\\ntokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\\n\\nnb_sequences =  tokens_numbers_sequences.shape[0]\\n\\nprint(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\\nprint(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "vocab = list(set(tokens))\n",
    "\n",
    "if \"<unk>\" not in vocab:\n",
    "    vocab.append(\"<unk>\")\n",
    "    \n",
    "vocab.sort()\n",
    "    \n",
    "vocab_size = len(vocab)\n",
    "\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\n",
    "tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "\n",
    "tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "\n",
    "nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Constitution d\\'un jeu de test numéroté selon le vocabulaire du jeu d\\'entrainement\\n\\ntext_test = load_all_data(\"data/fr.train.top1M.txt\", start=0.9, sample=0.1)\\n\\ntokens_test = nltk.word_tokenize(text_test)\\n\\nfor i in range(len(tokens_test)):\\n    if tokens_test[i] not in vocab:\\n        tokens_test[i] = \"<unk>\"\\n\\ntokens_numbers_test = np.array([vocab_numbers[tokens_test[i]] for i in range(len(tokens_test))])\\n\\ntokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\\ntokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\\n\\nnb_sequences_test =  tokens_numbers_sequences_test.shape[0]\\n\\nprint(\"Les données de test exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Constitution d'un jeu de test numéroté selon le vocabulaire du jeu d'entrainement\n",
    "\n",
    "text_test = load_all_data(\"data/fr.train.top1M.txt\", start=0.9, sample=0.1)\n",
    "\n",
    "tokens_test = nltk.word_tokenize(text_test)\n",
    "\n",
    "for i in range(len(tokens_test)):\n",
    "    if tokens_test[i] not in vocab:\n",
    "        tokens_test[i] = \"<unk>\"\n",
    "\n",
    "tokens_numbers_test = np.array([vocab_numbers[tokens_test[i]] for i in range(len(tokens_test))])\n",
    "\n",
    "tokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\n",
    "tokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\n",
    "\n",
    "nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "print(\"Les données de test exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif USE_CUDA:\\n    tokens_numbers_sequences.to(device)\\n    tokens_numbers_sequences_test.to(device)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "if USE_CUDA:\n",
    "    tokens_numbers_sequences.to(device)\n",
    "    tokens_numbers_sequences_test.to(device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Creation Fichier Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé des fichiers contenant 5% du data set initial, vocabulaire taille 20K et etendu=5 (voir train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-94c45ce61ad7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfichier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmon_pickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfichier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mmon_pickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_data_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-6b2f3b31b7d0>\u001b[0m in \u001b[0;36mload_data_train\u001b[1;34m(start, sample, vocab)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"<unk>\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "for i in range(20):\n",
    "    name = \"Taille5_Voca20K_\" + str(i)\n",
    "    with open(name,'wb') as fichier:\n",
    "        mon_pickler = pickle.Pickler(fichier)\n",
    "        mon_pickler.dump(load_data_train(i*0.05, 0.05, vocab))\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "if USE_CUDA:\n",
    "    LMtransformer.to(device)\n",
    "\n",
    "#Correspond à utiliser l'entropie croisée puisque les sorties sont des log_softmax\n",
    "#et l'entropie croisée = nll_loss(log_softmax(.), target)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(LMtransformer.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nb_epochs, batch_size, proportion):\n",
    "    \n",
    "    #What is this ?? I don't remember. Make grad required ?\n",
    "    LMtransformer.train()\n",
    "    \n",
    "    epochs_losses = []\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    etendu = 5\n",
    "    \n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        running_loss = 0\n",
    "        \n",
    "        print(\"Test epoch : \", epoch)\n",
    "        \n",
    "    \n",
    "        for step in range(int(proportion*100//etendu)):\n",
    "            \n",
    "            print(\"Test step 1 : \", step)\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            name = \"Taille5_Voca20K_\" + str(step)\n",
    "            with open(name,'rb') as fichier:\n",
    "                mon_depickler = pickle.Unpickler(fichier)\n",
    "                tokens_numbers_sequences = mon_depickler.load()   \n",
    "                \n",
    "            \"\"\"\n",
    "            \n",
    "            tokens_numbers_sequences =load_data_train(step*0.05, 0.05, vocab)\n",
    "            \n",
    "       \n",
    "            if USE_CUDA:\n",
    "                tokens_numbers_sequences.to(device) \n",
    "                \n",
    "            nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "        \n",
    "            randperm = torch.randperm(nb_sequences)\n",
    "            randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "            batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "            \n",
    "            print(\"Test step 2 : \", step)\n",
    "\n",
    "            for i, batch_indices in enumerate(batchs_indices):\n",
    "\n",
    "                batch = (tokens_numbers_sequences[batch_indices]).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = LMtransformer(batch[:,:-1])\n",
    "                loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                test_loss = 0\n",
    "\n",
    "                #Il faudrait adapter les affichages en fonction du nombre de batchs total\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                #Calcul de la loss sur les données de test\n",
    "                \"\"\"\n",
    "                if USE_CUDA:\n",
    "                    test_output = (LMtransformer(tokens_numbers_sequences_test[:,:-1])).cuda()\n",
    "                    test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "                else:\n",
    "                    test_output = LMtransformer(tokens_numbers_sequences_test[:,:-1])  \n",
    "                    test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "\n",
    "                print('[%d, %5d] loss: %.3f ; test_loss : %.3f' %\n",
    "                        (epoch + 1, i + 1, running_loss / step, test_loss))\n",
    "                \"\"\"\n",
    "            \n",
    "            nb_batches_in_the_step = nb_sequences//batch_size\n",
    "\n",
    "            print('[%d, %5d] loss: %.3f ' %\n",
    "                (epoch + 1, i + 1, running_loss / nb_batches_in_the_step))\n",
    "                    \n",
    "            #stock pour affichage graphique\n",
    "            epochs_losses.append(epoch-1+step)\n",
    "            losses.append(running_loss / nb_batches_in_the_step)                    \n",
    "                    \n",
    "            #test_losses.append(test_loss)\n",
    "\n",
    "            running_loss = 0.\n",
    "\n",
    "            end = time.time()\n",
    "            print(\"Temps : \", end-start)\n",
    "\n",
    "    plt.plot(epochs_losses, losses)\n",
    "    #plt.plot(epochs_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'overfitting sur un cas ultrasimplifié (5 tokens, longueur de séquence 1, 3 decoders, 2 heads) :\n",
    "- En observant les sorties le modèle a bien appris et overfitte ! (loss à 0 au bout de 5-6 epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch :  0\n",
      "Test step 1 :  0\n",
      "Test step 2 :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christos\\Desktop\\Git\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model_GPU.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = (torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  6315] loss: 4.025 \n",
      "Temps :  509.0999028682709\n",
      "Test step 1 :  1\n",
      "Test step 2 :  1\n",
      "[1,  6308] loss: 3.944 \n",
      "Temps :  1013.5090925693512\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(1,400,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 step :  0\n",
      "Test 2 step :  0\n",
      "Test 1 step :  1\n",
      "Test 2 step :  1\n",
      "[1] loss: 3.953 \n",
      "Temps :  407.90645027160645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17a1fa1bef0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Train Loss\n",
    "\n",
    "n = 1\n",
    "batch_size = 400\n",
    "\n",
    "epochs_losses = []\n",
    "train_losses = []\n",
    "    \n",
    "start = time.time()\n",
    "    \n",
    "for epoch in range(n):\n",
    "    \n",
    "    running_loss = 0\n",
    "    nb_batches_in_the_epoch = 0\n",
    "    \n",
    "    for step in range(int(0.1*100//5)):\n",
    "\n",
    "        print(\"Test 1 step : \", step)\n",
    "\n",
    "        tokens_numbers_sequences = load_data_train(step*0.05, 0.05, vocab)\n",
    "\n",
    "        if USE_CUDA:\n",
    "            tokens_numbers_sequences.to(device) \n",
    "\n",
    "        nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "        randperm = torch.randperm(nb_sequences)\n",
    "        randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "\n",
    "        print(\"Test 2 step : \", step)\n",
    "\n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            batch = (tokens_numbers_sequences[batch_indices]).to(device)\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        nb_batches_in_the_epoch += nb_sequences//batch_size\n",
    "\n",
    "    print('[%d] loss: %.3f ' %\n",
    "        (epoch + 1, running_loss / nb_batches_in_the_epoch))\n",
    "\n",
    "    epochs_losses.append(n+1)\n",
    "    train_losses.append(running_loss / nb_batches_in_the_epoch)                    \n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Temps : \", end-start)\n",
    "\n",
    "plt.plot(epochs_losses, train_losses)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul Erreur de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load(\"params/vocabData90percentSize30k\", map_location=torch.device('cpu'))\n",
    "vocab_size = len(vocab)\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 step :  0\n",
      "Test 2 step :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christos\\Desktop\\Git\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model_GPU.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = (torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)).to(device)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ecd2074364a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtokens_numbers_sequences_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLMtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Loss\n",
    "\n",
    "nb_epoch = 1\n",
    "batch_size = 400\n",
    "proportion = 0.1\n",
    "start = 0.9\n",
    "\n",
    "\n",
    "epochs_losses = []\n",
    "test_losses = []\n",
    "    \n",
    "begin = time.time()\n",
    "    \n",
    "for epoch in range(nb_epoch):\n",
    "    \n",
    "    name_model = \"params/LMtfparamsData90percentBatch512epoch\" + str(epoch+1)\n",
    "    lp = torch.load(name_model, map_location=torch.device('cuda:0'))\n",
    "    nb_decoders = lp[\"nb_decoders\"]\n",
    "    vector_size = lp[\"vector_size\"]\n",
    "    nb_heads = lp[\"nb_heads\"]\n",
    "    head_size = lp[\"head_size\"]\n",
    "    max_length = lp[\"max_length\"]\n",
    "    ffn_hidden_size = lp[\"ffn_hidden_size\"]\n",
    "    vocab_size = lp[\"vocab_size\"]\n",
    "    model_params_dict = lp[\"model_params_dict\"]\n",
    "\n",
    "    LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "    LMtransformer.load_state_dict(model_params_dict)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    test_loss = 0\n",
    "    nb_batches_in_the_epoch = 0\n",
    "    \n",
    "    for step in range(int(proportion*100//5)):\n",
    "\n",
    "        print(\"Test 1 step : \", step)\n",
    "\n",
    "        tokens_numbers_sequences_test = load_data_train(start + step*0.05, 0.05, vocab)\n",
    "\n",
    "        if USE_CUDA:\n",
    "            tokens_numbers_sequences_test.to(device) \n",
    "\n",
    "        nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "        randperm = torch.randperm(nb_sequences_test)\n",
    "        randperm = randperm[:(nb_sequences_test//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences_test//batch_size, batch_size)\n",
    "\n",
    "        print(\"Test 2 step : \", step)\n",
    "\n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            batch = (tokens_numbers_sequences_test[batch_indices]).to(device)\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "            test_loss += loss.item()\n",
    "\n",
    "        nb_batches_in_the_epoch += nb_sequences_test//batch_size\n",
    "\n",
    "    print('[%d] loss: %.3f ' %\n",
    "        (epoch + 1, test_loss / nb_batches_in_the_epoch))\n",
    "\n",
    "    epochs_losses.append(epoch+1)\n",
    "    test_losses.append(test_loss / nb_batches_in_the_epoch)                    \n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Temps : \", end-begin)\n",
    "\n",
    "plt.plot(epochs_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des paramètres du modèle obtenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "#Un dico  des hyperparams serait pratique ^^\n",
    "torch.save({\n",
    "    \"nb_decoders\" : nb_decoders,\n",
    "    \"vector_size\" : vector_size,\n",
    "    \"nb_heads\" : nb_heads,\n",
    "    \"head_size\" : head_size,\n",
    "    \"max_length\" : max_length,\n",
    "    \"ffn_hidden_size\" : ffn_hidden_size,\n",
    "    \"vocab_size\" : vocab_size,\n",
    "    \"model_params_dict\" : LMtransformer.state_dict()}\n",
    "    ,\n",
    "    \"params/LMtfparamsTEST\")\n",
    "    #\"params/LMtfparams\"+str(np.random.rand())[2:])\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "#Later to restore:\n",
    "lp = torch.load(\"params/LMtfparamsTEST\")\n",
    "\n",
    "nb_decoders = lp[\"nb_decoders\"]\n",
    "vector_size = lp[\"vector_size\"]\n",
    "nb_heads = lp[\"nb_heads\"]\n",
    "head_size = lp[\"head_size\"]\n",
    "max_length = lp[\"max_length\"]\n",
    "ffn_hidden_size = lp[\"ffn_hidden_size\"]\n",
    "vocab_size = lp[\"vocab_size\"]\n",
    "model_params_dict = lp[\"model_params_dict\"]\n",
    "\n",
    "LMtransformerTEST = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "LMtransformerTEST.load_state_dict(model_params_dict)\n",
    "\n",
    "#Attention, pour pouvoir générer il faut reconstruire le vocabulaire et ses numéros associés avec le code plus haut\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load(\"params/vocabData90percentSize30k\", map_location=torch.device('cpu'))\n",
    "vocab_size = len(vocab)\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selection du modèle\n",
    "\n",
    "name_model = \"params/LMtfparamsData90percentBatch512epoch\" + str(1)\n",
    "lp = torch.load(name_model, map_location=torch.device('cuda:0'))\n",
    "nb_decoders = lp[\"nb_decoders\"]\n",
    "vector_size = lp[\"vector_size\"]\n",
    "nb_heads = lp[\"nb_heads\"]\n",
    "head_size = lp[\"head_size\"]\n",
    "max_length = lp[\"max_length\"]\n",
    "ffn_hidden_size = lp[\"ffn_hidden_size\"]\n",
    "vocab_size = lp[\"vocab_size\"]\n",
    "model_params_dict = lp[\"model_params_dict\"]\n",
    "\n",
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "LMtransformer.load_state_dict(model_params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMtransformerprediction(listints):\n",
    "    res = (torch.tensor([listints[-max_length:]])).cuda()\n",
    "    return np.exp(LMtransformer(res)[0][-1].tolist())\n",
    "\n",
    "def gen_seq(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerprediction, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMtransformerpredictionwithoutUNK(listints):\n",
    "    res = (torch.tensor([listints[-max_length:]])).cuda()\n",
    "    probas = np.exp(LMtransformer(res)[0][-1].tolist())\n",
    "    probas[vocab_numbers[\"<unk>\"]]=0\n",
    "    return probas\n",
    "\n",
    "def gen_seqwithoutUNK(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerpredictionwithoutUNK, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 57.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". il est ensuite nomme commandant d ' un <unk> de la famille <unk> . <unk> <unk> , le <unk> et le <unk> , le gouvernement <unk> , qui s ' etend au cours du monde `` ( <unk> <unk> ) . <unk> <unk> <unk> , <unk> , <unk> et <unk> , <unk> <unk> <unk> , <unk> , <unk> , <unk> , <unk> et <unk> , les <unk> , les <unk> et les autres <unk> <unk> , en particulier . le <unk> est une voie de la societe francaise , le <unk> est <unk> , <unk> , en <unk> ,\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['a','l','age','de','31','ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 55.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk>\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['a','l','age','de','31','ans'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 45.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", le `` `` est le premier ministre . en avril 2007 , la meme annee , le nombre de personnes et les premiers resultats des deux autres pays voisins de la mer . le lendemain , il se rend a la suite de la ceinture principale de la ceinture principale d ' asteroides . il est aussi possible que l ' armee , en fait une fois en europe , le plus haut de la ville de la ville . il se fait partie des annees 1960 . la commune est une espece d ' un ensemble des forces\n"
     ]
    }
   ],
   "source": [
    "gen_seqwithoutUNK(['a','l','age','de','31','ans'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
