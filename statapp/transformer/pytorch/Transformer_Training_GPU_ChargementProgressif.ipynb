{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformer_model_GPU import *\n",
    "import nltk\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from statapp.common.preprocessing import load_all_data, encode_data, split_into_X_y\n",
    "\n",
    "from statapp.common.sampling import sample_token_sequence\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing maison assez brouillon pour le moment... L'encodage est effectué au niveau des mots. Les données exploitées sont placées dans le dossier data dans le dossier du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir proportion multiple de 0.05\n",
    "\n",
    "def build_vocab(vocab_size=10000, proportion=0.1):\n",
    "    \n",
    "    dico = {}\n",
    "    \n",
    "    step = int(proportion*100//5)\n",
    "    \n",
    "    for i in range(step):\n",
    "        \n",
    "        text = load_all_data(\"data/fr.train.top1M.txt\", start=i*0.05, sample=0.05)\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        vocab = list(set(tokens))\n",
    "        vocab.sort()\n",
    "        \n",
    "        for word in vocab:\n",
    "            if word not in dico.keys():\n",
    "                dico[word]=0\n",
    "\n",
    "        for token in tokens:\n",
    "            dico[token]+=1\n",
    "\n",
    "    sorted_list = sorted(dico.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    sorted_dico = {}\n",
    "\n",
    "    for i in range(min(len(sorted_list),vocab_size-1)):\n",
    "        sorted_dico[sorted_list[i][0]] = sorted_list[i][1]        \n",
    "    \n",
    "    vocab = list(sorted_dico.keys())\n",
    "    vocab.append(\"<unk>\")\n",
    "    vocab.sort()  \n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(vocab_size=5000, proportion=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_train(start, sample, vocab):\n",
    "    \n",
    "    text = load_all_data(\"data/fr.train.top1M.txt\", start=start, sample=sample)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in vocab:\n",
    "            tokens[i] = \"<unk>\"       \n",
    "\n",
    "    vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "    tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "    tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "    tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "    \n",
    "    #if USE_CUDA:\n",
    "    #    tokens_numbers_sequences.to(device)\n",
    "    \n",
    "    return tokens_numbers_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvocab = list(set(tokens))\\n\\nif \"<unk>\" not in vocab:\\n    vocab.append(\"<unk>\")\\n    \\nvocab.sort()\\n    \\nvocab_size = len(vocab)\\n\\nvocab_numbers = dict(zip(vocab, range(0,len(vocab))))\\nvocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\\ntokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\\n\\ntokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\\ntokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\\n\\nnb_sequences =  tokens_numbers_sequences.shape[0]\\n\\nprint(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\\nprint(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "vocab = list(set(tokens))\n",
    "\n",
    "if \"<unk>\" not in vocab:\n",
    "    vocab.append(\"<unk>\")\n",
    "    \n",
    "vocab.sort()\n",
    "    \n",
    "vocab_size = len(vocab)\n",
    "\n",
    "vocab_numbers = dict(zip(vocab, range(0,len(vocab))))\n",
    "vocab_numeroted = dict(zip(range(0,len(vocab)), vocab))\n",
    "tokens_numbers = np.array([vocab_numbers[tokens[i]] for i in range(len(tokens))])\n",
    "\n",
    "tokens_numbers_sequences = np.array([ tokens_numbers[i:i+max_length+1] for i in range(len(tokens_numbers)-max_length)])\n",
    "tokens_numbers_sequences = torch.tensor(tokens_numbers_sequences , dtype=torch.int64)\n",
    "\n",
    "nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "print(\"Les données exploitées contiennent {} tokens (mots) au total.\".format(len(tokens)))\n",
    "print(\"La taille du vocabulaire ainsi constitué est de {}\".format(vocab_size))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Constitution d\\'un jeu de test numéroté selon le vocabulaire du jeu d\\'entrainement\\n\\ntext_test = load_all_data(\"data/fr.train.top1M.txt\", start=0.9, sample=0.1)\\n\\ntokens_test = nltk.word_tokenize(text_test)\\n\\nfor i in range(len(tokens_test)):\\n    if tokens_test[i] not in vocab:\\n        tokens_test[i] = \"<unk>\"\\n\\ntokens_numbers_test = np.array([vocab_numbers[tokens_test[i]] for i in range(len(tokens_test))])\\n\\ntokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\\ntokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\\n\\nnb_sequences_test =  tokens_numbers_sequences_test.shape[0]\\n\\nprint(\"Les données de test exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Constitution d'un jeu de test numéroté selon le vocabulaire du jeu d'entrainement\n",
    "\n",
    "text_test = load_all_data(\"data/fr.train.top1M.txt\", start=0.9, sample=0.1)\n",
    "\n",
    "tokens_test = nltk.word_tokenize(text_test)\n",
    "\n",
    "for i in range(len(tokens_test)):\n",
    "    if tokens_test[i] not in vocab:\n",
    "        tokens_test[i] = \"<unk>\"\n",
    "\n",
    "tokens_numbers_test = np.array([vocab_numbers[tokens_test[i]] for i in range(len(tokens_test))])\n",
    "\n",
    "tokens_numbers_sequences_test = np.array([ tokens_numbers_test[i:i+max_length+1] for i in range(len(tokens_numbers_test)-max_length)])\n",
    "tokens_numbers_sequences_test = torch.tensor(tokens_numbers_sequences_test , dtype=torch.int64)\n",
    "\n",
    "nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "print(\"Les données de test exploitées contiennent {} tokens (mots) au total.\".format(len(tokens_test)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif USE_CUDA:\\n    tokens_numbers_sequences.to(device)\\n    tokens_numbers_sequences_test.to(device)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "if USE_CUDA:\n",
    "    tokens_numbers_sequences.to(device)\n",
    "    tokens_numbers_sequences_test.to(device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Creation Fichier Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé des fichiers contenant 5% du data set initial, vocabulaire taille 20K et etendu=5 (voir train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-94c45ce61ad7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfichier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmon_pickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfichier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mmon_pickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_data_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-6b2f3b31b7d0>\u001b[0m in \u001b[0;36mload_data_train\u001b[1;34m(start, sample, vocab)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"<unk>\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    name = \"Taille5_Voca20K_\" + str(i)\n",
    "    with open(name,'wb') as fichier:\n",
    "        mon_pickler = pickle.Pickler(fichier)\n",
    "        mon_pickler.dump(load_data_train(i*0.05, 0.05, vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMtransformer = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "if USE_CUDA:\n",
    "    LMtransformer.to(device)\n",
    "\n",
    "#Correspond à utiliser l'entropie croisée puisque les sorties sont des log_softmax\n",
    "#et l'entropie croisée = nll_loss(log_softmax(.), target)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(LMtransformer.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nb_epochs, batch_size, proportion):\n",
    "    \n",
    "    #What is this ?? I don't remember. Make grad required ?\n",
    "    LMtransformer.train()\n",
    "    \n",
    "    epochs_losses = []\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    etendu = 5\n",
    "    \n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        running_loss = 0\n",
    "        \n",
    "        print(\"Test epoch : \", epoch)\n",
    "        \n",
    "    \n",
    "        for step in range(int(proportion*100//etendu)):\n",
    "            \n",
    "            print(\"Test step 1 : \", step)\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            name = \"Taille5_Voca20K_\" + str(step)\n",
    "            with open(name,'rb') as fichier:\n",
    "                mon_depickler = pickle.Unpickler(fichier)\n",
    "                tokens_numbers_sequences = mon_depickler.load()   \n",
    "                \n",
    "            \"\"\"\n",
    "            \n",
    "            tokens_numbers_sequences =load_data_train(step*0.05, 0.05, vocab)\n",
    "            \n",
    "       \n",
    "            if USE_CUDA:\n",
    "                tokens_numbers_sequences.to(device) \n",
    "                \n",
    "            nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "        \n",
    "            randperm = torch.randperm(nb_sequences)\n",
    "            randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "            batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "            \n",
    "            print(\"Test step 2 : \", step)\n",
    "\n",
    "            for i, batch_indices in enumerate(batchs_indices):\n",
    "\n",
    "                batch = (tokens_numbers_sequences[batch_indices]).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = LMtransformer(batch[:,:-1])\n",
    "                loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                test_loss = 0\n",
    "\n",
    "                #Il faudrait adapter les affichages en fonction du nombre de batchs total\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                #Calcul de la loss sur les données de test\n",
    "                \"\"\"\n",
    "                if USE_CUDA:\n",
    "                    test_output = (LMtransformer(tokens_numbers_sequences_test[:,:-1])).cuda()\n",
    "                    test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "                else:\n",
    "                    test_output = LMtransformer(tokens_numbers_sequences_test[:,:-1])  \n",
    "                    test_loss = criterion(test_output.reshape(-1, vocab_size), tokens_numbers_sequences_test[:,1:].flatten())\n",
    "\n",
    "                print('[%d, %5d] loss: %.3f ; test_loss : %.3f' %\n",
    "                        (epoch + 1, i + 1, running_loss / step, test_loss))\n",
    "                \"\"\"\n",
    "            \n",
    "            nb_batches_in_the_step = nb_sequences//batch_size\n",
    "\n",
    "            print('[%d, %5d] loss: %.3f ' %\n",
    "                (epoch + 1, i + 1, running_loss / nb_batches_in_the_step))\n",
    "                    \n",
    "            #stock pour affichage graphique\n",
    "            epochs_losses.append(epoch-1+step)\n",
    "            losses.append(running_loss / nb_batches_in_the_step)                    \n",
    "                    \n",
    "            #test_losses.append(test_loss)\n",
    "\n",
    "            running_loss = 0.\n",
    "\n",
    "            end = time.time()\n",
    "            print(\"Temps : \", end-start)\n",
    "\n",
    "    plt.plot(epochs_losses, losses)\n",
    "    #plt.plot(epochs_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'overfitting sur un cas ultrasimplifié (5 tokens, longueur de séquence 1, 3 decoders, 2 heads) :\n",
    "- En observant les sorties le modèle a bien appris et overfitte ! (loss à 0 au bout de 5-6 epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch :  0\n",
      "Test step 1 :  0\n",
      "Test step 2 :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christos\\Desktop\\Git\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model_GPU.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = (torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  6315] loss: 4.023 \n",
      "Temps :  510.4543104171753\n",
      "Test step 1 :  1\n",
      "Test step 2 :  1\n",
      "[1,  6308] loss: 3.943 \n",
      "Temps :  1018.0531251430511\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3hUddr/8fedQkKvAZEgEUGlFyNSE0UQbCBFxYodFQTJqis/93GVXde6FLvYsSs2RKQKCU0g9N4UpSlBilKk3r8/MuzDkw1mIGWSyed1XXPlzDnfOXN/ET6enDlzH3N3REQkfEWEugAREclfCnoRkTCnoBcRCXMKehGRMKegFxEJc1GhLiCrKlWqeEJCQqjLEBEpUubNm7fN3eOy21bogj4hIYH09PRQlyEiUqSY2Y/H26ZTNyIiYU5BLyIS5hT0IiJhTkEvIhLmFPQiImFOQS8iEuYU9CIiYS5sgt7d+dfYFXyfsTvUpYiIFCphE/Q/bNvDh3N+4uLh03g5dR2HDh8JdUkiIoVC2AR97bgyTExJJvnMOJ74ZiVXvDiD5Zt/C3VZIiIhFzZBD1CtXCyv3HAOL17XnJ93/UGX56fz7wmr2H/ocKhLExEJmbAKegAz45JG1Zk4MJkuTU/luW/Xcsnwacz7cXuoSxMRCYmwC/qjKpYuwZCrmvLWzefyx8Ej9Hx5Fo+MXsae/YdCXZqISIEKOujNLNLMFpjZmGy2xZjZR2a21sxmm1lCYH1HM5tnZksCP9vnXenBOf+sqowfmMQNLWvx1sz1dBqWxrQ1GQVdhohIyJzIEf0AYMVxtt0K7HD3OsBQ4MnA+m3A5e7eCOgNvHOyheZGmZgoBndtyMd9WlEiMoIbXp/D/Z8sYtfeg6EoR0SkQAUV9GYWD1wKvHacIV2BtwPLo4ALzczcfYG7bw6sXwbEmllMbgrOjRanV2LsgHbcff4ZfLZgEx2GpjJu6c+hKkdEpEAEe0Q/DHgAON7F6TWADQDufgjYBVTOMqYHsMDd92d9sZndYWbpZpaekZG/p1VioyN5oPPZfNm3DXFlYrjz3Xnc/d48tv7+R76+r4hIqOQY9GZ2GbDV3ef92bBs1vkx+2hA5umcPtm92N1HuHuiuyfGxWV7J6w817BGeb7s14b7O53FpBVb6TgkjVHzNuLuOb9YRKQICeaIvg3QxczWAx8C7c3s3SxjNgI1AcwsCigPbA88jwc+B25093V5VHeeiI6MoO8FdRjbvx11qpbhvk8W0fvNuWzcsTfUpYmI5Jkcg97dB7l7vLsnAL2Ab939+izDRpP5YStAz8AYN7MKwNfAIHefkYd156k6VcvwSZ9WPNqlAenrt3PR0DTenrmeI0d0dC8iRd9JX0dvZoPNrEvg6etAZTNbC6QADwbW9wPqAP9jZgsDj6q5qjifREQYvVsnMGFgEokJlfj76GVc9cos1qlJmogUcVbYzkknJiZ6enp6SGtwdz6dv4l/jFnOvoOHGXBhXe5Iqk10ZNh+v0xEijgzm+fuidltU3Jlw8zoeU48E1OS6FCvKk+PX0XX52ewdNOuUJcmInLCFPR/omrZWF687hxevr45W3/fT9cXZvDkuJX8cVBN0kSk6FDQB6Fzw+pMTkmme7MavDR1HZcMn8bc9WqSJiJFg4I+SOVLRfP0lU0YeUsL9h86wpUvz+LhL5eyW03SRKSQU9CfoKQz45gwMImbWifwznc/0mloGqmr1SRNRAovBf1JKB0TxSNdGjDqzlbERkfQ+405pHy8kB17DoS6NBGR/6Kgz4VzalXi6/7t6HdBHUYv3EzHoamMXbJFbRREpFBR0OdSbHQk93U6iy/7teGU8rHc/d587nx3Hlt/U5M0ESkcFPR5pMGp5fni7jb8tfPZTFmVQYchqXycvkFH9yIScgr6PBQVGcFd55/BuAHtOPuUcjwwajE3vD6HDdvVJE1EQkdBnw9qx5Xhwzta8o8rGrLgpx1cNDSNN2f8wGE1SROREFDQ55OICOOGlrWYkJLMebUr8ehXy7ny5Zms+eX3UJcmIsWMgj6f1ahQkjdvOpehVzfh+217uPTZ6Tw3eQ0HDx/vZl0iInlLQV8AzIxuzeKZlJJMxwbV+PfE1Vz+3HSWbFSTNBHJfwr6AlSlTAwvXNucV244h+17DtD1hek8/s0KNUkTkXyloA+BTg1OYWJKMlcl1uSV1O+5ePg0Zn//a6jLEpEwFXTQm1mkmS0wszHZbIsxs4/MbK2ZzTazhMD6ymY2xcx2m9nzeVd20Ve+ZDRP9GjMe7edx6EjR7h6xHf87Ysl/P7HwVCXJiJh5kSO6AcAK46z7VZgh7vXAYYCTwbW/wH8D3DfSVcY5trUqcL4e5O4te3pvDf7Jy4amsaUlVtDXZaIhJGggt7M4oFLgdeOM6Qr8HZgeRRwoZmZu+9x9+lkBr4cR6kSUfzPZfX59K7WlImJ4ua35nLvhwvYriZpIpIHgj2iHwY8ABzvmsAawAYAdz8E7AIqB1uEmd1hZulmlp6RUXxb/jY/rSJj+rel/4V1GbN4Cx2HpPLVos1qoyAiuZJj0JvZZcBWd5/3Z8OyWRd0Orn7CHdPdPfEuLi4YF8WlmKiIknpeCZf3dOWGhVLcs8HC7h95Dx+UZM0ETlJwRzRtwG6mNl64EOgvZm9m2XMRqAmgJlFAeUB3WsvF+pVL8dnd7XmoUvqMW1NZpO0D+f8pKN7ETlhOQa9uw9y93h3TwB6Ad+6+/VZho0GegeWewbGKJFyKSoygtuTajP+3iTqVy/Hg58t4brXZvPjr3tCXZqIFCEnfR29mQ02sy6Bp68Dlc1sLZACPHjMuPXAEOAmM9toZvVzUW+xlFClNB/c3pJ/dWvE4o276DQsjdemfa8maSISFCtsB96JiYmenp4e6jIKrS279vHQ50v5duVWmtSswFM9GnPWKWVDXZaIhJiZzXP3xOy26ZuxRUz18iV5vXciw3s1ZcP2vVz23DSGTVrNgUNqkiYi2VPQF0FmRtemNZg4MIlLGlVn2KQ1XP7cdBZt2Bnq0kSkEFLQF2GVy8QwvFczXrsxkV37DtLtxRk89vVy9h1QkzQR+V8K+jDQoX41JqQk0avFabw67Qc6D09j5rptoS5LRAoJBX2YKBcbzb+6NeL9288D4NpXZzPosyX8piZpIsWegj7MtD6jCuMGJHFHUm0+mvsTHYekMmn5L6EuS0RCSEEfhkqWiOT/XVKPz+9uQ8VSJbhtZDr9P1jAr7v3h7o0EQkBBX0Ya1KzAqP7tWVghzP5ZukWOgxJ5cuFm9RGQaSYUdCHuRJREQzoUJev+7ejVuXSDPhwIbe9nc6WXftCXZqIFBAFfTFxZrWyfHpXa/52aT1mrNtGxyFpvDf7R46ojYJI2FPQFyOREcZt7Woz4d5kGseX56HPl3LNq9/xwzY1SRMJZwr6Yui0yqV477bzeKJ7I5Zv/o3Ow9IYkbaOQ4fVRkEkHCnoiykzo1eL05iYkky7unH8a+xKur80kxVbfgt1aSKSxxT0xdwp5WN59cZzeP7aZmzasY/Ln5vOkImr2X9IbRREwoWCXjAzLmt8KpNSkrm8yak8O3kNlz07nfk/7Qh1aSKSB4IOejOLNLMFZjYmm20xZvaRma01s9lmlnDMtkGB9avMrFPelC35oWLpEgy9uilv3nQuu/cfosdLM/nHmOXsPXAo1KWJSC6cyBH9AGDFcbbdCuxw9zrAUOBJgMDdpHoBDYDOwItmFnny5UpBuODsqkwYmMR1553G69N/oNOwNGasVZM0kaIqqKA3s3jgUuC14wzpCrwdWB4FXGhmFlj/obvvd/cfgLVAi9yVLAWhbGw0/7yiER/d0ZKoiAiue202fx21mF371CRNpKgJ9oh+GPAAcLzr72oAGwDc/RCwC6h87PqAjYF1/4eZ3WFm6WaWnpGREWRJUhDOq12Zbwa0487kMxg1fyMdh6QyYdnPoS5LRE5AjkFvZpcBW9193p8Ny2ad/8n6/7vCfYS7J7p7YlxcXE4lSQGLjY7kwYvP5ou721C5TAx3vDOPvu/PJ+N3NUkTKQqCOaJvA3Qxs/XAh0B7M3s3y5iNQE0AM4sCygPbj10fEA9szmXNEiKN4sszul8b7rvoTCYu+4WOQ1P5bP5GNUkTKeRyDHp3H+Tu8e6eQOYHq9+6+/VZho0GegeWewbGeGB9r8BVOacDdYE5eVa9FLjoyAj6ta/L2AFtqV2lNCkfL+Lmt+ayaaeapIkUVid9Hb2ZDTazLoGnrwOVzWwtkAI8CODuy4CPgeXAOKCvu+ubOGGgTtWyfHJna/5+eX1mf7+di4ak8s6s9WqSJlIIWWH7tTsxMdHT09NDXYacgA3b9/L/Pl/CtDXbaJFQiSd6NKJ2XJlQlyVSrJjZPHdPzG6bvhkruVazUilG3tKCp3s2ZuXPv9F5+DRemqomaSKFhYJe8oSZcWViTSalJHPBWXE8OW4lV7w4g+Wb1SRNJNQU9JKnqpaL5ZUbEnnpuub8vGs/XZ6fzjPjV/HHQX00IxIqCnrJFxc3qs6klCS6Nq3B81PWcumz05j34/ZQlyVSLCnoJd9UKFWCf1/VhLdvacEfB4/Q8+VZPDJ6GXv2q0maSEFS0Eu+Sz4zjvEDk7ixZS3enrWei4amkbZarS5ECoqCXgpEmZgoHu3akI/7tCImOoIb35jDfZ8sYtdeNUkTyW8KeilQ5yZUYmz/dtx9/hl8vmATHYamMm7pllCXJRLWFPRS4GKjI3mg89l82bcNcWViuPPd+dz17jy2/v5HqEsTCUsKegmZhjXK82W/Ntzf6Swmr9xKxyFpfJK+QU3SRPKYgl5CKjoygr4X1GFs/3bUrVqG+0ct5sY35rBh+95QlyYSNhT0UijUqVqGj/u0YnDXBsz/cQedhqXx1owf1CRNJA8o6KXQiIgwbmyVwPiBSSQmVOKRr5Zz1SuzWLt1d6hLEynSFPRS6MRXLMXbN5/Lv69swpqtu7lk+DRemLKWg2qSJnJSFPRSKJkZPc6JZ1JKMh3qV+Xp8avo+vwMlm7aFerSRIocBb0UanFlY3jxunN4+frmZOzeT9cXZvDkuJVqkiZyAoK5OXismc0xs0VmtszMHs1mTC0zm2xmi81sqpnFH7PtSTNbGnhcndcTkOKhc8PqTBqYTI/mNXhp6jouGT6NuevVJE0kGMEc0e8H2rt7E6Ap0NnMWmYZ8www0t0bA4OBxwHM7FKgeeB15wH3m1m5vCpeipfypaJ5qmcT3r31PA4cPsKVL8/i4S+XsltN0kT+VDA3B3d3P3rZQ3TgkfWat/rA5MDyFKDrMetT3f2Qu+8BFgGdc121FGtt61Zh/L1J3NwmgXe++5FOQ9OYumprqMsSKbSCOkdvZpFmthDYCkx099lZhiwCegSWuwFlzaxyYP3FZlbKzKoAFwA1s9n/HWaWbmbpGRnqaig5Kx0Txd8vb8CoO1tTskQkN705l5SPF7Jjz4FQlyZS6AQV9O5+2N2bAvFACzNrmGXIfUCymS0AkoFNwCF3nwCMBWYCHwCzgP/6PdvdR7h7orsnxsXFnfxspNg5p1ZFvu7flnva12H0ws10HJrK14u3qI2CyDFO6Kobd98JTCXL6Rd33+zu3d29GfBQYN2uwM/H3L2pu3cEDFiTF4WLHBUTFclfLjqL0f3aUr18Sfq+P58+78xj629qkiYCwV11E2dmFQLLJYEOwMosY6qY2dF9DQLeCKyPDJzCwcwaA42BCXlXvsj/qn9qOT6/uzWDLj6b1NUZXDgklY/nqkmaSDBH9NWBKWa2GJhL5jn6MWY22My6BMacD6wys9VANeCxwPpoYJqZLQdGANe7uy6RkHwTFRlBn+Qz+GZAO+pVL8cDny7mhtfVJE2KNytsRzuJiYmenp4e6jIkDBw54rw/5yee+GYlh48493c6i96tE4iMsFCXJpLnzGyeuydmt03fjJWwFRFhXN+yFhMGJnFe7UoMHrOcni/PZM0vv4e6NJECpaCXsHdqhZK8edO5DLu6Keu37eHSZ6fz7OQ1HDikJmlSPCjopVgwM65oVoOJKcl0angKQyaupsvz01m8cWeoSxPJdwp6KVaqlInhuWua8eqNiezYe4ArXpjB42NXqEmahDUFvRRLHetXY8LAZK4+tyavpH1P52FpfPf9r6EuSyRfKOil2CpfMprHuzfm/dvO44hDrxHf8dDnS/j9j4OhLk0kTynopdhrXacK4+5tx21tT+eDOT9x0dA0vl35S6jLEskzCnoRoFSJKP52WX0+vas1ZWKiuOWtdO79cAHb1SRNwoCCXuQYzU6ryJj+bRlwYV2+XrKFDkNSGb1os9ooSJGmoBfJIiYqkoEdz+Sre9pSs2JJ+n+wgNtHzuPnXWqSJkWTgl7kOM4+pRyf3d2Ghy6px/S1GXQcksoHc37S0b0UOQp6kT8RGWHcnlSbcQOSaFCjHIM+W8K1r87mx1/3hLo0kaAp6EWCkFClNO/f1pJ/dWvE0k276DQsjdemfc/hIzq6l8JPQS8SpIgI49rzTmNCShJtzqjCP79eQfeXZrLqZzVJk8JNQS9ygqqXL8lrvRN59ppmbNi+l8uem8awSavVJE0KrWDuMBVrZnPMbJGZLTOzR7MZU8vMJpvZYjObambxx2x7KvC6FWb2rJmpGbgUeWZGlyanMiklmUsaVWfYpDVc/tx0Fm5QkzQpfII5ot8PtHf3JkBToLOZtcwy5hlgpLs3BgYDjwOYWWugDZm3EGwInEvmzcNFwkKl0iUY3qsZr/dOZNe+g3R/cQaPfb2cfQfUJE0KjxyD3jPtDjyNDjyyfgJVH5gcWJ4CdD36ciAWKAHEBF6r75ZL2LmwXjUmpCTRq8VpvDrtBzoNS2Pmum2hLksECPIcfeAm3wuBrWTeM3Z2liGLgB6B5W5AWTOr7O6zyAz+LYHHeHdfkTelixQu5WKj+Ve3Rnxwe0vM4NpXZzPos8X8piZpEmJBBb27H3b3pkA80MLMGmYZch+QbGYLyDw1swk4ZGZ1gHqB19UA2ptZUtb9m9kdZpZuZukZGRm5mI5I6LU6ozLjBiTRJ6k2H83dQMchqUxarl9kJXRO6Kobd98JTAU6Z1m/2d27u3sz4KHAul1kHt1/5+67A6d/vgGynt/H3Ue4e6K7J8bFxZ3cTEQKkZIlIhl0ST2+6NuGiqVKcNvIdO75YAG/7t4f6tKkGArmqps4M6sQWC4JdABWZhlTxcyO7msQ8EZg+Scyj/SjzCyazKN9nbqRYqNxfAVG92tLSsczGbc0s0nalws3qY2CFKhgjuirA1PMbDEwl8xz9GPMbLCZdQmMOR9YZWargWrAY4H1o4B1wBIyz+Mvcvev8nICIoVdiagI+l9Yl6/7t6NW5dIM+HAht76dzuad+0JdmhQTVtiOLBITEz09PT3UZYjki8NHnLdmrueZ8auIjDAevPhsrm1xGhER+nqJ5I6ZzXP3xOy26ZuxIgUoMsK4te3pjL83iSY1y/O3L5Zyzavf8cM2NUmT/KOgFwmB0yqX4t1bz+OpHo1ZvuU3Og9L45XUdRw6rDYKkvcU9CIhYmZcdW5NJqUkk3RmHI9/s5LuL81kxZbfQl2ahBkFvUiIVSsXy4gbzuGFa5uzeec+Ln9uOkMmrGL/IbVRkLyhoBcpBMyMSxtXZ+LAZLo0OZVnv13LZc9OZ/5PO0JdmoQBBb1IIVKxdAmGXN2UN28+lz37D9HjpZkM/mo5ew8cCnVpUoQp6EUKoQvOqsr4gUlcf14t3pjxAxcNTWP6GjVJk5OjoBcppMrGRvOPKxrycZ9WREdGcP3rs3lg1CJ27VOTNDkxCnqRQq7F6ZX4ZkA77jr/DD6dv4mOQ1IZv+znUJclRYiCXqQIiI2O5K+dz+aLu9tQuUwMfd6ZR9/35pPxu5qkSc4U9CJFSKP48ozu14b7O53FxOW/0HFoKp/N36gmafKnFPQiRUx0ZAR9L6jD2AFtOSOuDCkfL+KmN+eySU3S5DgU9CJFVJ2qZfmkTyseubw+c9dv56IhqYyctZ4jR3R0L/+Xgl6kCIuIMG5qk9kkrXmtijz85TKuHjGLdRm7c36xFBsKepEwULNSKUbe0oKnezZm1c+/c/Hwabw4da2apAmgoBcJG2bGlYk1mfSXZNqfVZWnxq3iihdnsGzzrlCXJiEWzK0EY81sjpktMrNlZvZoNmNqmdlkM1tsZlPNLD6w/gIzW3jM4w8zuyI/JiIimaqWjeXlG87hpeua8/Ou/XR5fgZPj1/JHwfVJK24yvEOU2ZmQGl33x247+t0YIC7f3fMmE+AMe7+tpm1B2529xuy7KcSsBaId/e9x3s/3WFKJO/s3HuAf369glHzNlI7rjRP9WhMYkKlUJcl+SBXd5jyTEc/2YkOPLL+36E+MDmwPAXoms2uegLf/FnIi0jeqlCqBM9c2YSRt7Rg/8EjXPnKLB4ZvYw9+9UkrTgJ6hy9mUWa2UJgK5k3B5+dZcgioEdguRtQ1swqZxnTC/jgOPu/w8zSzSw9IyMj+OpFJChJZ8YxYWASvVsl8Pas9Vw0NI201fq3VlwEFfTuftjdmwLxQAsza5hlyH1AspktAJKBTcB/DhnMrDrQCBh/nP2PcPdEd0+Mi4s7iWmISE5Kx0TxSJcGfNKnFTHREdz4xhzu+2QRO/ceCHVpks9O6Kobd98JTAU6Z1m/2d27u3sz4KHAumM/6r8K+Nzd1XZPJMQSEyoxtn87+l5wBp8v2ESHIWl8s2RLqMuSfBTMVTdxZlYhsFwS6ACszDKmipkd3dcg4I0su7mG45y2EZGCFxsdyf2dzmZ0vzZUKxfDXe/N565357H19z9CXZrkg2CO6KsDU8xsMTCXzHP0Y8xssJl1CYw5H1hlZquBasBjR19sZglATSA1D+sWkTzQ4NTyfNG3DX/tfDaTV26lw79T+SR9g5qkhZkcL68saLq8UiQ01mXs5sFPFzN3/Q7a1a3Cv7o1omalUqEuS4KUq8srRaR4OCOuDB/d0Yp/dG3A/B930GlYGm/N+EFN0sKAgl5E/iMiwrihVQLjByZxbkIlHvlqOVe+Mou1W38PdWmSCwp6Efkv8RVL8dbN5zLkqiasy9jNJcOn88KUtRxUk7QiSUEvItkyM7o3j2fiwGQ6NqjG0+NX0eX5GSzdpCZpRY2CXkT+VFzZGF64tjmv3HAO23bvp+sLM3jiGzVJK0oU9CISlE4NTmHSwGR6No/n5dR1XDJ8GnN+2B7qsiQICnoRCVr5UtE82bMx7956HgcOH+GqV2bxP18sZbeapBVqCnoROWFt61ZhwsAkbmlzOu/O/pGLhqQyZdXWUJclx6GgF5GTUqpEFA9fXp9Rd7amVEwUN785l5SPFrJjj5qkFTYKehHJlXNqVeTr/m3p374OoxdtpsOQVMYs3qw2CoWIgl5Eci0mKpKUi87iq3vacmqFkvR7fwF93pnHL7+pSVphoKAXkTxTr3o5Pr+7NYMuPpvU1Rl0GJLKR3N/0tF9iCnoRSRPRUVG0Cf5DMbdm0S96uX466dLuP712fz0q+4iGioKehHJF6dXKc2Ht7fkn1c0ZNGGXXQalsbr03/gsJqkFTgFvYjkm4gI4/qWtZgwMIlWZ1TmH2OW0/Plmaz5RU3SClIwd5iKNbM5ZrbIzJaZ2aPZjKllZpPNbLGZTTWz+GO2nWZmE8xshZktD9yIRESKkVMrlOT13okM79WU9dv2cMmz03h28hoOHFKTtIIQzBH9fqC9uzcBmgKdzaxlljHPACPdvTEwGHj8mG0jgafdvR7QAtC3KkSKITOja9MaTEpJpnPD6gyZuJouz09n0YadoS4t7OUY9J5pd+BpdOCR9SRbfWByYHkK0BXAzOoDUe4+MbCv3e6uT2REirHKZWJ47ppmvHpjIjv2HqDbizN4fOwK9h1Qk7T8EtQ5ejOLNLOFZB6NT3T32VmGLAJ6BJa7AWXNrDJwJrDTzD4zswVm9rSZReZV8SJSdHWsX42JKclcfW5NXkn7nouHp/Hd97+GuqywFFTQu/thd28KxAMtzKxhliH3AclmtgBIBjYBh4AooF1g+7lAbeCmrPs3szvMLN3M0jMyMk52LiJSxJSLjebx7o15/7bzOOLQa8R3PPT5En7/42CoSwsrJ3TVjbvvBKYCnbOs3+zu3d29GfBQYN0uYCOwwN2/d/dDwBdA82z2O8LdE909MS4u7uRmIiJFVus6VRh/bxK3tzudD+b8xEVD0/h25S+hLitsBHPVTZyZVQgslwQ6ACuzjKliZkf3NQh4I7A8F6hoZkfTuz2wPC8KF5HwUrJEJA9dWp/P7m5DudhobnkrnQEfLuDX3ftDXVqRF8wRfXVgipktJjO4J7r7GDMbbGZdAmPOB1aZ2WqgGvAYZJ7yIfO0zWQzWwIY8Goez0FEwkjTmhX46p623NuhLmOXbKHj0DRGL1KTtNywwvaHl5iY6Onp6aEuQ0QKgVU//84Dny5m0YaddKhXlX9e0YhTyseGuqxCyczmuXtidtv0zVgRKbTOOqUsn93Vmr9dWo/pa7fRcUgqH8xRk7QTpaAXkUItMsK4rV1txt+bRMMa5Rn02RKufXU2P/66J9SlFRkKehEpEmpVLs37t5/HE90bsXRTZpO0V9O+V5O0ICjoRaTIMDN6tTiNiSnJtK1ThcfGrqD7izNY9bOapP0ZBb2IFDmnlI/l1RsTee6aZmzcsY/LnpvG0Imr1STtOBT0IlIkmRmXNzmViSnJXNqoOsMnr+Gy56axUE3S/ouCXkSKtEqlSzCsVzPeuCmR3/84RPcXZ/DPMcvVJO0YCnoRCQvtz67GhIFJXNPiNF6b/gOdhqUxc+22UJdVKCjoRSRslI2N5rFujfjwjpZEGFz72mwe/HQxu/YV7yZpCnoRCTsta1dm3L1J9EmuzcfpG7hoaCoTlxffJmkKehEJS7HRkQy6uB5f9G1DxVIluH1kOv3en8+2YtgkTUEvImGtcXwFRvdry186nsmEZb/QcUgqXyzYVKzaKCjoRSTslYiK4J4L6/J1/7YkVCnNvR8t5Na309m8c1+oSysQCnoRKTbqVivLqDtb8/Bl9Zm17lcuGprGu9/9yOtPkDwAAAoLSURBVJEwb6OgoBeRYiUywril7elMGJhE05oV+NsXS+n16nf8sC18m6Qp6EWkWKpZqRTv3NqCp3o0ZsWW3+g8LI2XU9dx6HD4tVEI5laCsWY2x8wWmdkyM3s0mzG1zGyymS02s6lmFn/MtsNmtjDwGJ3XExAROVlmxlXn1mRSSjLJZ8bxxDcr6fbiTJZv/i3UpeWpYI7o9wPt3b0J0BTobGYts4x5Bhjp7o2BwcDjx2zb5+5NA48uiIgUMtXKxfLKDefwwrXN2bJrH12en86/J6xi/6HwaKOQY9B7pt2Bp9GBR9ZPLuoDkwPLU4CueVahiEgBMDMubVydiQOT6dL0VJ77di2XPjudeT/uCHVpuRbUOXozizSzhcBWMm8OPjvLkEVAj8ByN6CsmVUOPI81s3Qz+87MrjjO/u8IjEnPyMg4iWmIiOSNiqVLMOSqprx187nsO3CYni/P5NGvlrFn/6FQl3bSTujm4GZWAfgcuMfdlx6z/lTgeeB0II3M0G/g7rvM7FR332xmtYFvgQvdfd3x3kM3BxeRwmL3/kM8NW4lI2f9SHzFkjzevRHt6saFuqxs5dnNwd19JzAV6Jxl/WZ37+7uzYCHAut2Hd0W+Pl94LXNTrB+EZGQKBMTxeCuDfm4TytKREZww+tzeGDUInbtLVpN0oK56iYucCSPmZUEOgArs4ypYmZH9zUIeCOwvqKZxRwdA7QBludd+SIi+a/F6ZUYO6Add51/Bp/O30SHoamMW/pzqMsKWjBH9NWBKWa2GJhL5jn6MWY22MyOXkVzPrDKzFYD1YDHAuvrAelmtojMD2mfcHcFvYgUObHRkfy189l82bcNcWViuPPdefR9bz4Zvxf+JmkndI6+IOgcvYgUdgcPH2FE2vcMn7yGktGRPHxZfbo3r4GZhaymPDtHLyIiEB0ZQd8L6jC2fzvqVC3DXz5ZRO8357Jxx95Ql5YtBb2IyEmqU7UMn/RpxaNdGpC+fjudhqYxctb6QtckTUEvIpILERFG79YJjL83iea1KvLwl8u4esQs1mXszvnFBURBLyKSB2pWKsXIW1rwzJVNWP3Lbi4ePo0Xp67lYCFokqagFxHJI2ZGz3PimZiSRId6VXlq3CqueGEGSzftCmldCnoRkTxWtWwsL153Di9f35xffttP1xdm8PT4lfxxMDRN0hT0IiL5pHPD6kxOSaZ7sxq8MGUdlzw7jfT12wu8DgW9iEg+Kl8qmqevbMLIW1qw/+ARrnxlFn//cim7C7BJmoJeRKQAJJ0Zx4SBSfRulcDI736k09A0UlcXTLdeBb2ISAEpHRPFI10a8EmfVsRGR9D7jTn85eNF7Nx7IF/fV0EvIlLAEhMq8XX/dvS7oA5fLtxEhyFpfLNkS769n4JeRCQEYqMjua/TWXzZrw2nlI/hrvfm0/e9+fnyrdqoPN+jiIgErcGp5fni7ja8Nv0Hdv9xiIiIvG+MpqAXEQmxqMgI7kw+I9/2r1M3IiJhTkEvIhLmgrmVYKyZzTGzRWa2zMwezWZMLTObbGaLzWyqmcVn2V7OzDaZ2fN5WbyIiOQsmCP6/UB7d28CNAU6m1nLLGOeAUa6e2NgMPB4lu3/AFJzW6yIiJy4HIPeMx1trBwdeGS9/qc+MDmwPAXoenSDmZ1D5n1kJ+S6WhEROWFBnaM3s0gzWwhsJfPm4LOzDFkE9AgsdwPKmlllM4sA/g3cn8P+7zCzdDNLz8gomK8Ei4gUF0EFvbsfdvemQDzQwswaZhlyH5BsZguAZGATcAi4Gxjr7hty2P8Id09098S4uLgTnoSIiBzfCV1H7+47zWwq0BlYesz6zUB3ADMrA/Rw911m1gpoZ2Z3A2WAEma2290fzKsJiIjInzP3P/+6rZnFAQcDIV+SzHPtT7r7mGPGVAG2u/sRM3sMOOzuD2fZz01Aorv3y+H9MoAfT2o2maoA23Lx+qKouM25uM0XNOfiIjdzruXu2Z4SCeaIvjrwtplFknmq52N3H2Nmg4F0dx8NnA88bmYOpAF9T7JQjldosMws3d0Tc7OPoqa4zbm4zRc05+Iiv+acY9C7+2KgWTbrHz5meRQwKof9vAW8dcIViohIruibsSIiYS4cg35EqAsIgeI25+I2X9Cci4t8mXOOH8aKiEjRFo5H9CIicgwFvYhImCvyQW9mVwa6ah4xs+NelmRmnc1slZmtNbMi/YUtM6tkZhPNbE3gZ8XjjHsq8GezwsyeNbO8v3VNATiB+Z5mZhMC811uZgkFW2neCXbOgbFh0R02mDmbWVMzmxX4e73YzK4ORa25lVMemVmMmX0U2D47t3+Xi3zQk/kN3e5kXr+frcB3AF4ALiazAds1Zla/YMrLFw8Ck929LpnN5LL7i9IaaAM0BhoC55LZnqIoynG+ASOBp929HtCCzN5MRVWwc4bw6Q4bzJz3Aje6ewMyv6E/zMwqFGCNuRZkHt0K7HD3OsBQ4MncvGeRD3p3X+Huq3IY1gJY6+7fu/sB4EOO6bBZBHUF3g4svw1ckc0YB2KBEkAMmV1HfymQ6vJejvMN/EOJcveJAO6+2933FlyJeS6Y/8bh1h02xzm7+2p3XxNY3kzm/8yLWoOsYPLo2D+LUcCFufmNvMgHfZBqAMc2VtsYWFdUVXP3LQCBn1WzDnD3WWS2jN4SeIx39xUFWmXeyXG+wJnATjP7zMwWmNnTgSOnoirHOQfbHbYICea/83+YWQsyD2TWFUBteSmYPPrPGHc/BOwCKp/sGxaJm4Ob2STglGw2PeTuXwazi2zWFerrSv9szkG+vg5Qj8yOowATzSzJ3Y97iiuUcjtfMv8utyPzW9w/AR8BNwGv50V9+SEP5vyf7rBF5eOXPJjz0f1UB94Berv7kbyorQAFk0d5mllFIujdvUMud7ERqHnM83hgcy73ma/+bM5m9ouZVXf3LYG/8Nmdi+4GfHf0pjFm9g3Qkj/5LCOU8mC+G4EF7v594DVfkDnfQhv0eTDnItcdNg/mjJmVA74G/ubu3+VTqfkpmDw6OmajmUUB5YHtJ/uGxeXUzVygrpmdbmYlgF7A6BDXlBujgd6B5d5Adr/V/ETmPQKizCyazA9ii+qpm2DmOxeoGOi2CtAeWF4AteWXHOfs7te5+2nunkDmPSFGFuaQD0KOcw78+/2czLl+UoC15aVg8ujYP4uewLeem2+3unuRfpB55LqRzHvb/kLmuWiAU8n8tfbouEuA1WSez3so1HXncs6VybwqYU3gZ6XA+kTgtcByJPAKmeG+HBgS6rrzc76B5x2BxcASMhvolQh17fk952PG3wQ8H+q683vOwPXAQWDhMY+moa79JOb6X3lE5v22uwSWY4FPgLXAHKB2bt5PLRBERMJccTl1IyJSbCnoRUTCnIJeRCTMKehFRMKcgl5EJMwp6EVEwpyCXkQkzP1/HLMDv/9pzSQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(1,400,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 step :  0\n",
      "Test 2 step :  0\n",
      "Test 1 step :  1\n",
      "Test 2 step :  1\n",
      "[1] loss: 3.953 \n",
      "Temps :  407.90645027160645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17a1fa1bef0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train Loss\n",
    "\n",
    "n = 1\n",
    "batch_size = 400\n",
    "\n",
    "epochs_losses = []\n",
    "train_losses = []\n",
    "    \n",
    "start = time.time()\n",
    "    \n",
    "for epoch in range(n):\n",
    "    \n",
    "    running_loss = 0\n",
    "    nb_batches_in_the_epoch = 0\n",
    "    \n",
    "    for step in range(int(0.1*100//5)):\n",
    "\n",
    "        print(\"Test 1 step : \", step)\n",
    "\n",
    "        tokens_numbers_sequences = load_data_train(step*0.05, 0.05, vocab)\n",
    "\n",
    "        if USE_CUDA:\n",
    "            tokens_numbers_sequences.to(device) \n",
    "\n",
    "        nb_sequences =  tokens_numbers_sequences.shape[0]\n",
    "\n",
    "        randperm = torch.randperm(nb_sequences)\n",
    "        randperm = randperm[:(nb_sequences//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences//batch_size, batch_size)\n",
    "\n",
    "        print(\"Test 2 step : \", step)\n",
    "\n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            batch = (tokens_numbers_sequences[batch_indices]).to(device)\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        nb_batches_in_the_epoch += nb_sequences//batch_size\n",
    "\n",
    "    print('[%d] loss: %.3f ' %\n",
    "        (epoch + 1, running_loss / nb_batches_in_the_epoch))\n",
    "\n",
    "    epochs_losses.append(n+1)\n",
    "    train_losses.append(running_loss / nb_batches_in_the_epoch)                    \n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Temps : \", end-start)\n",
    "\n",
    "plt.plot(epochs_losses, train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 step :  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-2fb97db156ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test 1 step : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mtokens_numbers_sequences_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-6b2f3b31b7d0>\u001b[0m in \u001b[0;36mload_data_train\u001b[1;34m(start, sample, vocab)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_all_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/fr.train.top1M.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Git\\statapp_language_model\\statapp\\common\\preprocessing.py\u001b[0m in \u001b[0;36mload_all_data\u001b[1;34m(path, start, sample)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \"\"\"\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test Loss\n",
    "\n",
    "nb_epoch = 1\n",
    "batch_size = 400\n",
    "proportion = 0.1\n",
    "start = 0.9\n",
    "\n",
    "\n",
    "epochs_losses = []\n",
    "test_losses = []\n",
    "    \n",
    "begin = time.time()\n",
    "    \n",
    "for epoch in range(nb_epoch):\n",
    "    \n",
    "    test_loss = 0\n",
    "    nb_batches_in_the_epoch = 0\n",
    "    \n",
    "    for step in range(int(proportion*100//5)):\n",
    "\n",
    "        print(\"Test 1 step : \", step)\n",
    "\n",
    "        tokens_numbers_sequences_test = load_data_train(start + step*0.05, 0.05, vocab)\n",
    "\n",
    "        if USE_CUDA:\n",
    "            tokens_numbers_sequences_test.to(device) \n",
    "\n",
    "        nb_sequences_test =  tokens_numbers_sequences_test.shape[0]\n",
    "\n",
    "        randperm = torch.randperm(nb_sequences_test)\n",
    "        randperm = randperm[:(nb_sequences_test//batch_size)*batch_size]\n",
    "        batchs_indices = randperm.reshape(nb_sequences_test//batch_size, batch_size)\n",
    "\n",
    "        print(\"Test 2 step : \", step)\n",
    "\n",
    "        for i, batch_indices in enumerate(batchs_indices):\n",
    "            batch = (tokens_numbers_sequences_test[batch_indices]).to(device)\n",
    "            output = LMtransformer(batch[:,:-1])\n",
    "            loss = criterion(output.reshape(-1, vocab_size), batch[:,1:].flatten())\n",
    "            test_loss += loss.item()\n",
    "\n",
    "        nb_batches_in_the_epoch += nb_sequences_test//batch_size\n",
    "\n",
    "    print('[%d] loss: %.3f ' %\n",
    "        (epoch + 1, test_loss / nb_batches_in_the_epoch))\n",
    "\n",
    "    epochs_losses.append(n+1)\n",
    "    test_losses.append(test_loss / nb_batches_in_the_epoch)                    \n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Temps : \", end-begin)\n",
    "\n",
    "plt.plot(epochs_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des paramètres du modèle obtenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un dico  des hyperparams serait pratique ^^\n",
    "torch.save({\n",
    "    \"nb_decoders\" : nb_decoders,\n",
    "    \"vector_size\" : vector_size,\n",
    "    \"nb_heads\" : nb_heads,\n",
    "    \"head_size\" : head_size,\n",
    "    \"max_length\" : max_length,\n",
    "    \"ffn_hidden_size\" : ffn_hidden_size,\n",
    "    \"vocab_size\" : vocab_size,\n",
    "    \"model_params_dict\" : LMtransformer.state_dict()}\n",
    "    ,\n",
    "    \"params/LMtfparamsTEST\")\n",
    "    #\"params/LMtfparams\"+str(np.random.rand())[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Later to restore:\n",
    "lp = torch.load(\"params/LMtfparamsTEST\")\n",
    "\n",
    "nb_decoders = lp[\"nb_decoders\"]\n",
    "vector_size = lp[\"vector_size\"]\n",
    "nb_heads = lp[\"nb_heads\"]\n",
    "head_size = lp[\"head_size\"]\n",
    "max_length = lp[\"max_length\"]\n",
    "ffn_hidden_size = lp[\"ffn_hidden_size\"]\n",
    "vocab_size = lp[\"vocab_size\"]\n",
    "model_params_dict = lp[\"model_params_dict\"]\n",
    "\n",
    "LMtransformerTEST = buildTransformer(vector_size, nb_decoders, nb_heads, head_size, ffn_hidden_size, vocab_size)\n",
    "LMtransformerTEST.load_state_dict(model_params_dict)\n",
    "\n",
    "#Attention, pour pouvoir générer il faut reconstruire le vocabulaire et ses numéros associés avec le code plus haut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bidouilles pour adapter nos fonctions aux fonctions common codées par Nathra \n",
    "#(sequence list of ints en entree, list of probas en sortie)\n",
    "#(Faire mieux plus tard)\n",
    "def LMtransformerprediction(listints):\n",
    "    return np.exp(LMtransformer(torch.tensor([listints[-max_length:]]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMtransformerpredictionTEST(listints):\n",
    "    return np.exp(LMtransformerTEST(torch.tensor([listints[-max_length:]]))[0][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerprediction, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seqTEST(prev_seq, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        sample_token_seq = sample_token_sequence(LMtransformerpredictionTEST, prev_seq_numbers, top_k=top_k)\n",
    "        tokens_pred = [vocab_numeroted[i] for i in sample_token_seq]\n",
    "        print(' '.join(tokens_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def gen_seq_maison(prev_seq):\\n    with torch.no_grad():\\n        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\\n        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\\n        tokens_pred = vocab_numeroted[indice]\\n        print(' '.join(tokens_pred))\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def gen_seq_maison(prev_seq):\n",
    "    with torch.no_grad():\n",
    "        prev_seq_numbers = [vocab_numbers[token] for token in prev_seq]\n",
    "        indice = np.argmax(np.array(LMtransformer(torch.tensor([prev_seq_numbers]))))\n",
    "        tokens_pred = vocab_numeroted[indice]\n",
    "        print(' '.join(tokens_pred))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/100 [00:00<?, ?it/s]C:\\Users\\Eric\\statapp_language_model\\statapp\\transformer\\pytorch\\transformer_model.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.add(embedded, pos_encodings), dtype=torch.float32)\n",
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 96.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est alors persuade d ' avoir atteint , par la meditation des lettres et des lettres et des nombres , l ' inspiration prophetique et l ' etat de 31 ans , a barcelone , il est touche par l ' esprit prophetique apres avoir obtenu la connaissance du vrai nom de dieu . il est alors persuade d ' avoir atteint , par la meditation des lettres et des lettres et des nombres , l ' inspiration prophetique et l ' etat de 31 ans , a barcelone , il est touche par l ' esprit prophetique apres avoir\n"
     ]
    }
   ],
   "source": [
    "gen_seqTEST(['il'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LMtransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-59864a84ff91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgen_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'l'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'de'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'31'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ans'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-e1e5ecab4b1a>\u001b[0m in \u001b[0;36mgen_seq\u001b[1;34m(prev_seq, top_k)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprev_seq_numbers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvocab_numbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprev_seq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0msample_token_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_token_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLMtransformerprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_seq_numbers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mtokens_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvocab_numeroted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_token_seq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\statapp_language_model\\statapp\\common\\sampling.py\u001b[0m in \u001b[0;36msample_token_sequence\u001b[1;34m(predictor, sequence, gen_length, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0moriginal_sequence_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_from_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7cd12335495a>\u001b[0m in \u001b[0;36mLMtransformerprediction\u001b[1;34m(listints)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#(Faire mieux plus tard)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mLMtransformerprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLMtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlistints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'LMtransformer' is not defined"
     ]
    }
   ],
   "source": [
    "gen_seq(['a','l','age','de','31','ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 95.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... en 1981 , mer . non content d ' exercer son sacerdoce , roger ducouret fut auteur de romans policiers , de contes pour enfants , brocanteur , ami d ' artistes comme pierre dac , fernand raynaud ou jacques brel ... il fut , l ' , les gens de maintenant de vitoria-gasteiz , dont l ' aeroport se met a se specialiser dans le traitement de charge aerienne et , formee par aena , la mairie de vitoria-gasteiz , dont l ' aeroport se met a se specialiser dans le traitement de charge aerienne et , formee\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>','<unk>'], top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 93.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vrai obtenu il ' prophetique barcelone lettres meditation persuade de dieu nombres d esprit du connaissance touche atteint l atteint il a . la prophetique est age etat alors age etat alors age inspiration . ans atteint l vrai alors ans atteint des de avoir apres . la prophetique est age etat alors age inspiration . ans atteint l vrai alors ans atteint des de avoir apres . la prophetique est age etat alors age inspiration . ans atteint l vrai alors age inspiration . ans atteint l vrai alors age inspiration . ans atteint l vrai alors ans atteint\n"
     ]
    }
   ],
   "source": [
    "gen_seq(['barcelone',',','il','est','touche','par','l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tokens)<100:\n",
    "    print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
